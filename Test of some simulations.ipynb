{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of some simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from simulations import *\n",
    "from JobOffer import JobOffer\n",
    "from User import User\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation 0 started, time elapsed: 0.000 seconds.\n",
      "End of the simulations, time elapsed: 28.864 seconds.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "regret, regrets, _, _ = run_several_experiments_Random(nb_exp = 20)\n",
    "plot_regret(regret, regrets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation 0 started, time elapsed: 0.000 seconds.\n",
      "best reward is :  [0.57777778 0.55328244 0.53268293 0.51348837 0.50833333]\n",
      "reward is :  [0.024      0.2176     0.032      0.27789474 0.28533333]\n",
      "regrets is :  [0.55377778 0.33568244 0.50068293 0.23559364 0.223     ] \n",
      "\n",
      "best reward is :  [0.432      0.344      0.2976     0.26588235 0.232     ]\n",
      "reward is :  [0.344      0.2976     0.432      0.19789474 0.232     ]\n",
      "regrets is :  [ 0.088       0.0464     -0.1344      0.06798762  0.        ] \n",
      "\n",
      "best reward is :  [0.45886792 0.35130435 0.295      0.23111111 0.19902439]\n",
      "reward is :  [0.35130435 0.45886792 0.03789474 0.16       0.072     ]\n",
      "regrets is :  [ 0.10756358 -0.10756358  0.25710526  0.07111111  0.12702439] \n",
      "\n",
      "best reward is :  [0.49886792 0.295      0.27130435 0.23111111 0.19902439]\n",
      "reward is :  [0.27130435 0.49886792 0.03789474 0.16       0.072     ]\n",
      "regrets is :  [ 0.22756358 -0.20386792  0.23340961  0.07111111  0.12702439] \n",
      "\n",
      "best reward is :  [0.70569106 0.67111111 0.65566265 0.58666667 0.52512821]\n",
      "reward is :  [0.65566265 0.19130435 0.35789474 0.28       0.252     ]\n",
      "regrets is :  [0.05002841 0.47980676 0.29776791 0.30666667 0.27312821] \n",
      "\n",
      "best reward is :  [0.49148325 0.34253521 0.32872727 0.32702619 0.22172949]\n",
      "reward is :  [0.32702619 0.49148325 0.32872727 0.09053686 0.19444976]\n",
      "regrets is :  [ 0.16445706 -0.14894804  0.          0.23648933  0.02727973] \n",
      "\n",
      "best reward is :  [0.49359165 0.35714286 0.32872727 0.3006993  0.208     ]\n",
      "reward is :  [0.49359165 0.06818182 0.32872727 0.09053686 0.036     ]\n",
      "regrets is :  [0.         0.28896104 0.         0.21016244 0.172     ] \n",
      "\n",
      "best reward is :  [0.55053686 0.52839161 0.49167464 0.44793388 0.41983471]\n",
      "reward is :  [0.01974026 0.38818182 0.01090909 0.55053686 0.316     ]\n",
      "regrets is :  [ 0.5307966   0.14020979  0.48076555 -0.10260298  0.10383471] \n",
      "\n",
      "best reward is :  [0.83714286 0.51366495 0.51157895 0.49909091 0.47505828]\n",
      "reward is :  [0.17974026 0.2291796  0.01090909 0.27053686 0.1174026 ]\n",
      "regrets is :  [0.6574026  0.28448535 0.50066986 0.22855404 0.35765568] \n",
      "\n",
      "best reward is :  [0.39714286 0.3406993  0.29217716 0.2691796  0.248     ]\n",
      "reward is :  [0.29217716 0.2691796  0.05090909 0.21053686 0.1774026 ]\n",
      "regrets is :  [0.1049657  0.0715197  0.24126807 0.05864274 0.0705974 ] \n",
      "\n",
      "best reward is :  [0.42       0.36408602 0.221      0.18645669 0.18619355]\n",
      "reward is :  [0.08218362 0.003      0.36408602 0.42       0.18619355]\n",
      "regrets is :  [ 0.33781638  0.36108602 -0.14308602 -0.23354331  0.        ] \n",
      "\n",
      "best reward is :  [0.66645669 0.54735484 0.51088288 0.51       0.45558974]\n",
      "reward is :  [0.32388235 0.323      0.02009302 0.24       0.00619355]\n",
      "regrets is :  [0.34257434 0.22435484 0.49078986 0.27       0.4493962 ] \n",
      "\n",
      "best reward is :  [0.36       0.30976271 0.30645669 0.30421622 0.303     ]\n",
      "reward is :  [0.19220662 0.10171429 0.26009302 0.36       0.12619355]\n",
      "regrets is :  [ 0.16779338  0.20804843  0.04636367 -0.05578378  0.17680645] \n",
      "\n",
      "best reward is :  [0.52       0.5024166  0.23731288 0.21325698 0.19865772]\n",
      "reward is :  [0.23731288 0.00454976 0.5024166  0.52       0.1666482 ]\n",
      "regrets is :  [ 0.28268712  0.49786684 -0.26510372 -0.30674302  0.03200952] \n",
      "\n",
      "best reward is :  [0.52       0.41192547 0.32086957 0.2866482  0.18631167]\n",
      "reward is :  [0.41192547 0.00454976 0.52       0.07731288 0.2866482 ]\n",
      "regrets is :  [ 0.10807453  0.4073757  -0.19913043  0.20933532 -0.10033653] \n",
      "\n",
      "best reward is :  [0.44922266 0.41768977 0.39393258 0.39       0.38819672]\n",
      "reward is :  [0.25972603 0.35345912 0.01972603 0.11158672 0.07954802]\n",
      "regrets is :  [0.18949663 0.06423065 0.37420656 0.27841328 0.3086487 ] \n",
      "\n",
      "best reward is :  [0.52679245 0.41972603 0.4167209  0.36895184 0.35588933]\n",
      "reward is :  [0.41972603 0.52679245 0.17972603 0.27158672 0.07954802]\n",
      "regrets is :  [ 0.10706643 -0.10706643  0.23699487  0.09736513  0.27634131] \n",
      "\n",
      "best reward is :  [0.59393258 0.55327189 0.51926606 0.51588933 0.50285714]\n",
      "reward is :  [0.42526316 0.50285714 0.36679245 0.02526316 0.11158672]\n",
      "regrets is :  [0.16866943 0.05041475 0.1524736  0.49062617 0.39127043] \n",
      "\n",
      "best reward is :  [0.4367209  0.40285714 0.38895184 0.38431373 0.38393531]\n",
      "reward is :  [0.34526316 0.38393531 0.18526316 0.40285714 0.27158672]\n",
      "regrets is :  [ 0.09145774  0.01892183  0.20368868 -0.01854342  0.11234859] \n",
      "\n",
      "best reward is :  [0.44800196 0.4367209  0.40285714 0.38895184 0.38431373]\n",
      "reward is :  [0.34526316 0.44800196 0.18526316 0.40285714 0.27158672]\n",
      "regrets is :  [ 0.10273881 -0.01128106  0.21759398 -0.0139053   0.11272701] \n",
      "\n",
      "best reward is :  [0.30041958 0.28923077 0.22835443 0.20581818 0.20149856]\n",
      "reward is :  [0.11097248 0.04298507 0.22835443 0.30041958 0.20581818]\n",
      "regrets is :  [ 0.1894471   0.24624569  0.         -0.0946014  -0.00431962] \n",
      "\n",
      "best reward is :  [0.58666667 0.52256729 0.52025157 0.5191342  0.4732948 ]\n",
      "reward is :  [0.36298507 0.34835443 0.06041958 0.39248485 0.43097248]\n",
      "regrets is :  [0.22368159 0.17421286 0.45983199 0.12664935 0.04232232] \n",
      "\n",
      "best reward is :  [0.63589744 0.59097248 0.53160173 0.52130081 0.50666667]\n",
      "reward is :  [0.36581818 0.39164179 0.06107143 0.38820084 0.19590062]\n",
      "regrets is :  [0.27007925 0.19933069 0.4705303  0.13309998 0.31076605] \n",
      "\n",
      "best reward is :  [0.5677381  0.3318593  0.27093991 0.24549618 0.20820084]\n",
      "reward is :  [0.3318593  0.20820084 0.07457627 0.5677381  0.01590062]\n",
      "regrets is :  [ 0.2358788   0.12365846  0.19636364 -0.32224191  0.19230022] \n",
      "\n",
      "best reward is :  [0.44876033 0.28923077 0.28167024 0.23457627 0.20149856]\n",
      "reward is :  [0.44876033 0.23457627 0.28167024 0.1718593  0.01590062]\n",
      "regrets is :  [0.         0.0546545  0.         0.06271697 0.18559794] \n",
      "\n",
      "best reward is :  [0.29971334 0.20941176 0.20186916 0.18586826 0.18580645]\n",
      "reward is :  [0.18586826 0.29971334 0.20186916 0.20941176 0.18580645]\n",
      "regrets is :  [ 0.11384508 -0.09030158  0.         -0.0235435   0.        ] \n",
      "\n",
      "best reward is :  [0.25711183 0.22222222 0.18734177 0.1404878  0.13153374]\n",
      "reward is :  [0.07257019 0.18734177 0.22222222 0.25711183 0.13153374]\n",
      "regrets is :  [ 0.18454164  0.03488045 -0.03488045 -0.11662403  0.        ] \n",
      "\n",
      "best reward is :  [0.55711712 0.32222222 0.29824    0.2705314  0.23706422]\n",
      "reward is :  [0.02658462 0.32222222 0.07103594 0.22280255 0.55711712]\n",
      "regrets is :  [ 0.5305325   0.          0.22720406  0.04772885 -0.3200529 ] \n",
      "\n",
      "best reward is :  [0.46658462 0.32386473 0.29484277 0.29039755 0.25333333]\n",
      "reward is :  [0.46658462 0.14222222 0.23103594 0.04280255 0.05727273]\n",
      "regrets is :  [0.         0.18164251 0.06380683 0.24759501 0.19606061] \n",
      "\n",
      "best reward is :  [0.28222222 0.25613588 0.18658462 0.13824    0.13727273]\n",
      "reward is :  [0.18658462 0.28222222 0.07804878 0.25613588 0.13727273]\n",
      "regrets is :  [ 0.09563761 -0.02608634  0.10853583 -0.11789588  0.        ] \n",
      "\n",
      "best reward is :  [0.58666667 0.45315406 0.39444947 0.38940117 0.38901961]\n",
      "reward is :  [0.0993218  0.11222936 0.05005348 0.20294118 0.18      ]\n",
      "regrets is :  [0.48734487 0.3409247  0.344396   0.18645999 0.20901961] \n",
      "\n",
      "best reward is :  [0.66823529 0.61333333 0.53490196 0.51231373 0.50823529]\n",
      "reward is :  [0.0993218  0.11222936 0.05005348 0.23627451 0.21333333]\n",
      "regrets is :  [0.56891349 0.50110397 0.48484848 0.27603922 0.29490196] \n",
      "\n",
      "best reward is :  [0.39222936 0.2793218  0.24       0.23005348 0.17486068]\n",
      "reward is :  [0.2793218  0.39222936 0.23005348 0.02294118 0.        ]\n",
      "regrets is :  [ 0.11290756 -0.11290756  0.00994652  0.2071123   0.17486068] \n",
      "\n",
      "best reward is :  [0.52       0.4793218  0.45486068 0.45303167 0.44      ]\n",
      "reward is :  [0.0993218  0.11222936 0.17486068 0.18294118 0.28      ]\n",
      "regrets is :  [0.4206782  0.36709244 0.28       0.2700905  0.16      ] \n",
      "\n",
      "best reward is :  [0.55222936 0.3393218  0.2593218  0.24       0.20778281]\n",
      "reward is :  [0.10016807 0.3393218  0.55222936 0.18294118 0.16      ]\n",
      "regrets is :  [ 0.4520613   0.         -0.29290756  0.05705882  0.04778281] \n",
      "\n",
      "best reward is :  [0.49699208 0.46341463 0.44       0.4        0.38947368]\n",
      "reward is :  [0.03164835 0.17882353 0.25352113 0.18165414 0.46341463]\n",
      "regrets is :  [ 0.46534373  0.2845911   0.18647887  0.21834586 -0.07394095] \n",
      "\n",
      "best reward is :  [0.50165414 0.45333333 0.33612403 0.31164835 0.30724638]\n",
      "reward is :  [0.31164835 0.17371429 0.23215686 0.01352113 0.50165414]\n",
      "regrets is :  [ 0.19000578  0.27961905  0.10396717  0.29812722 -0.19440776] \n",
      "\n",
      "best reward is :  [0.45333333 0.41858586 0.40037559 0.33612403 0.33136612]\n",
      "reward is :  [0.31164835 0.09882353 0.18461538 0.01352113 0.24156863]\n",
      "regrets is :  [0.14168498 0.31976233 0.2157602  0.3226029  0.08979749] \n",
      "\n",
      "best reward is :  [0.44280702 0.43032542 0.4        0.37333333 0.31074321]\n",
      "reward is :  [0.03326733 0.17882353 0.20461538 0.19352113 0.1932948 ]\n",
      "regrets is :  [0.40953969 0.25150189 0.19538462 0.17981221 0.11744842] \n",
      "\n",
      "best reward is :  [0.43326733 0.39982196 0.37348837 0.3627907  0.32      ]\n",
      "reward is :  [0.43326733 0.19882353 0.02461538 0.17352113 0.2132948 ]\n",
      "regrets is :  [0.         0.20099843 0.34887299 0.18926957 0.1067052 ] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best reward is :  [0.33336898 0.3049711  0.24       0.22175439 0.18612245]\n",
      "reward is :  [0.         0.01006993 0.33336898 0.3049711  0.09804511]\n",
      "regrets is :  [ 0.33336898  0.29490117 -0.09336898 -0.08321671  0.08807734] \n",
      "\n",
      "best reward is :  [0.65289617 0.58666667 0.40175439 0.39427293 0.36612245]\n",
      "reward is :  [0.32       0.29006993 0.19336898 0.65289617 0.01804511]\n",
      "regrets is :  [ 0.33289617  0.29659674  0.2083854  -0.25862324  0.34807734] \n",
      "\n",
      "best reward is :  [0.40670232 0.2475841  0.24       0.22175439 0.21831603]\n",
      "reward is :  [0.         0.01177914 0.40670232 0.18622951 0.09804511]\n",
      "regrets is :  [ 0.40670232  0.23580496 -0.16670232  0.03552488  0.12027092] \n",
      "\n",
      "best reward is :  [0.52       0.44790123 0.436778   0.43217877 0.4       ]\n",
      "reward is :  [0.4        0.25177914 0.25506726 0.30735751 0.01804511]\n",
      "regrets is :  [0.12       0.19612209 0.18171073 0.12482126 0.38195489] \n",
      "\n",
      "best reward is :  [0.57217877 0.52       0.46063037 0.45418719 0.44790123]\n",
      "reward is :  [0.39355599 0.39177914 0.39506726 0.30735751 0.01804511]\n",
      "regrets is :  [0.17862278 0.12822086 0.06556311 0.14682968 0.42985612] \n",
      "\n",
      "best reward is :  [0.4289172  0.38569697 0.352      0.29894737 0.28871508]\n",
      "reward is :  [0.18215385 0.         0.22417178 0.38569697 0.4289172 ]\n",
      "regrets is :  [ 0.24676335  0.38569697  0.12782822 -0.0867496  -0.14020211] \n",
      "\n",
      "best reward is :  [0.58485281 0.48932039 0.45403509 0.41894737 0.40350877]\n",
      "reward is :  [0.18341463 0.21333333 0.20948454 0.1        0.29377001]\n",
      "regrets is :  [0.40143818 0.27598706 0.24455055 0.31894737 0.10973876] \n",
      "\n",
      "best reward is :  [0.45333333 0.4289172  0.352      0.29894737 0.28948454]\n",
      "reward is :  [0.24341463 0.         0.28948454 0.45333333 0.4289172 ]\n",
      "regrets is :  [ 0.2099187   0.4289172   0.06251546 -0.15438596 -0.13943266] \n",
      "\n",
      "best reward is :  [0.48349769 0.36341463 0.29439093 0.25272195 0.23333333]\n",
      "reward is :  [0.36341463 0.16       0.29439093 0.23333333 0.48349769]\n",
      "regrets is :  [ 0.12008306  0.20341463  0.          0.01938862 -0.25016436] \n",
      "\n",
      "best reward is :  [0.75918736 0.66435518 0.57894737 0.56560255 0.53738667]\n",
      "reward is :  [0.02341463 0.08768    0.05439093 0.26       0.05067449]\n",
      "regrets is :  [0.73577272 0.57667518 0.52455643 0.30560255 0.48671218] \n",
      "\n",
      "best reward is :  [0.41190083 0.41051095 0.4        0.38760331 0.31330869]\n",
      "reward is :  [0.04043956 0.41051095 0.38760331 0.1220438  0.03173554]\n",
      "regrets is :  [0.37146127 0.         0.01239669 0.26555951 0.28157315] \n",
      "\n",
      "best reward is :  [0.68       0.65586777 0.65586777 0.65460446 0.64914286]\n",
      "reward is :  [0.28043956 0.17051095 0.21045822 0.0420438  0.3784022 ]\n",
      "regrets is :  [0.39956044 0.48535682 0.44540955 0.61256067 0.27074065] \n",
      "\n",
      "best reward is :  [0.60804065 0.58726862 0.58043956 0.52634483 0.48870091]\n",
      "reward is :  [0.58043956 0.01051095 0.05045822 0.0420438  0.47173554]\n",
      "regrets is :  [0.02760109 0.57675767 0.52998134 0.48430103 0.01696537] \n",
      "\n",
      "best reward is :  [0.4        0.37613461 0.37420243 0.36804065 0.36342059]\n",
      "reward is :  [0.01051095 0.05045822 0.2620438  0.21456    0.1877686 ]\n",
      "regrets is :  [0.38948905 0.32567639 0.11215863 0.15348065 0.175652  ] \n",
      "\n",
      "best reward is :  [0.42       0.28804065 0.27420243 0.26726862 0.24789333]\n",
      "reward is :  [0.01051095 0.05045822 0.2020438  0.16       0.24789333]\n",
      "regrets is :  [0.40948905 0.23758243 0.07215863 0.10726862 0.        ] \n",
      "\n",
      "best reward is :  [0.51555556 0.48571429 0.30368461 0.2999613  0.28139545]\n",
      "reward is :  [0.20804576 0.04384342 0.01578947 0.30368461 0.16436019]\n",
      "regrets is :  [ 0.3075098   0.44187087  0.28789514 -0.00372331  0.11703526] \n",
      "\n",
      "best reward is :  [0.51555556 0.48571429 0.36456763 0.2999613  0.28139545]\n",
      "reward is :  [0.20804576 0.04384342 0.01578947 0.36456763 0.16436019]\n",
      "regrets is :  [ 0.3075098   0.44187087  0.34877815 -0.06460633  0.11703526] \n",
      "\n",
      "best reward is :  [0.41472879 0.40456763 0.38468647 0.38222222 0.36473118]\n",
      "reward is :  [0.20804576 0.04384342 0.01578947 0.40456763 0.15102686]\n",
      "regrets is :  [ 0.20668303  0.36072421  0.36889699 -0.02234541  0.21370433] \n",
      "\n",
      "best reward is :  [0.2952381  0.27555556 0.26956879 0.26191781 0.25769352]\n",
      "reward is :  [0.24804576 0.13384342 0.11293233 0.25769352 0.25674877]\n",
      "regrets is :  [0.04719234 0.14171214 0.15663646 0.00422429 0.00094475] \n",
      "\n",
      "best reward is :  [0.62857143 0.55578947 0.54855032 0.52384342 0.51327217]\n",
      "reward is :  [0.09489292 0.24689503 0.32804576 0.52384342 0.55578947]\n",
      "regrets is :  [ 0.53367851  0.30889445  0.22050457  0.         -0.0425173 ] \n",
      "\n",
      "best reward is :  [0.64195599 0.58666667 0.58152905 0.54035088 0.52156863]\n",
      "reward is :  [0.19891892 0.02793651 0.05260274 0.31867299 0.52156863]\n",
      "regrets is :  [0.44303707 0.55873016 0.52892631 0.22167789 0.        ] \n",
      "\n",
      "best reward is :  [0.35779528 0.352      0.25953917 0.22987013 0.22743802]\n",
      "reward is :  [0.352      0.35779528 0.20451253 0.22987013 0.0374026 ]\n",
      "regrets is :  [ 0.00579528 -0.00579528  0.05502664  0.          0.19003542] \n",
      "\n",
      "best reward is :  [0.66222222 0.64       0.5902008  0.5774026  0.53209713]\n",
      "reward is :  [0.04030534 0.18451253 0.432      0.04987013 0.5774026 ]\n",
      "regrets is :  [ 0.62191688  0.45548747  0.1582008   0.52753247 -0.04530547] \n",
      "\n",
      "best reward is :  [0.86222222 0.6555206  0.6374026  0.572      0.54743802]\n",
      "reward is :  [0.04030534 0.18877384 0.572      0.04987013 0.6374026 ]\n",
      "regrets is :  [ 0.82191688  0.46674676  0.0654026   0.52212987 -0.08996458] \n",
      "\n",
      "best reward is :  [0.72       0.64146341 0.55486239 0.54321489 0.51368421]\n",
      "reward is :  [0.04436975 0.0326935  0.64146341 0.21260274 0.42017621]\n",
      "regrets is :  [ 0.67563025  0.60876992 -0.08660103  0.33061215  0.093508  ] \n",
      "\n",
      "best reward is :  [0.35589744 0.34842105 0.33826087 0.27364269 0.26254072]\n",
      "reward is :  [0.26254072 0.25630901 0.09708108 0.12503198 0.13509434]\n",
      "regrets is :  [0.09335672 0.09211204 0.24117979 0.14861071 0.12744638] \n",
      "\n",
      "best reward is :  [0.67286064 0.50697602 0.40374775 0.39630901 0.39390476]\n",
      "reward is :  [0.24254072 0.39630901 0.40374775 0.21836532 0.09509434]\n",
      "regrets is :  [0.43031992 0.11066701 0.         0.1779437  0.29881042] \n",
      "\n",
      "best reward is :  [0.62816542 0.61328205 0.55508772 0.55121423 0.54492754]\n",
      "reward is :  [0.06254072 0.37630901 0.05708108 0.16       0.08503198]\n",
      "regrets is :  [0.5656247  0.23697304 0.49800664 0.39121423 0.45989555] \n",
      "\n",
      "best reward is :  [0.55508772 0.54492754 0.46816542 0.45328205 0.39121423]\n",
      "reward is :  [0.22254072 0.33630901 0.05708108 0.16       0.08645161]\n",
      "regrets is :  [0.332547   0.20861852 0.41108434 0.29328205 0.30476262] \n",
      "\n",
      "best reward is :  [0.69708108 0.3795273  0.36842105 0.35826087 0.34645161]\n",
      "reward is :  [0.34254072 0.21910323 0.69708108 0.16       0.34645161]\n",
      "regrets is :  [ 0.35454036  0.16042407 -0.32866003  0.19826087  0.        ] \n",
      "\n",
      "best reward is :  [0.36561404 0.26833496 0.24771574 0.22209446 0.21490909]\n",
      "reward is :  [0.1957377  0.05376782 0.36561404 0.21490909 0.08225214]\n",
      "regrets is :  [ 0.16987633  0.21456714 -0.1178983   0.00718536  0.13265695] \n",
      "\n",
      "best reward is :  [0.53376782 0.43685504 0.30232558 0.26493506 0.26225214]\n",
      "reward is :  [0.0157377  0.53376782 0.01894737 0.26225214 0.03490909]\n",
      "regrets is :  [ 0.51803012 -0.09691278  0.28337821  0.00268292  0.22734305] \n",
      "\n",
      "best reward is :  [0.38907104 0.23529412 0.23443223 0.22080614 0.19130435]\n",
      "reward is :  [0.38907104 0.22080614 0.23443223 0.09411765 0.11490909]\n",
      "regrets is :  [0.         0.01448798 0.         0.12668849 0.07639526] \n",
      "\n",
      "best reward is :  [0.50380165 0.4343824  0.40876112 0.38745098 0.35856749]\n",
      "reward is :  [0.38745098 0.22907104 0.06080614 0.1610989  0.24824242]\n",
      "regrets is :  [0.11635067 0.20531136 0.34795498 0.22635208 0.11032507] \n",
      "\n",
      "best reward is :  [0.59685504 0.5752381  0.56493506 0.52899225 0.51710145]\n",
      "reward is :  [0.02594595 0.0157377  0.22080614 0.1810989  0.19934426]\n",
      "regrets is :  [0.57090909 0.55950039 0.34412892 0.34789335 0.31775719] \n",
      "\n",
      "best reward is :  [0.47027027 0.44       0.35766423 0.30503597 0.28      ]\n",
      "reward is :  [0.05048544 0.04888889 0.03512195 0.20380228 0.11439252]\n",
      "regrets is :  [0.41978483 0.39111111 0.32254228 0.10123369 0.16560748] \n",
      "\n",
      "best reward is :  [0.50117647 0.4036036  0.37333333 0.34852321 0.33333333]\n",
      "reward is :  [0.05048544 0.14888889 0.03512195 0.20987013 0.11439252]\n",
      "regrets is :  [0.45069103 0.25471471 0.33821138 0.13865308 0.21894081] \n",
      "\n",
      "best reward is :  [0.53693694 0.50666667 0.39766423 0.36784314 0.31518987]\n",
      "reward is :  [0.05048544 0.12888889 0.03512195 0.20987013 0.11439252]\n",
      "regrets is :  [0.4864515  0.37777778 0.36254228 0.15797301 0.20079735] \n",
      "\n",
      "best reward is :  [0.64       0.62105919 0.58       0.55111111 0.52784314]\n",
      "reward is :  [0.29048544 0.28888889 0.43512195 0.22987013 0.62105919]\n",
      "regrets is :  [ 0.34951456  0.3321703   0.14487805  0.32124098 -0.09321605] \n",
      "\n",
      "best reward is :  [0.52       0.49048544 0.48585366 0.45309091 0.42503597]\n",
      "reward is :  [0.11555556 0.35512195 0.48585366 0.32987013 0.28      ]\n",
      "regrets is :  [0.40444444 0.13536349 0.         0.12322078 0.14503597] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best reward is :  [0.83263158 0.44571429 0.41032258 0.31924528 0.31441441]\n",
      "reward is :  [0.17704918 0.83263158 0.27766323 0.25789474 0.31441441]\n",
      "regrets is :  [ 0.6555824  -0.38691729  0.13265935  0.06135055  0.        ] \n",
      "\n",
      "best reward is :  [0.61704918 0.53391304 0.52615385 0.40255319 0.4       ]\n",
      "reward is :  [0.61704918 0.0643299  0.27789474 0.04108108 0.23714286]\n",
      "regrets is :  [0.         0.46958315 0.24825911 0.36147211 0.16285714] \n",
      "\n",
      "best reward is :  [0.72       0.46526912 0.4637037  0.45864078 0.44313656]\n",
      "reward is :  [0.72       0.04781609 0.42831858 0.03402985 0.2088826 ]\n",
      "regrets is :  [0.         0.41745303 0.03538512 0.42461093 0.23425396] \n",
      "\n",
      "best reward is :  [0.76487805 0.69308057 0.55703704 0.50822795 0.50105263]\n",
      "reward is :  [0.4        0.26114943 0.18831858 0.24736318 0.0488826 ]\n",
      "regrets is :  [0.36487805 0.43193114 0.36871845 0.26086476 0.45217003] \n",
      "\n",
      "best reward is :  [0.55629139 0.53592233 0.52       0.51728155 0.44245333]\n",
      "reward is :  [0.52       0.04781609 0.20831858 0.03402985 0.1288826 ]\n",
      "regrets is :  [0.03629139 0.48810624 0.31168142 0.4832517  0.31357073] \n",
      "\n",
      "best reward is :  [0.3981253  0.3963339  0.3913253  0.38569385 0.3763522 ]\n",
      "reward is :  [0.344      0.22845806 0.01207547 0.25266491 0.2152059 ]\n",
      "regrets is :  [0.0541253  0.16787584 0.37924983 0.13302894 0.16114631] \n",
      "\n",
      "best reward is :  [0.49233405 0.48186528 0.464      0.38840529 0.38465409]\n",
      "reward is :  [0.464      0.38840529 0.01203762 0.19262327 0.48186528]\n",
      "regrets is :  [ 0.02833405  0.09345999  0.45196238  0.19578202 -0.0972112 ] \n",
      "\n",
      "best reward is :  [0.41203762 0.34933786 0.344      0.33014085 0.32191108]\n",
      "reward is :  [0.344      0.01648069 0.41203762 0.01262327 0.16355995]\n",
      "regrets is :  [ 0.06803762  0.33285717 -0.06803762  0.31751757  0.15835113] \n",
      "\n",
      "best reward is :  [0.50289608 0.49789614 0.483      0.48188051 0.48      ]\n",
      "reward is :  [0.344      0.25642429 0.012      0.19258191 0.0835468 ]\n",
      "regrets is :  [0.15889608 0.24147184 0.471      0.2892986  0.3964532 ] \n",
      "\n",
      "best reward is :  [0.3758263  0.36221742 0.35674667 0.35511737 0.34856927]\n",
      "reward is :  [0.184      0.29636829 0.29196262 0.01254082 0.00353374]\n",
      "regrets is :  [0.1918263  0.06584914 0.06478405 0.34257655 0.34503553] \n",
      "\n",
      "best reward is :  [0.43766423 0.39258216 0.38546685 0.37333333 0.368125  ]\n",
      "reward is :  [0.30352941 0.19617978 0.16989691 0.20171244 0.33617978]\n",
      "regrets is :  [0.13413482 0.19640238 0.21556994 0.17162089 0.03194522] \n",
      "\n",
      "best reward is :  [0.416      0.41495119 0.39333333 0.38989691 0.38795699]\n",
      "reward is :  [0.18352941 0.18064516 0.38989691 0.18171244 0.01617978]\n",
      "regrets is :  [0.23247059 0.23430602 0.00343643 0.20818447 0.37177721] \n",
      "\n",
      "best reward is :  [0.40933333 0.40828452 0.38129032 0.37052632 0.35345794]\n",
      "reward is :  [0.02352941 0.02064516 0.24989691 0.02171244 0.01617978]\n",
      "regrets is :  [0.38580392 0.38763936 0.13139342 0.34881388 0.33727817] \n",
      "\n",
      "best reward is :  [0.50352941 0.47766423 0.42171244 0.42064516 0.35522936]\n",
      "reward is :  [0.01682805 0.50352941 0.42064516 0.42171244 0.33617978]\n",
      "regrets is :  [ 0.48670137 -0.02586518  0.00106728 -0.00106728  0.01904958] \n",
      "\n",
      "best reward is :  [0.416      0.41495119 0.39333333 0.38795699 0.37854859]\n",
      "reward is :  [0.18352941 0.31153285 0.33682805 0.18064516 0.18629108]\n",
      "regrets is :  [0.23247059 0.10341834 0.05650529 0.20731183 0.19225751] \n",
      "\n",
      "best reward is :  [0.63037975 0.55282051 0.51701149 0.47870968 0.46848921]\n",
      "reward is :  [0.02086957 0.11052632 0.03956044 0.63037975 0.28285714]\n",
      "regrets is :  [ 0.60951018  0.4422942   0.47745105 -0.15167007  0.18563207] \n",
      "\n",
      "best reward is :  [0.50622711 0.48753623 0.27586207 0.2725     0.26723404]\n",
      "reward is :  [0.26666667 0.48753623 0.50622711 0.19529412 0.04285714]\n",
      "regrets is :  [ 0.23956044  0.         -0.23036504  0.07720588  0.2243769 ] \n",
      "\n",
      "best reward is :  [0.44996564 0.42974359 0.33701149 0.27586207 0.2725    ]\n",
      "reward is :  [0.33701149 0.42974359 0.44996564 0.19529412 0.04285714]\n",
      "regrets is :  [ 0.11295414  0.         -0.11295414  0.08056795  0.22964286] \n",
      "\n",
      "best reward is :  [0.68117647 0.605      0.52285714 0.476      0.4496    ]\n",
      "reward is :  [0.10034483 0.02307692 0.04329897 0.35529412 0.52285714]\n",
      "regrets is :  [ 0.58083164  0.58192308  0.47955817  0.12070588 -0.07325714] \n",
      "\n",
      "best reward is :  [0.46252874 0.45390071 0.41252033 0.35626667 0.34666667]\n",
      "reward is :  [0.05034483 0.18307692 0.20329897 0.27956044 0.28285714]\n",
      "regrets is :  [0.41218391 0.27082379 0.20922136 0.07670623 0.06380952] \n",
      "\n",
      "End of the simulations, time elapsed: 84.772 seconds.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "regret, regrets, rewards, regrets_normal = run_several_experiments_hist_ML(LinearRegression, nb_exp = 20, \n",
    "                                                                           evolutive_env = True, nb_steps_history=1000)\n",
    "plot_regret(regret, regrets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation 0 started, time elapsed: 0.000 seconds.\n",
      "best reward is :  [0.44966156 0.31078717 0.31045062 0.30823529 0.28655738]\n",
      "reward is :  [0.44966156 0.18745098 0.17098901 0.21678264 0.13977813]\n",
      "regrets is :  [0.         0.12333619 0.13946161 0.09145266 0.14677925] \n",
      "\n",
      "best reward is :  [0.39411765 0.31997226 0.29115646 0.24470588 0.24170213]\n",
      "reward is :  [0.39411765 0.29115646 0.07636364 0.02677291 0.20862385]\n",
      "regrets is :  [0.         0.0288158  0.21479283 0.21793297 0.03307827] \n",
      "\n",
      "best reward is :  [0.61711729 0.59322404 0.5752381  0.53745384 0.53638803]\n",
      "reward is :  [0.01411765 0.2244898  0.45636364 0.30677291 0.02862385]\n",
      "regrets is :  [0.60299964 0.36873425 0.11887446 0.23068093 0.50776418] \n",
      "\n",
      "best reward is :  [0.64166667 0.61636364 0.55510669 0.5480315  0.50666667]\n",
      "reward is :  [0.17411765 0.13115646 0.61636364 0.46677291 0.18862385]\n",
      "regrets is :  [ 0.46754902  0.48520717 -0.06125695  0.08125859  0.31804281] \n",
      "\n",
      "best reward is :  [0.32       0.27045062 0.25411765 0.24655738 0.22857143]\n",
      "reward is :  [0.25411765 0.32       0.13115646 0.0280292  0.10862385]\n",
      "regrets is :  [ 0.06588235 -0.04954938  0.12296118  0.21852818  0.11994758] \n",
      "\n",
      "best reward is :  [0.46816327 0.46388732 0.455      0.44149533 0.43707317]\n",
      "reward is :  [0.01476923 0.03518325 0.46816327 0.2016185  0.04732394]\n",
      "regrets is :  [ 0.45339403  0.42870408 -0.01316327  0.23987683  0.38974923] \n",
      "\n",
      "best reward is :  [0.53055399 0.50816199 0.40768362 0.40385816 0.36816327]\n",
      "reward is :  [0.17476923 0.31518325 0.36816327 0.0416185  0.04732394]\n",
      "regrets is :  [0.35578476 0.19297875 0.03952035 0.36223966 0.32083932] \n",
      "\n",
      "best reward is :  [0.73230769 0.69055399 0.66816199 0.56768362 0.56385816]\n",
      "reward is :  [0.01476923 0.03518325 0.73230769 0.0416185  0.20732394]\n",
      "regrets is :  [ 0.71753846  0.65537074 -0.0641457   0.52606512  0.35653421] \n",
      "\n",
      "best reward is :  [0.82388732 0.7620339  0.53071038 0.52645161 0.43333333]\n",
      "reward is :  [0.29476923 0.21518325 0.096      0.41495183 0.26065728]\n",
      "regrets is :  [0.52911809 0.54685065 0.43471038 0.11149978 0.17267606] \n",
      "\n",
      "best reward is :  [0.66388732 0.64149533 0.54101695 0.53719149 0.49995699]\n",
      "reward is :  [0.49995699 0.19518325 0.44266667 0.04948454 0.16732394]\n",
      "regrets is :  [0.16393033 0.44631208 0.09835028 0.48770695 0.33263305] \n",
      "\n",
      "best reward is :  [0.51134021 0.49971831 0.475      0.46208589 0.45204301]\n",
      "reward is :  [0.51134021 0.32089941 0.02382134 0.27654676 0.42721311]\n",
      "regrets is :  [0.         0.1788189  0.45117866 0.18553913 0.0248299 ] \n",
      "\n",
      "best reward is :  [0.39654676 0.37971831 0.34848989 0.34625767 0.33030568]\n",
      "reward is :  [0.11294118 0.205      0.18382134 0.39654676 0.20721311]\n",
      "regrets is :  [ 0.28360559  0.17471831  0.16466855 -0.05028909  0.12309256] \n",
      "\n",
      "best reward is :  [0.50848989 0.50625767 0.49030568 0.48056338 0.47280182]\n",
      "reward is :  [0.27294118 0.045      0.46382134 0.39654676 0.04721311]\n",
      "regrets is :  [0.23554872 0.46125767 0.02648434 0.08401662 0.42558871] \n",
      "\n",
      "best reward is :  [0.51294118 0.475      0.37971831 0.34208589 0.33204301]\n",
      "reward is :  [0.51294118 0.205      0.02729858 0.27654676 0.28721311]\n",
      "regrets is :  [0.         0.27       0.35241973 0.06553913 0.0448299 ] \n",
      "\n",
      "best reward is :  [0.64682772 0.55654676 0.35007833 0.34848989 0.22625767]\n",
      "reward is :  [0.64682772 0.11449857 0.045      0.18729858 0.55654676]\n",
      "regrets is :  [ 0.          0.4420482   0.30507833  0.16119131 -0.33028909] \n",
      "\n",
      "best reward is :  [0.47083333 0.44179245 0.40649123 0.40105263 0.39840796]\n",
      "reward is :  [0.18033898 0.07254545 0.05538462 0.40649123 0.01534884]\n",
      "regrets is :  [ 0.29049435  0.369247    0.35110661 -0.0054386   0.38305912] \n",
      "\n",
      "best reward is :  [0.55254545 0.4        0.37052632 0.33534884 0.32      ]\n",
      "reward is :  [0.02033898 0.55254545 0.29538462 0.03315789 0.33534884]\n",
      "regrets is :  [ 0.53220647 -0.15254545  0.0751417   0.30219094 -0.01534884] \n",
      "\n",
      "best reward is :  [0.48035242 0.35534884 0.33538462 0.3        0.29052632]\n",
      "reward is :  [0.02033898 0.48035242 0.33538462 0.03315789 0.35534884]\n",
      "regrets is :  [ 0.46001344 -0.12500359  0.          0.26684211 -0.06482252] \n",
      "\n",
      "best reward is :  [0.60416667 0.54179245 0.53192982 0.53174129 0.50105263]\n",
      "reward is :  [0.26727273 0.08035242 0.05538462 0.27315789 0.01534884]\n",
      "regrets is :  [0.33689394 0.46144003 0.47654521 0.2585834  0.48570379] \n",
      "\n",
      "best reward is :  [0.60416667 0.54179245 0.53192982 0.53174129 0.50105263]\n",
      "reward is :  [0.26727273 0.08035242 0.05538462 0.27315789 0.01534884]\n",
      "regrets is :  [0.33689394 0.46144003 0.47654521 0.2585834  0.48570379] \n",
      "\n",
      "best reward is :  [0.48       0.46535552 0.46532544 0.33907285 0.33696113]\n",
      "reward is :  [0.33696113 0.33907285 0.17078652 0.24516129 0.46532544]\n",
      "regrets is :  [ 0.14303887  0.12628267  0.29453893  0.09391156 -0.12836431] \n",
      "\n",
      "best reward is :  [0.42       0.4062069  0.4053717  0.40535552 0.34666667]\n",
      "reward is :  [0.17696113 0.17907285 0.17078652 0.24680486 0.4062069 ]\n",
      "regrets is :  [ 0.24303887  0.22713405  0.23458519  0.15855066 -0.05954023] \n",
      "\n",
      "best reward is :  [0.44802228 0.43347153 0.40133591 0.4        0.38981273]\n",
      "reward is :  [0.         0.01696113 0.08136499 0.0662069  0.43347153]\n",
      "regrets is :  [ 0.44802228  0.4165104   0.31997093  0.3337931  -0.04365879] \n",
      "\n",
      "best reward is :  [0.57287356 0.44       0.43148995 0.42       0.40535552]\n",
      "reward is :  [0.44       0.29696113 0.30136499 0.2483682  0.57287356]\n",
      "regrets is :  [ 0.13287356  0.14303887  0.13012497  0.1716318  -0.16751804] \n",
      "\n",
      "best reward is :  [0.68       0.49870504 0.45811321 0.44774194 0.44      ]\n",
      "reward is :  [0.36085106 0.38730964 0.26136499 0.22703911 0.0883682 ]\n",
      "regrets is :  [0.31914894 0.11139539 0.19674822 0.22070283 0.3516318 ] \n",
      "\n",
      "best reward is :  [0.38516934 0.38378378 0.38352941 0.36504348 0.35782946]\n",
      "reward is :  [0.05448649 0.2        0.33189189 0.02774566 0.2       ]\n",
      "regrets is :  [0.33068285 0.18378378 0.05163752 0.33729781 0.15782946] \n",
      "\n",
      "best reward is :  [0.56298667 0.54352941 0.51782946 0.42378378 0.41813953]\n",
      "reward is :  [0.21448649 0.04       0.21189189 0.18774566 0.04      ]\n",
      "regrets is :  [0.34850018 0.50352941 0.30593757 0.23603812 0.37813953] \n",
      "\n",
      "best reward is :  [0.52       0.40621514 0.3740836  0.36786632 0.35632   ]\n",
      "reward is :  [0.33448649 0.08       0.09189189 0.32774566 0.18      ]\n",
      "regrets is :  [0.18551351 0.32621514 0.28219171 0.04012066 0.17632   ] \n",
      "\n",
      "best reward is :  [0.54516934 0.45684211 0.42378378 0.42352941 0.4       ]\n",
      "reward is :  [0.21448649 0.04114286 0.33189189 0.18851485 0.04      ]\n",
      "regrets is :  [0.33068285 0.41569925 0.09189189 0.23501456 0.36      ] \n",
      "\n",
      "best reward is :  [0.52       0.42075027 0.41453299 0.40621514 0.39855856]\n",
      "reward is :  [0.33448649 0.22114286 0.21189189 0.10851485 0.22      ]\n",
      "regrets is :  [0.18551351 0.19960741 0.2026411  0.29770029 0.17855856] \n",
      "\n",
      "best reward is :  [0.53956204 0.42211982 0.3847619  0.26171733 0.24847373]\n",
      "reward is :  [0.42211982 0.20597968 0.02226804 0.24847373 0.53956204]\n",
      "regrets is :  [ 0.11744223  0.21614013  0.36249386  0.01324361 -0.29108832] \n",
      "\n",
      "best reward is :  [0.42709677 0.3443609  0.34226804 0.32865672 0.3193921 ]\n",
      "reward is :  [0.3443609  0.12262958 0.31520981 0.34226804 0.21051767]\n",
      "regrets is :  [ 0.08273587  0.22173132  0.02705823 -0.01361132  0.10887443] \n",
      "\n",
      "best reward is :  [0.5443609  0.53284848 0.40568421 0.36823305 0.36464548]\n",
      "reward is :  [0.02548673 0.10854314 0.5443609  0.30330097 0.25051767]\n",
      "regrets is :  [ 0.51887418  0.42430534 -0.13867669  0.06493208  0.11412781] \n",
      "\n",
      "best reward is :  [0.52493942 0.49051767 0.46709677 0.46422018 0.36865672]\n",
      "reward is :  [0.02548673 0.20854314 0.52493942 0.46422018 0.49051767]\n",
      "regrets is :  [ 0.4994527   0.28197453 -0.05784265  0.         -0.12186095] \n",
      "\n",
      "best reward is :  [0.45097931 0.35142857 0.34548673 0.30709677 0.28139279]\n",
      "reward is :  [0.34548673 0.45097931 0.28139279 0.18422018 0.09051767]\n",
      "regrets is :  [ 0.10549258 -0.09955074  0.06409393  0.12287659  0.19087513] \n",
      "\n",
      "best reward is :  [0.56       0.54352941 0.48235294 0.48235294 0.48173913]\n",
      "reward is :  [0.03368421 0.20507042 0.25       0.0702439  0.02086957]\n",
      "regrets is :  [0.52631579 0.33845899 0.23235294 0.41210904 0.46086957] \n",
      "\n",
      "best reward is :  [0.46083333 0.45333333 0.43487179 0.41333333 0.41078014]\n",
      "reward is :  [0.03368421 0.04507042 0.19       0.0702439  0.02086957]\n",
      "regrets is :  [0.42714912 0.40826291 0.24487179 0.34308943 0.38991058] \n",
      "\n",
      "best reward is :  [0.45333333 0.44568116 0.41333333 0.41078014 0.38133333]\n",
      "reward is :  [0.03368421 0.04507042 0.19777778 0.0702439  0.02086957]\n",
      "regrets is :  [0.41964912 0.40061074 0.21555556 0.34053624 0.36046377] \n",
      "\n",
      "best reward is :  [0.45333333 0.35777778 0.31686275 0.28568116 0.26133333]\n",
      "reward is :  [0.19368421 0.04507042 0.35777778 0.2302439  0.18086957]\n",
      "regrets is :  [ 0.25964912  0.31270736 -0.04091503  0.05543726  0.08046377] \n",
      "\n",
      "best reward is :  [0.65777778 0.58666667 0.45686534 0.4559487  0.39466667]\n",
      "reward is :  [0.19368421 0.04507042 0.65777778 0.2302439  0.18086957]\n",
      "regrets is :  [ 0.46409357  0.54159624 -0.20091244  0.2257048   0.2137971 ] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best reward is :  [0.35764706 0.29345794 0.29156627 0.29090909 0.25707865]\n",
      "reward is :  [0.25707865 0.29345794 0.29090909 0.35764706 0.18440678]\n",
      "regrets is :  [ 0.10056841  0.          0.00065717 -0.06673797  0.07267187] \n",
      "\n",
      "best reward is :  [0.41098039 0.29090909 0.25707865 0.22798982 0.21333333]\n",
      "reward is :  [0.25707865 0.22798982 0.29090909 0.41098039 0.18865672]\n",
      "regrets is :  [ 0.15390174  0.06291927 -0.03383044 -0.18299057  0.02467662] \n",
      "\n",
      "best reward is :  [0.47913043 0.41090909 0.40449799 0.38363636 0.36931298]\n",
      "reward is :  [0.47913043 0.41090909 0.04363636 0.20865672 0.048     ]\n",
      "regrets is :  [0.         0.         0.36086163 0.17497965 0.32131298] \n",
      "\n",
      "best reward is :  [0.57090909 0.45652582 0.39916667 0.39848101 0.36823529]\n",
      "reward is :  [0.01142857 0.57090909 0.20285714 0.36823529 0.01142857]\n",
      "regrets is :  [ 0.55948052 -0.11438327  0.19630952  0.03024572  0.35680672] \n",
      "\n",
      "best reward is :  [0.39466667 0.39142857 0.34666667 0.22705882 0.20285714]\n",
      "reward is :  [0.39142857 0.13090909 0.39466667 0.02823529 0.19142857]\n",
      "regrets is :  [ 0.0032381   0.26051948 -0.048       0.19882353  0.01142857] \n",
      "\n",
      "best reward is :  [0.57066667 0.52682569 0.50971429 0.49715663 0.46833898]\n",
      "reward is :  [0.23606349 0.036      0.0558806  0.18618182 0.436     ]\n",
      "regrets is :  [0.33460317 0.49082569 0.45383369 0.31097481 0.03233898] \n",
      "\n",
      "best reward is :  [0.72       0.63977591 0.61333333 0.5969637  0.53409524]\n",
      "reward is :  [0.1471746  0.416      0.3358806  0.34618182 0.196     ]\n",
      "regrets is :  [0.5728254  0.22377591 0.27745274 0.25078188 0.33809524] \n",
      "\n",
      "best reward is :  [0.77310924 0.58666667 0.48       0.46933333 0.46363036]\n",
      "reward is :  [0.10364444 0.316      0.4034554  0.36953846 0.196     ]\n",
      "regrets is :  [0.6694648  0.27066667 0.0765446  0.09979487 0.26763036] \n",
      "\n",
      "best reward is :  [0.50870922 0.436      0.39466667 0.39333333 0.37678873]\n",
      "reward is :  [0.3692     0.436      0.37678873 0.312      0.04266667]\n",
      "regrets is :  [0.13950922 0.         0.01787793 0.08133333 0.33412207] \n",
      "\n",
      "best reward is :  [0.56       0.45333333 0.4369637  0.41866667 0.41006289]\n",
      "reward is :  [0.14808889 0.28266667 0.33678873 0.31388235 0.04266667]\n",
      "regrets is :  [0.41191111 0.17066667 0.10017496 0.10478431 0.36739623] \n",
      "\n",
      "best reward is :  [0.52758621 0.43232136 0.41364341 0.40555143 0.39774436]\n",
      "reward is :  [0.41364341 0.18466718 0.30630137 0.38677809 0.19443609]\n",
      "regrets is :  [0.1139428  0.24765418 0.10734204 0.01877334 0.20330827] \n",
      "\n",
      "best reward is :  [0.65364341 0.54466718 0.53894945 0.52565469 0.49888476]\n",
      "reward is :  [0.65364341 0.42630137 0.44664701 0.45443609 0.18410042]\n",
      "regrets is :  [0.         0.11836581 0.09230245 0.0712186  0.31478434] \n",
      "\n",
      "best reward is :  [0.41656958 0.40092098 0.37764706 0.3774359  0.36385337]\n",
      "reward is :  [0.33632653 0.02630137 0.0417942  0.01443609 0.08565469]\n",
      "regrets is :  [0.08024305 0.37461961 0.33585286 0.36299981 0.27819867] \n",
      "\n",
      "best reward is :  [0.62758621 0.49774436 0.49632653 0.4916129  0.47945205]\n",
      "reward is :  [0.49632653 0.26630137 0.3217942  0.17443609 0.33888476]\n",
      "regrets is :  [0.13125968 0.23144299 0.17453234 0.31717681 0.1405673 ] \n",
      "\n",
      "best reward is :  [0.54990291 0.53425432 0.49315068 0.41098039 0.39052003]\n",
      "reward is :  [0.17894207 0.02630137 0.0417942  0.01568627 0.05888476]\n",
      "regrets is :  [0.37096085 0.50795295 0.45135649 0.39529412 0.33163528] \n",
      "\n",
      "best reward is :  [0.75452865 0.41522013 0.39231198 0.39038589 0.32099644]\n",
      "reward is :  [0.75452865 0.39038589 0.16666667 0.41522013 0.19761194]\n",
      "regrets is :  [ 0.          0.02483424  0.22564531 -0.02483424  0.1233845 ] \n",
      "\n",
      "best reward is :  [0.63537906 0.55038589 0.41817097 0.39231198 0.32099644]\n",
      "reward is :  [0.63537906 0.55038589 0.28666667 0.41817097 0.19761194]\n",
      "regrets is :  [ 0.          0.          0.13150431 -0.025859    0.1233845 ] \n",
      "\n",
      "best reward is :  [0.67761194 0.56169851 0.54766311 0.51844581 0.50666667]\n",
      "reward is :  [0.23619048 0.07202572 0.00666667 0.04083176 0.67761194]\n",
      "regrets is :  [ 0.44142146  0.48967279  0.54099644  0.47761405 -0.17094527] \n",
      "\n",
      "best reward is :  [0.59959596 0.58       0.57312289 0.54126126 0.53072682]\n",
      "reward is :  [0.07619048 0.23202572 0.00666667 0.20083176 0.20099644]\n",
      "regrets is :  [0.52340548 0.34797428 0.56645622 0.3404295  0.32973038] \n",
      "\n",
      "best reward is :  [0.55202572 0.47619048 0.44083176 0.43231198 0.4       ]\n",
      "reward is :  [0.47619048 0.55202572 0.28666667 0.44083176 0.04099644]\n",
      "regrets is :  [ 0.07583525 -0.07583525  0.15416509 -0.00851978  0.35900356] \n",
      "\n",
      "best reward is :  [0.6        0.41563672 0.29258427 0.27724518 0.24783734]\n",
      "reward is :  [0.41563672 0.6        0.29258427 0.17116279 0.02456693]\n",
      "regrets is :  [ 0.18436328 -0.18436328  0.          0.10608239  0.22327041] \n",
      "\n",
      "best reward is :  [0.56666667 0.30068627 0.25253731 0.24115942 0.19546875]\n",
      "reward is :  [0.19546875 0.56666667 0.25253731 0.01111111 0.02447059]\n",
      "regrets is :  [ 0.37119792 -0.26598039  0.          0.23004831  0.17099816] \n",
      "\n",
      "best reward is :  [0.46396369 0.36096454 0.30760694 0.28678652 0.28096   ]\n",
      "reward is :  [0.46396369 0.36096454 0.17311475 0.17662992 0.02810811]\n",
      "regrets is :  [0.         0.         0.13449218 0.1101566  0.25285189] \n",
      "\n",
      "best reward is :  [0.34396369 0.31429787 0.30760694 0.29662992 0.29311475]\n",
      "reward is :  [0.29662992 0.34396369 0.31429787 0.29311475 0.02810811]\n",
      "regrets is :  [ 0.04733377 -0.02966582 -0.00669094  0.00351517  0.26500665] \n",
      "\n",
      "best reward is :  [0.67177305 0.64       0.61333333 0.56528268 0.52652874]\n",
      "reward is :  [0.01662992 0.02396369 0.01471264 0.48810811 0.21940928]\n",
      "regrets is :  [0.65514313 0.61603631 0.59862069 0.07717457 0.30711945] \n",
      "\n",
      "best reward is :  [0.47818182 0.44259542 0.4        0.38965517 0.38965517]\n",
      "reward is :  [0.47818182 0.22857143 0.06857143 0.23011236 0.25509434]\n",
      "regrets is :  [0.         0.21402399 0.33142857 0.15954281 0.13456083] \n",
      "\n",
      "best reward is :  [0.74666667 0.66416667 0.638753   0.60857143 0.57939439]\n",
      "reward is :  [0.25411765 0.60857143 0.22857143 0.57939439 0.43509434]\n",
      "regrets is :  [0.49254902 0.05559524 0.41018157 0.02917704 0.14430005] \n",
      "\n",
      "best reward is :  [0.62       0.53058693 0.46313253 0.39068413 0.38089888]\n",
      "reward is :  [0.62       0.27135678 0.46313253 0.31135678 0.21913043]\n",
      "regrets is :  [0.         0.25923015 0.         0.07932735 0.16176844] \n",
      "\n",
      "best reward is :  [0.74259542 0.50181818 0.48       0.42298851 0.42298851]\n",
      "reward is :  [0.23011236 0.072      0.23148936 0.02181818 0.31931034]\n",
      "regrets is :  [0.51248306 0.42981818 0.24851064 0.40117032 0.10367816] \n",
      "\n",
      "best reward is :  [0.55960784 0.512      0.50416667 0.48657718 0.45011236]\n",
      "reward is :  [0.45011236 0.512      0.23148936 0.17931034 0.18181818]\n",
      "regrets is :  [0.10949548 0.         0.2726773  0.30726684 0.26829418] \n",
      "\n",
      "best reward is :  [0.57039484 0.50351607 0.49451292 0.41255501 0.36377358]\n",
      "reward is :  [0.49451292 0.05488127 0.57039484 0.05082353 0.08690461]\n",
      "regrets is :  [ 0.07588192  0.4486348  -0.07588192  0.36173148  0.27686898] \n",
      "\n",
      "best reward is :  [0.52690461 0.51405128 0.51398693 0.49543199 0.44984424]\n",
      "reward is :  [0.27553816 0.49543199 0.01548387 0.29082353 0.52690461]\n",
      "regrets is :  [ 0.25136645  0.01861929  0.49850306  0.20460846 -0.07706037] \n",
      "\n",
      "best reward is :  [0.62690461 0.49475285 0.45595337 0.45300813 0.44738462]\n",
      "reward is :  [0.27553816 0.45595337 0.01548387 0.49475285 0.62690461]\n",
      "regrets is :  [ 0.35136645  0.03879948  0.4404695  -0.04174472 -0.17951999] \n",
      "\n",
      "best reward is :  [0.53595337 0.28317757 0.25942197 0.24690461 0.24      ]\n",
      "reward is :  [0.11553816 0.53595337 0.17548387 0.23845018 0.24690461]\n",
      "regrets is :  [ 0.42041521 -0.2527758   0.08393809  0.00845442 -0.00690461] \n",
      "\n",
      "best reward is :  [0.48608696 0.44317757 0.40860215 0.39248292 0.36690461]\n",
      "reward is :  [0.11553816 0.33644769 0.0185209  0.40860215 0.36690461]\n",
      "regrets is :  [ 0.3705488   0.10672988  0.39008125 -0.01611923  0.        ] \n",
      "\n",
      "best reward is :  [0.48857143 0.44331096 0.42       0.35972028 0.35021277]\n",
      "reward is :  [0.48857143 0.28247788 0.44331096 0.04834532 0.33207373]\n",
      "regrets is :  [ 0.          0.16083309 -0.02331096  0.31137496  0.01813903] \n",
      "\n",
      "best reward is :  [0.51687943 0.48857143 0.47972028 0.44809339 0.42247788]\n",
      "reward is :  [0.48857143 0.42247788 0.3966443  0.04834532 0.33494357]\n",
      "regrets is :  [0.028308   0.06609355 0.08307598 0.39974806 0.08753431] \n",
      "\n",
      "best reward is :  [0.5766443  0.45333333 0.43972028 0.40809339 0.39457227]\n",
      "reward is :  [0.25297297 0.21106383 0.         0.5766443  0.04834532]\n",
      "regrets is :  [ 0.32367132  0.2422695   0.43972028 -0.16855091  0.34622695] \n",
      "\n",
      "best reward is :  [0.35972028 0.32809339 0.27032836 0.26167866 0.24      ]\n",
      "reward is :  [0.01297297 0.18       0.05106383 0.16162866 0.26167866]\n",
      "regrets is :  [ 0.34674731  0.14809339  0.21926453  0.10004999 -0.02167866] \n",
      "\n",
      "best reward is :  [0.64162866 0.45333333 0.43972028 0.40809339 0.39457227]\n",
      "reward is :  [0.25297297 0.         0.21106383 0.64162866 0.05189189]\n",
      "regrets is :  [ 0.38865569  0.45333333  0.22865645 -0.23353528  0.34268038] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best reward is :  [0.55748879 0.528      0.44462585 0.39632184 0.37635739]\n",
      "reward is :  [0.55748879 0.20777251 0.23882698 0.528      0.0346988 ]\n",
      "regrets is :  [ 0.          0.32022749  0.20579887 -0.13167816  0.34165859] \n",
      "\n",
      "best reward is :  [0.4552     0.42533333 0.39408451 0.36133333 0.31061224]\n",
      "reward is :  [0.23748879 0.04777251 0.42533333 0.02133333 0.2146988 ]\n",
      "regrets is :  [ 0.21771121  0.37756082 -0.03124883  0.34        0.09591345] \n",
      "\n",
      "best reward is :  [0.73118734 0.61563964 0.57477477 0.56967825 0.53287169]\n",
      "reward is :  [0.07748879 0.04777251 0.73118734 0.18133333 0.2146988 ]\n",
      "regrets is :  [ 0.65369855  0.56786713 -0.15641256  0.38834492  0.3181729 ] \n",
      "\n",
      "best reward is :  [0.47748879 0.42777251 0.2752     0.25795918 0.21408451]\n",
      "reward is :  [0.47748879 0.42777251 0.09648241 0.18133333 0.0346988 ]\n",
      "regrets is :  [0.         0.         0.17871759 0.07662585 0.17938571] \n",
      "\n",
      "best reward is :  [0.47129252 0.42298851 0.41073593 0.40302405 0.38777251]\n",
      "reward is :  [0.25748879 0.38777251 0.09648241 0.23466667 0.1946988 ]\n",
      "regrets is :  [0.21380373 0.03521599 0.31425352 0.16835739 0.19307372] \n",
      "\n",
      "best reward is :  [0.72865979 0.49333333 0.42378378 0.41834395 0.35615385]\n",
      "reward is :  [0.29257362 0.0341637  0.16       0.26716279 0.72865979]\n",
      "regrets is :  [ 0.43608618  0.45916963  0.26378378  0.15118116 -0.37250595] \n",
      "\n",
      "best reward is :  [0.41333333 0.364      0.34941176 0.34378378 0.33834395]\n",
      "reward is :  [0.33679245 0.30516291 0.0341637  0.16       0.26716279]\n",
      "regrets is :  [0.07654088 0.05883709 0.31524806 0.18378378 0.07118116] \n",
      "\n",
      "best reward is :  [0.45382946 0.37870968 0.32145231 0.25851767 0.24836272]\n",
      "reward is :  [0.32145231 0.37870968 0.18       0.45382946 0.25851767]\n",
      "regrets is :  [ 0.13237715  0.          0.14145231 -0.19531178 -0.01015495] \n",
      "\n",
      "best reward is :  [0.41333333 0.40013245 0.36811897 0.364      0.34941176]\n",
      "reward is :  [0.36811897 0.10247788 0.16       0.27014623 0.40013245]\n",
      "regrets is :  [ 0.04521436  0.29765457  0.20811897  0.09385377 -0.05072069] \n",
      "\n",
      "best reward is :  [0.38164706 0.33333333 0.32378378 0.28948718 0.27014623]\n",
      "reward is :  [0.24430472 0.04565217 0.16       0.27014623 0.38164706]\n",
      "regrets is :  [ 0.13734234  0.28768116  0.16378378  0.01934095 -0.11150083] \n",
      "\n",
      "best reward is :  [0.59789864 0.50347267 0.4        0.36344828 0.359     ]\n",
      "reward is :  [0.359      0.02086957 0.50347267 0.02938776 0.59789864]\n",
      "regrets is :  [ 0.23889864  0.4826031  -0.10347267  0.33406052 -0.23889864] \n",
      "\n",
      "best reward is :  [0.44       0.38342029 0.36676471 0.33067371 0.30597403]\n",
      "reward is :  [0.159      0.30086957 0.16347267 0.06938776 0.13789864]\n",
      "regrets is :  [0.281      0.08255072 0.20329204 0.26128596 0.16807539] \n",
      "\n",
      "best reward is :  [0.4916965  0.44198004 0.42992031 0.40229108 0.39176812]\n",
      "reward is :  [0.38       0.14724891 0.21789047 0.19111111 0.32663904]\n",
      "regrets is :  [0.1116965  0.29473113 0.21202984 0.21117997 0.06512907] \n",
      "\n",
      "best reward is :  [0.64494845 0.50969072 0.48793388 0.45531337 0.41562441]\n",
      "reward is :  [0.02724891 0.07789047 0.24       0.19777778 0.2284529 ]\n",
      "regrets is :  [0.61769955 0.43180026 0.24793388 0.2575356  0.18717152] \n",
      "\n",
      "best reward is :  [0.61100638 0.55710843 0.52       0.39775306 0.38713043]\n",
      "reward is :  [0.38713043 0.55710843 0.52       0.0055814  0.61100638]\n",
      "regrets is :  [ 0.22387594  0.          0.          0.39217167 -0.22387594] \n",
      "\n",
      "best reward is :  [0.66477064 0.64705882 0.57524211 0.504      0.496     ]\n",
      "reward is :  [0.26584615 0.03857143 0.095      0.1979235  0.17978022]\n",
      "regrets is :  [0.39892449 0.60848739 0.48024211 0.3060765  0.31621978] \n",
      "\n",
      "best reward is :  [0.53769912 0.51450746 0.46384937 0.45764706 0.44491803]\n",
      "reward is :  [0.02823529 0.27857143 0.015      0.1447619  0.29978022]\n",
      "regrets is :  [0.50946382 0.23593603 0.44884937 0.31288515 0.14513781] \n",
      "\n",
      "best reward is :  [0.41769912 0.39450746 0.36894118 0.34384937 0.33764706]\n",
      "reward is :  [0.02823529 0.27857143 0.015      0.1447619  0.17978022]\n",
      "regrets is :  [0.38946382 0.11593603 0.35394118 0.19908747 0.15786684] \n",
      "\n",
      "best reward is :  [0.55560784 0.53291667 0.53251282 0.51899543 0.50823529]\n",
      "reward is :  [0.50823529 0.19857143 0.415      0.3847619  0.01978022]\n",
      "regrets is :  [0.04737255 0.33434524 0.11751282 0.13423353 0.48845507] \n",
      "\n",
      "best reward is :  [0.664      0.64506024 0.57524211 0.50477064 0.496     ]\n",
      "reward is :  [0.26823529 0.03857143 0.095      0.24052164 0.01978022]\n",
      "regrets is :  [0.39576471 0.60648881 0.48024211 0.264249   0.47621978] \n",
      "\n",
      "End of the simulations, time elapsed: 98.583 seconds.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "regret, regrets, rewards, regrets_normal = run_several_experiments_hist_ML_online(LinearRegression, nb_exp = 20, \n",
    "                                                                                  evolutive_env = True, nb_steps_history=1000)\n",
    "plot_regret(regret, regrets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation 0 started, time elapsed: 0.000 seconds.\n",
      "best reward is :  [0.76526441 0.65085051 0.64152595 0.57052632 0.53008102]\n",
      "reward is :  [0.57052632 0.76526441 0.64152595 0.65085051 0.51796954]\n",
      "regrets is :  [ 0.19473809 -0.11441389  0.         -0.0803242   0.01211148] \n",
      "\n",
      "best reward is :  [0.5809827  0.49712307 0.45916041 0.43081123 0.40767852]\n",
      "reward is :  [0.35881059 0.5809827  0.43081123 0.45916041 0.33796954]\n",
      "regrets is :  [ 0.22217212 -0.08385964  0.02834918 -0.02834918  0.06970897] \n",
      "\n",
      "best reward is :  [0.71052632 0.59151813 0.58731707 0.46725158 0.45617021]\n",
      "reward is :  [0.71052632 0.58731707 0.45617021 0.37647864 0.46725158]\n",
      "regrets is :  [ 0.          0.00420106  0.13114686  0.09077293 -0.01108136] \n",
      "\n",
      "best reward is :  [0.70505621 0.62388721 0.52217301 0.45620426 0.44345144]\n",
      "reward is :  [0.08259766 0.22526441 0.14102303 0.11916041 0.27261056]\n",
      "regrets is :  [0.62245855 0.39862281 0.38114998 0.33704386 0.17084088] \n",
      "\n",
      "best reward is :  [0.69349312 0.58606929 0.4875432  0.41659911 0.36716093]\n",
      "reward is :  [0.06685625 0.41659911 0.26516001 0.29477681 0.09987845]\n",
      "regrets is :  [0.62663688 0.16947018 0.22238319 0.1218223  0.26728249] \n",
      "\n",
      "best reward is :  [0.74       0.64694701 0.58160298 0.56706893 0.54425963]\n",
      "reward is :  [0.56706893 0.74       0.64694701 0.34747298 0.58160298]\n",
      "regrets is :  [ 0.17293107 -0.09305299 -0.06534403  0.21959595 -0.03734335] \n",
      "\n",
      "best reward is :  [0.78       0.6134033  0.52020769 0.51374647 0.49398103]\n",
      "reward is :  [0.6134033  0.78       0.38711316 0.24747298 0.44160298]\n",
      "regrets is :  [ 0.1665967  -0.1665967   0.13309453  0.26627349  0.05237805] \n",
      "\n",
      "best reward is :  [0.66413965 0.51336019 0.50884659 0.47938118 0.46739748]\n",
      "reward is :  [0.26250757 0.44898979 0.36061265 0.66413965 0.10160298]\n",
      "regrets is :  [ 0.40163207  0.0643704   0.14823394 -0.18475847  0.3657945 ] \n",
      "\n",
      "best reward is :  [0.94       0.7734033  0.58028035 0.42197701 0.36402939]\n",
      "reward is :  [0.7734033  0.94       0.58028035 0.34747298 0.36402939]\n",
      "regrets is :  [ 0.1665967  -0.1665967   0.          0.07450403  0.        ] \n",
      "\n",
      "best reward is :  [0.8159487  0.649352   0.55622905 0.47526861 0.46409255]\n",
      "reward is :  [0.649352   0.8159487  0.55622905 0.35675501 0.47526861]\n",
      "regrets is :  [ 0.1665967  -0.1665967   0.          0.1185136  -0.01117606] \n",
      "\n",
      "best reward is :  [0.60251663 0.60068648 0.53015913 0.52388019 0.52246156]\n",
      "reward is :  [0.26545264 0.08809093 0.26171816 0.20457454 0.16687616]\n",
      "regrets is :  [0.33706398 0.51259555 0.26844096 0.31930565 0.3555854 ] \n",
      "\n",
      "best reward is :  [0.71823411 0.66384326 0.58687616 0.58064516 0.57135058]\n",
      "reward is :  [0.71823411 0.54465947 0.54978699 0.66384326 0.58687616]\n",
      "regrets is :  [ 0.          0.11918379  0.03708916 -0.0831981  -0.01552558] \n",
      "\n",
      "best reward is :  [0.67338129 0.55258561 0.5314084  0.51272784 0.48879645]\n",
      "reward is :  [0.67338129 0.48879645 0.48050496 0.45517181 0.41586595]\n",
      "regrets is :  [0.         0.06378915 0.05090344 0.05755603 0.0729305 ] \n",
      "\n",
      "best reward is :  [0.64663948 0.61921204 0.58978664 0.55804008 0.5530623 ]\n",
      "reward is :  [0.54266333 0.64663948 0.34552669 0.48827248 0.5530623 ]\n",
      "regrets is :  [ 0.10397615 -0.02742743  0.24425995  0.0697676   0.        ] \n",
      "\n",
      "best reward is :  [0.59705758 0.54666331 0.49363147 0.48847931 0.48657526]\n",
      "reward is :  [0.54666331 0.39347229 0.48847931 0.49363147 0.30808936]\n",
      "regrets is :  [ 0.05039428  0.15319102  0.00515216 -0.00515216  0.1784859 ] \n",
      "\n",
      "best reward is :  [0.65692308 0.61879134 0.53276126 0.52364452 0.51828213]\n",
      "reward is :  [0.65692308 0.03583012 0.11703781 0.26611573 0.35712755]\n",
      "regrets is :  [0.         0.58296122 0.41572346 0.25752879 0.16115458] \n",
      "\n",
      "best reward is :  [0.62955306 0.61699884 0.55692308 0.55522278 0.54601719]\n",
      "reward is :  [0.55692308 0.03583012 0.0946114  0.23972499 0.55522278]\n",
      "regrets is :  [ 0.07262998  0.58116873  0.46231168  0.31549779 -0.00920559] \n",
      "\n",
      "best reward is :  [0.68488195 0.66368932 0.56302543 0.53870697 0.52068293]\n",
      "reward is :  [0.22445296 0.52068293 0.5146114  0.66368932 0.44864703]\n",
      "regrets is :  [ 0.46042898  0.14300639  0.04841403 -0.12498235  0.0720359 ] \n",
      "\n",
      "best reward is :  [0.55151307 0.53782212 0.51934948 0.50542255 0.49240874]\n",
      "reward is :  [0.51934948 0.06085185 0.09770541 0.30854213 0.41136194]\n",
      "regrets is :  [0.03216359 0.47697027 0.42164407 0.19688041 0.0810468 ] \n",
      "\n",
      "best reward is :  [0.69987068 0.69818182 0.55825652 0.55703781 0.50926635]\n",
      "reward is :  [0.21960095 0.55825652 0.55703781 0.69987068 0.26050633]\n",
      "regrets is :  [ 0.48026974  0.1399253   0.00121872 -0.14283288  0.24876002] \n",
      "\n",
      "best reward is :  [0.57090258 0.484      0.47158755 0.44435411 0.37642633]\n",
      "reward is :  [0.11949032 0.484      0.24545268 0.37642633 0.31613238]\n",
      "regrets is :  [0.45141226 0.         0.22613486 0.06792778 0.06029395] \n",
      "\n",
      "best reward is :  [0.63613238 0.624      0.58451495 0.57555186 0.57118701]\n",
      "reward is :  [0.12314747 0.624      0.3300937  0.33106735 0.63613238]\n",
      "regrets is :  [ 0.51298491  0.          0.25442125  0.24448451 -0.06494537] \n",
      "\n",
      "best reward is :  [0.43778849 0.36975411 0.31471288 0.29221611 0.27990933]\n",
      "reward is :  [0.43778849 0.25328203 0.07898662 0.0754     0.04892442]\n",
      "regrets is :  [0.         0.11647208 0.23572626 0.21681611 0.2309849 ] \n",
      "\n",
      "best reward is :  [0.58217209 0.4718031  0.42368317 0.39298979 0.34988429]\n",
      "reward is :  [0.58217209 0.39298979 0.25163404 0.27009196 0.23231374]\n",
      "regrets is :  [0.         0.07881331 0.17204913 0.12289783 0.11757055] \n",
      "\n",
      "best reward is :  [0.73328203 0.66473472 0.62970834 0.59893665 0.58541441]\n",
      "reward is :  [0.27949032 0.73328203 0.66473472 0.62970834 0.58541441]\n",
      "regrets is :  [ 0.45379171 -0.06854732 -0.03502637 -0.0307717   0.        ] \n",
      "\n",
      "best reward is :  [0.84       0.56371601 0.55535893 0.55334888 0.50229866]\n",
      "reward is :  [0.84       0.55535893 0.50229866 0.43739392 0.31447617]\n",
      "regrets is :  [0.         0.00835708 0.05306027 0.11595496 0.18782249] \n",
      "\n",
      "best reward is :  [0.71477855 0.64       0.61301663 0.52802659 0.49535893]\n",
      "reward is :  [0.64       0.49535893 0.61301663 0.71477855 0.1317983 ]\n",
      "regrets is :  [ 0.07477855  0.14464107  0.         -0.18675196  0.36356063] \n",
      "\n",
      "best reward is :  [0.75565646 0.5157773  0.39639807 0.39586466 0.39066361]\n",
      "reward is :  [0.75565646 0.5157773  0.39586466 0.3613939  0.35811023]\n",
      "regrets is :  [0.         0.         0.00053342 0.03447076 0.03255338] \n",
      "\n",
      "best reward is :  [0.7        0.63854256 0.62448622 0.61653608 0.5786406 ]\n",
      "reward is :  [0.7        0.52743028 0.51301663 0.46811189 0.12700898]\n",
      "regrets is :  [0.         0.11111228 0.11146959 0.14842419 0.45163163] \n",
      "\n",
      "best reward is :  [0.5101548  0.48485281 0.48473014 0.48240244 0.44495702]\n",
      "reward is :  [0.48485281 0.34021175 0.09301663 0.11721616 0.48240244]\n",
      "regrets is :  [ 0.02530199  0.14464107  0.39171351  0.36518628 -0.03744543] \n",
      "\n",
      "best reward is :  [0.69084135 0.61033332 0.56582023 0.52634518 0.48553096]\n",
      "reward is :  [0.37033628 0.69084135 0.61033332 0.33176471 0.39130145]\n",
      "regrets is :  [ 0.32050507 -0.08050803 -0.0445131   0.19458047  0.09422951] \n",
      "\n",
      "best reward is :  [0.72130242 0.64890434 0.64240572 0.56633628 0.52641535]\n",
      "reward is :  [0.56633628 0.48984359 0.44018721 0.38201942 0.64240572]\n",
      "regrets is :  [ 0.15496613  0.15906075  0.20221852  0.18431687 -0.11599037] \n",
      "\n",
      "best reward is :  [0.68155932 0.63569231 0.56582023 0.52634518 0.48553096]\n",
      "reward is :  [0.40633628 0.68155932 0.63569231 0.33176471 0.39130145]\n",
      "regrets is :  [ 0.27522304 -0.04586701 -0.06987208  0.19458047  0.09422951] \n",
      "\n",
      "best reward is :  [0.51883829 0.49213587 0.49028177 0.45227781 0.45073068]\n",
      "reward is :  [0.14633628 0.19522495 0.09569231 0.10394607 0.29568505]\n",
      "regrets is :  [0.37250201 0.29691091 0.39458946 0.34833174 0.15504563] \n",
      "\n",
      "best reward is :  [0.51883829 0.49213587 0.49028177 0.45227781 0.45073068]\n",
      "reward is :  [0.14633628 0.19522495 0.09569231 0.12776471 0.30201942]\n",
      "regrets is :  [0.37250201 0.29691091 0.39458946 0.3245131  0.14871126] \n",
      "\n",
      "best reward is :  [0.62889849 0.61616268 0.59475751 0.57709576 0.55860503]\n",
      "reward is :  [0.49180262 0.17712148 0.27897611 0.07342241 0.22      ]\n",
      "regrets is :  [0.13709587 0.4390412  0.3157814  0.50367335 0.33860503] \n",
      "\n",
      "best reward is :  [0.6338883  0.60368352 0.52286725 0.52067811 0.51322347]\n",
      "reward is :  [0.25824818 0.33567003 0.06799586 0.30382892 0.344     ]\n",
      "regrets is :  [0.37564012 0.2680135  0.45487139 0.21684919 0.16922347] \n",
      "\n",
      "best reward is :  [0.62889849 0.61616268 0.59475751 0.57709576 0.55860503]\n",
      "reward is :  [0.49180262 0.17712148 0.27897611 0.07342241 0.22      ]\n",
      "regrets is :  [0.13709587 0.4390412  0.3157814  0.50367335 0.33860503] \n",
      "\n",
      "best reward is :  [0.66318833 0.51369002 0.49527946 0.47618136 0.45264174]\n",
      "reward is :  [0.49527946 0.51369002 0.45264174 0.42382892 0.47618136]\n",
      "regrets is :  [ 0.16790888  0.          0.04263772  0.05235244 -0.02353962] \n",
      "\n",
      "best reward is :  [0.47098387 0.46501857 0.42995998 0.39690615 0.38598831]\n",
      "reward is :  [0.38598831 0.46501857 0.42995998 0.366506   0.47098387]\n",
      "regrets is :  [ 0.08499556  0.          0.          0.03040015 -0.08499556] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best reward is :  [0.70502112 0.66270317 0.64572238 0.64404532 0.57606988]\n",
      "reward is :  [0.51523256 0.64404532 0.64572238 0.37364363 0.25620928]\n",
      "regrets is :  [0.18978856 0.01865785 0.         0.27040168 0.31986059] \n",
      "\n",
      "best reward is :  [0.6991925  0.62402385 0.59129033 0.55573548 0.4969247 ]\n",
      "reward is :  [0.55573548 0.6991925  0.40086957 0.15707509 0.01135647]\n",
      "regrets is :  [ 0.14345702 -0.07516866  0.19042077  0.39866039  0.48556823] \n",
      "\n",
      "best reward is :  [0.55686275 0.54572614 0.46238862 0.43328572 0.41957527]\n",
      "reward is :  [0.04702075 0.1836874  0.02086957 0.43328572 0.27009732]\n",
      "regrets is :  [0.50984199 0.36203874 0.44151905 0.         0.14947795] \n",
      "\n",
      "best reward is :  [0.64879082 0.61135647 0.59466682 0.54292684 0.53456678]\n",
      "reward is :  [0.23280615 0.38847453 0.30086957 0.64879082 0.61135647]\n",
      "regrets is :  [ 0.41598467  0.22288193  0.29379725 -0.10586398 -0.07678968] \n",
      "\n",
      "best reward is :  [0.59466682 0.58879082 0.55135647 0.54292684 0.53456678]\n",
      "reward is :  [0.25037975 0.38847453 0.30086957 0.58879082 0.55135647]\n",
      "regrets is :  [ 0.34428707  0.20031629  0.2504869  -0.04586398 -0.01678968] \n",
      "\n",
      "best reward is :  [0.59609015 0.57663779 0.53118847 0.4609649  0.422601  ]\n",
      "reward is :  [0.57663779 0.06857143 0.20304068 0.41225229 0.05123265]\n",
      "regrets is :  [0.01945236 0.50806636 0.32814779 0.04871261 0.37136835] \n",
      "\n",
      "best reward is :  [0.62941407 0.52074253 0.48100836 0.47258825 0.46507366]\n",
      "reward is :  [0.37559925 0.44857143 0.52074253 0.34689655 0.46507366]\n",
      "regrets is :  [ 0.25381482  0.0721711  -0.03973417  0.1256917   0.        ] \n",
      "\n",
      "best reward is :  [0.69124306 0.61979035 0.61638202 0.58367589 0.5094682 ]\n",
      "reward is :  [0.5094682  0.09210536 0.25461148 0.45174937 0.0340898 ]\n",
      "regrets is :  [0.18177486 0.52768498 0.36177054 0.13192653 0.4753784 ] \n",
      "\n",
      "best reward is :  [0.66975867 0.62857143 0.61356322 0.5540898  0.46461538]\n",
      "reward is :  [0.46461538 0.62857143 0.66975867 0.61356322 0.5540898 ]\n",
      "regrets is :  [ 0.20514328  0.         -0.05619545 -0.05947342 -0.08947441] \n",
      "\n",
      "best reward is :  [0.71617858 0.68238148 0.60989617 0.50273775 0.49294263]\n",
      "reward is :  [0.23360518 0.35756122 0.46975867 0.71617858 0.42337183]\n",
      "regrets is :  [ 0.4825734   0.32482025  0.1401375  -0.21344083  0.0695708 ] \n",
      "\n",
      "best reward is :  [0.71506625 0.6416176  0.57772487 0.57718754 0.48463539]\n",
      "reward is :  [0.41349311 0.41166889 0.57718754 0.6416176  0.71506625]\n",
      "regrets is :  [ 0.30157315  0.22994872  0.00053733 -0.06443006 -0.23043086] \n",
      "\n",
      "best reward is :  [0.66559535 0.58989164 0.57230757 0.54511594 0.44029525]\n",
      "reward is :  [0.04450331 0.11971455 0.21486442 0.36       0.04031784]\n",
      "regrets is :  [0.62109204 0.47017709 0.35744315 0.18511594 0.39997741] \n",
      "\n",
      "best reward is :  [0.6249879  0.60740907 0.53071521 0.51328917 0.49558143]\n",
      "reward is :  [0.07778532 0.16338462 0.17641705 0.25897367 0.04211213]\n",
      "regrets is :  [0.54720258 0.44402446 0.35429816 0.2543155  0.4534693 ] \n",
      "\n",
      "best reward is :  [0.61266665 0.59252859 0.52261537 0.44602273 0.43822538]\n",
      "reward is :  [0.27378534 0.61266665 0.43747978 0.52261537 0.30869182]\n",
      "regrets is :  [ 0.3388813  -0.02013806  0.08513558 -0.07659263  0.12953356] \n",
      "\n",
      "best reward is :  [0.74709113 0.49182395 0.46235609 0.45408979 0.41445289]\n",
      "reward is :  [0.06219635 0.32338462 0.21486442 0.36       0.04762909]\n",
      "regrets is :  [0.68489478 0.16843934 0.24749168 0.09408979 0.36682379] \n",
      "\n",
      "best reward is :  [0.57453732 0.56584102 0.56192824 0.52915766 0.49795318]\n",
      "reward is :  [0.56584102 0.47974643 0.31487928 0.30222333 0.22648476]\n",
      "regrets is :  [0.00869631 0.08609459 0.24704896 0.22693433 0.27146841] \n",
      "\n",
      "best reward is :  [0.5611037  0.52336152 0.5184832  0.4483931  0.44635117]\n",
      "reward is :  [0.22908854 0.4483931  0.3033598  0.32355666 0.31610405]\n",
      "regrets is :  [0.33201516 0.07496842 0.2151234  0.12483643 0.13024712] \n",
      "\n",
      "best reward is :  [0.5383093  0.45778178 0.45002647 0.44691072 0.4312    ]\n",
      "reward is :  [0.4312     0.39732002 0.45002647 0.41979692 0.40388944]\n",
      "regrets is :  [0.1071093  0.06046176 0.         0.0271138  0.02731056] \n",
      "\n",
      "best reward is :  [0.53566658 0.5233598  0.50180468 0.49739583 0.4912    ]\n",
      "reward is :  [0.4912     0.47489362 0.5233598  0.40090445 0.48146304]\n",
      "regrets is :  [ 0.04446658  0.04846618 -0.02155512  0.09649137  0.00973696] \n",
      "\n",
      "best reward is :  [0.58741768 0.57655574 0.57311869 0.56166988 0.53011836]\n",
      "reward is :  [0.57655574 0.36024935 0.2679738  0.24490041 0.22899292]\n",
      "regrets is :  [0.01086195 0.21630638 0.30514489 0.31676948 0.30112543] \n",
      "\n",
      "best reward is :  [0.71556641 0.54895189 0.52923077 0.52386474 0.52137112]\n",
      "reward is :  [0.19843898 0.04941863 0.4434084  0.04676372 0.34322708]\n",
      "regrets is :  [0.51712743 0.49953325 0.08582237 0.47710102 0.17814404] \n",
      "\n",
      "best reward is :  [0.63434906 0.57868953 0.54597302 0.53298507 0.53110872]\n",
      "reward is :  [0.20885642 0.0339267  0.43236594 0.06090585 0.32042343]\n",
      "regrets is :  [0.42549263 0.54476283 0.11360708 0.47207922 0.21068529] \n",
      "\n",
      "best reward is :  [0.56836177 0.52324921 0.48382863 0.41090909 0.40757062]\n",
      "reward is :  [0.41090909 0.30720871 0.34648995 0.26676372 0.40757062]\n",
      "regrets is :  [0.15745268 0.2160405  0.13733868 0.14414537 0.        ] \n",
      "\n",
      "best reward is :  [0.53442663 0.53320582 0.42027485 0.41796629 0.39153204]\n",
      "reward is :  [0.20709045 0.20982109 0.25632751 0.08140473 0.15027296]\n",
      "regrets is :  [0.32733617 0.32338473 0.16394734 0.33656156 0.24125907] \n",
      "\n",
      "best reward is :  [0.7544186  0.63503111 0.49959302 0.45626483 0.44621329]\n",
      "reward is :  [0.45626483 0.34320873 0.7544186  0.40471105 0.49959302]\n",
      "regrets is :  [ 0.29815378  0.29182237 -0.25482558  0.05155378 -0.05337974] \n",
      "\n",
      "best reward is :  [0.74875841 0.73620681 0.70381321 0.64426469 0.63842543]\n",
      "reward is :  [0.73620681 0.70381321 0.62928203 0.64426469 0.74875841]\n",
      "regrets is :  [ 0.01255161  0.0323936   0.07453118  0.         -0.11033298] \n",
      "\n",
      "best reward is :  [0.84       0.73258045 0.66120986 0.58572368 0.56004186]\n",
      "reward is :  [0.50254118 0.45453118 0.84       0.38397245 0.50408258]\n",
      "regrets is :  [ 0.33745882  0.27804927 -0.17879014  0.20175123  0.05595928] \n",
      "\n",
      "best reward is :  [0.60958751 0.51795134 0.48485281 0.46788945 0.4407793 ]\n",
      "reward is :  [0.20739399 0.22381321 0.48485281 0.01498266 0.1683748 ]\n",
      "regrets is :  [0.40219351 0.29413813 0.         0.45290679 0.27240451] \n",
      "\n",
      "best reward is :  [0.84       0.73258045 0.66120986 0.58572368 0.56004186]\n",
      "reward is :  [0.50254118 0.45453118 0.84       0.39498266 0.51509278]\n",
      "regrets is :  [ 0.33745882  0.27804927 -0.17879014  0.19074102  0.04494908] \n",
      "\n",
      "best reward is :  [0.60958751 0.51795134 0.48485281 0.46788945 0.4407793 ]\n",
      "reward is :  [0.20739399 0.22381321 0.48485281 0.01498266 0.1683748 ]\n",
      "regrets is :  [0.40219351 0.29413813 0.         0.45290679 0.27240451] \n",
      "\n",
      "best reward is :  [0.73333333 0.70519889 0.62746988 0.54422833 0.46613265]\n",
      "reward is :  [0.73333333 0.62746988 0.46613265 0.45979755 0.34448363]\n",
      "regrets is :  [0.         0.07772901 0.16133723 0.08443078 0.12164902] \n",
      "\n",
      "best reward is :  [0.59828527 0.55066937 0.43974912 0.43902965 0.42697964]\n",
      "reward is :  [0.32485281 0.09746988 0.28380952 0.08185022 0.28448363]\n",
      "regrets is :  [0.27343246 0.45319949 0.1559396  0.35717943 0.14249601] \n",
      "\n",
      "best reward is :  [0.51618136 0.46387042 0.46331743 0.42232796 0.41189621]\n",
      "reward is :  [0.51618136 0.26080321 0.30916526 0.21613593 0.27576429]\n",
      "regrets is :  [0.         0.20306721 0.15415217 0.20619202 0.13613192] \n",
      "\n",
      "best reward is :  [0.41074045 0.39768376 0.38956292 0.34448363 0.32134836]\n",
      "reward is :  [0.3        0.12746988 0.30095238 0.04634512 0.34448363]\n",
      "regrets is :  [ 0.11074045  0.27021388  0.08861054  0.29813851 -0.02313526] \n",
      "\n",
      "best reward is :  [0.68262125 0.61408955 0.6108536  0.60284436 0.44912929]\n",
      "reward is :  [0.30928203 0.08161202 0.26175686 0.04082389 0.10243096]\n",
      "regrets is :  [0.37333921 0.53247754 0.34909675 0.56202047 0.34669833] \n",
      "\n",
      "best reward is :  [0.62305698 0.61165647 0.51512626 0.51360617 0.50138251]\n",
      "reward is :  [0.0421519  0.31995485 0.07396823 0.21056047 0.22214592]\n",
      "regrets is :  [0.58090508 0.29170162 0.44115803 0.3030457  0.27923658] \n",
      "\n",
      "best reward is :  [0.76403488 0.75498969 0.70438407 0.67143393 0.62750166]\n",
      "reward is :  [0.67143393 0.70438407 0.76403488 0.75498969 0.62750166]\n",
      "regrets is :  [ 0.09260095  0.05060562 -0.05965081 -0.08355576  0.        ] \n",
      "\n",
      "best reward is :  [0.47345627 0.46869809 0.46791889 0.45269056 0.45004398]\n",
      "reward is :  [0.24009923 0.43304937 0.23828679 0.33937329 0.10214592]\n",
      "regrets is :  [0.23335704 0.03564871 0.2296321  0.11331727 0.34789806] \n",
      "\n",
      "best reward is :  [0.53328819 0.51742981 0.46693425 0.4421519  0.42699874]\n",
      "reward is :  [0.4421519  0.53328819 0.41475285 0.37056047 0.42699874]\n",
      "regrets is :  [ 0.09113629 -0.01585838  0.0521814   0.07159143  0.        ] \n",
      "\n",
      "best reward is :  [0.61275257 0.57510403 0.56390447 0.47647536 0.45312979]\n",
      "reward is :  [0.30370453 0.61275257 0.41093421 0.38726029 0.45312979]\n",
      "regrets is :  [ 0.30904804 -0.03764855  0.15297025  0.08921507  0.        ] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best reward is :  [0.77923318 0.62628798 0.59765281 0.47400446 0.43543901]\n",
      "reward is :  [0.59765281 0.4123277  0.62628798 0.77923318 0.23037292]\n",
      "regrets is :  [ 0.18158037  0.21396028 -0.02863517 -0.30522873  0.20506609] \n",
      "\n",
      "best reward is :  [0.64200628 0.61438037 0.47217981 0.45869757 0.44378387]\n",
      "reward is :  [0.44378387 0.61438037 0.64200628 0.45869757 0.32807478]\n",
      "regrets is :  [ 0.19822241  0.         -0.16982647  0.          0.11570909] \n",
      "\n",
      "best reward is :  [0.65074733 0.6397361  0.59369639 0.53589594 0.51328928]\n",
      "reward is :  [0.65074733 0.6397361  0.59369639 0.31188417 0.43503824]\n",
      "regrets is :  [0.         0.         0.         0.22401177 0.07825104] \n",
      "\n",
      "best reward is :  [0.80241697 0.74069902 0.56609464 0.48669562 0.48135593]\n",
      "reward is :  [0.3928     0.25438037 0.34298167 0.23384694 0.33709091]\n",
      "regrets is :  [0.40961697 0.48631865 0.22311297 0.25284868 0.14426502] \n",
      "\n",
      "best reward is :  [0.73724037 0.64778613 0.62157815 0.58050789 0.51341199]\n",
      "reward is :  [0.22646563 0.40056651 0.23319346 0.45923318 0.38709091]\n",
      "regrets is :  [0.51077474 0.24721962 0.38838468 0.12127471 0.12632108] \n",
      "\n",
      "best reward is :  [0.76313932 0.64412992 0.52945882 0.47384544 0.45187882]\n",
      "reward is :  [0.76313932 0.64412992 0.44246149 0.17437123 0.07753152]\n",
      "regrets is :  [0.         0.         0.08699734 0.29947421 0.3743473 ] \n",
      "\n",
      "best reward is :  [0.58947368 0.56895274 0.55933333 0.52585078 0.3882669 ]\n",
      "reward is :  [0.58947368 0.3882669  0.38316701 0.17519123 0.08651757]\n",
      "regrets is :  [0.         0.18068584 0.17616632 0.35065955 0.30174933] \n",
      "\n",
      "best reward is :  [0.61137933 0.6108567  0.60209697 0.50149584 0.4837771 ]\n",
      "reward is :  [0.25449541 0.20156055 0.01417722 0.44608696 0.50149584]\n",
      "regrets is :  [ 0.35688392  0.40929615  0.58791975  0.05540889 -0.01771875] \n",
      "\n",
      "best reward is :  [0.61137933 0.6108567  0.60209697 0.4837771  0.44608696]\n",
      "reward is :  [0.25449541 0.20156055 0.01417722 0.44608696 0.44149584]\n",
      "regrets is :  [0.35688392 0.40929615 0.58791975 0.03769014 0.00459111] \n",
      "\n",
      "best reward is :  [0.57129951 0.5157506  0.41875572 0.41823245 0.39308479]\n",
      "reward is :  [0.41875572 0.57129951 0.32345925 0.17815831 0.07829921]\n",
      "regrets is :  [ 0.1525438  -0.05554892  0.09529647  0.24007415  0.31478558] \n",
      "\n",
      "best reward is :  [0.71937963 0.60104665 0.5689824  0.51411208 0.4923287 ]\n",
      "reward is :  [0.385      0.21581028 0.11197658 0.04379691 0.22965675]\n",
      "regrets is :  [0.33437963 0.38523637 0.45700582 0.47031517 0.26267195] \n",
      "\n",
      "best reward is :  [0.65862121 0.62134437 0.59653275 0.52491228 0.51792844]\n",
      "reward is :  [0.245      0.01581028 0.31297434 0.25029586 0.07208316]\n",
      "regrets is :  [0.41362121 0.60553409 0.28355841 0.27461642 0.44584528] \n",
      "\n",
      "best reward is :  [0.69991406 0.59054726 0.56999361 0.55703047 0.48816988]\n",
      "reward is :  [0.21828201 0.01581028 0.10243316 0.03029586 0.0483976 ]\n",
      "regrets is :  [0.48163205 0.57473698 0.46756046 0.52673461 0.43977228] \n",
      "\n",
      "best reward is :  [0.58591741 0.51539515 0.45600628 0.43964352 0.43876902]\n",
      "reward is :  [0.21183282 0.01581028 0.31297434 0.27514867 0.04817315]\n",
      "regrets is :  [0.3740846  0.49958487 0.14303194 0.16449485 0.39059587] \n",
      "\n",
      "best reward is :  [0.62396149 0.57134067 0.51369231 0.47900973 0.47866563]\n",
      "reward is :  [0.47866563 0.29199164 0.51369231 0.62396149 0.46332238]\n",
      "regrets is :  [ 0.14529586  0.27934903  0.         -0.14495176  0.01534325] \n",
      "\n",
      "best reward is :  [0.55608124 0.41517539 0.40560876 0.3953354  0.38130909]\n",
      "reward is :  [0.40560876 0.29752075 0.28329597 0.41517539 0.10491595]\n",
      "regrets is :  [ 0.15047249  0.11765465  0.12231279 -0.01983999  0.27639314] \n",
      "\n",
      "best reward is :  [0.4975711  0.47096774 0.44572238 0.43509434 0.40924538]\n",
      "reward is :  [0.47096774 0.43509434 0.44572238 0.21274899 0.1866072 ]\n",
      "regrets is :  [0.02660335 0.0358734  0.         0.22234535 0.22263818] \n",
      "\n",
      "best reward is :  [0.4975711  0.47096774 0.44572238 0.43509434 0.40924538]\n",
      "reward is :  [0.47096774 0.43509434 0.44572238 0.21274899 0.1866072 ]\n",
      "regrets is :  [0.02660335 0.0358734  0.         0.22234535 0.22263818] \n",
      "\n",
      "best reward is :  [0.61632348 0.5302894  0.46045008 0.445183   0.43705093]\n",
      "reward is :  [0.61632348 0.46045008 0.43705093 0.20239393 0.17999032]\n",
      "regrets is :  [0.         0.06983933 0.02339915 0.24278907 0.25706061] \n",
      "\n",
      "best reward is :  [0.68817931 0.55733632 0.5249636  0.46666667 0.43704534]\n",
      "reward is :  [0.29995754 0.11142427 0.10208277 0.5249636  0.19607751]\n",
      "regrets is :  [ 0.38822177  0.44591204  0.42288083 -0.05829693  0.24096783] \n",
      "\n",
      "End of the simulations, time elapsed: 60.864 seconds.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "regret, regrets, rewards, regrets_normal = run_several_experiments_hist_ML(LinearRegression, nb_exp = 20, \n",
    "                                                                           evolutive_env = False, nb_steps_history=1000)\n",
    "plot_regret(regret, regrets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation 0 started, time elapsed: 0.000 seconds.\n",
      "best reward is :  [0.63565646 0.56255191 0.47783784 0.45714286 0.44536282]\n",
      "reward is :  [0.63565646 0.36378488 0.45714286 0.47783784 0.56255191]\n",
      "regrets is :  [ 0.          0.19876703  0.02069498 -0.02069498 -0.1171891 ] \n",
      "\n",
      "best reward is :  [0.64666667 0.56255191 0.47783784 0.45714286 0.44536282]\n",
      "reward is :  [0.64666667 0.36378488 0.45714286 0.47783784 0.56255191]\n",
      "regrets is :  [ 0.          0.19876703  0.02069498 -0.02069498 -0.1171891 ] \n",
      "\n",
      "best reward is :  [0.72535574 0.67399668 0.51812269 0.45049033 0.42702994]\n",
      "reward is :  [0.72535574 0.67399668 0.42199567 0.40319357 0.51812269]\n",
      "regrets is :  [ 0.          0.          0.09612702  0.04729676 -0.09109276] \n",
      "\n",
      "best reward is :  [0.72535574 0.67399668 0.49326988 0.45049033 0.42702994]\n",
      "reward is :  [0.72535574 0.67399668 0.39714286 0.41783784 0.49326988]\n",
      "regrets is :  [ 0.          0.          0.09612702  0.03265249 -0.06623994] \n",
      "\n",
      "best reward is :  [0.60262331 0.49742999 0.44794444 0.43627212 0.43485225]\n",
      "reward is :  [0.30928203 0.06517954 0.28642489 0.26694211 0.38255191]\n",
      "regrets is :  [0.29334128 0.43225045 0.16151955 0.16933001 0.05230034] \n",
      "\n",
      "best reward is :  [0.6779428  0.62898979 0.50017806 0.46172156 0.45298522]\n",
      "reward is :  [0.62898979 0.46172156 0.50017806 0.6779428  0.34264253]\n",
      "regrets is :  [ 0.048953    0.16726823  0.         -0.21622124  0.11034269] \n",
      "\n",
      "best reward is :  [0.58188764 0.51542964 0.49300928 0.46499059 0.43926257]\n",
      "reward is :  [0.2644949  0.09738583 0.36873552 0.14582027 0.02936052]\n",
      "regrets is :  [0.31739274 0.4180438  0.12427376 0.31917031 0.40990205] \n",
      "\n",
      "best reward is :  [0.56643467 0.51178693 0.50017806 0.48557205 0.47347232]\n",
      "reward is :  [0.44       0.20465089 0.50017806 0.42228634 0.51178693]\n",
      "regrets is :  [ 0.12643467  0.30713603  0.          0.06328571 -0.03831461] \n",
      "\n",
      "best reward is :  [0.72592966 0.70666667 0.61775165 0.59186353 0.58999221]\n",
      "reward is :  [0.70666667 0.54596182 0.61775165 0.588953   0.22936052]\n",
      "regrets is :  [0.01926299 0.16070485 0.         0.00291053 0.3606317 ] \n",
      "\n",
      "best reward is :  [0.51835657 0.47106778 0.45529364 0.45244785 0.40399097]\n",
      "reward is :  [0.27464102 0.11393617 0.38310739 0.14456978 0.05336052]\n",
      "regrets is :  [0.24371556 0.35713161 0.07218625 0.30787807 0.35063045] \n",
      "\n",
      "best reward is :  [0.67838673 0.55319268 0.54047079 0.53640126 0.50215011]\n",
      "reward is :  [0.47394372 0.21507504 0.54047079 0.50215011 0.37330707]\n",
      "regrets is :  [0.204443   0.33811765 0.         0.03425115 0.12884304] \n",
      "\n",
      "best reward is :  [0.73889985 0.60275654 0.56383445 0.53243258 0.52317057]\n",
      "reward is :  [0.60275654 0.40255452 0.07459164 0.0172973  0.24640159]\n",
      "regrets is :  [0.13614331 0.20020202 0.48924281 0.51513528 0.27676898] \n",
      "\n",
      "best reward is :  [0.59394372 0.55543259 0.48297592 0.37689829 0.36888889]\n",
      "reward is :  [0.59394372 0.36888889 0.07871199 0.0172973  0.062797  ]\n",
      "regrets is :  [0.         0.1865437  0.40426393 0.359601   0.30609189] \n",
      "\n",
      "best reward is :  [0.74928361 0.65469806 0.60474669 0.53057931 0.52865772]\n",
      "reward is :  [0.41358581 0.21799316 0.74928361 0.53057931 0.41744405]\n",
      "regrets is :  [ 0.3356978   0.4367049  -0.14453692  0.          0.11121366] \n",
      "\n",
      "best reward is :  [0.67838673 0.55319268 0.53640126 0.51561798 0.48168586]\n",
      "reward is :  [0.47394372 0.21507504 0.51561798 0.4772973  0.37330707]\n",
      "regrets is :  [0.204443   0.33811765 0.02078328 0.03832068 0.10837879] \n",
      "\n",
      "best reward is :  [0.71581302 0.55901025 0.54482428 0.49382984 0.49229462]\n",
      "reward is :  [0.24457357 0.46       0.20559215 0.49229462 0.21830366]\n",
      "regrets is :  [0.47123946 0.09901025 0.33923213 0.00153522 0.27399095] \n",
      "\n",
      "best reward is :  [0.54660327 0.54138769 0.47007063 0.41280589 0.40453586]\n",
      "reward is :  [0.10241122 0.28242641 0.37007123 0.54138769 0.09294468]\n",
      "regrets is :  [ 0.44419205  0.25896128  0.09999941 -0.1285818   0.31159118] \n",
      "\n",
      "best reward is :  [0.84928203 0.67705224 0.6675857  0.60153315 0.5456695 ]\n",
      "reward is :  [0.67705224 0.84928203 0.45663462 0.16262257 0.6675857 ]\n",
      "regrets is :  [ 0.1722298  -0.1722298   0.21095108  0.43891058 -0.12191619] \n",
      "\n",
      "best reward is :  [0.69229462 0.64691124 0.54985067 0.50514541 0.49408473]\n",
      "reward is :  [0.08749808 0.3        0.44764482 0.69229462 0.071637  ]\n",
      "regrets is :  [ 0.60479653  0.34691124  0.10220585 -0.18714921  0.42244773] \n",
      "\n",
      "best reward is :  [0.71581302 0.55901025 0.54482428 0.49382984 0.49229462]\n",
      "reward is :  [0.24457357 0.46       0.20559215 0.49229462 0.21830366]\n",
      "regrets is :  [0.47123946 0.09901025 0.33923213 0.00153522 0.27399095] \n",
      "\n",
      "best reward is :  [0.63812065 0.60424929 0.5175176  0.49743451 0.44897268]\n",
      "reward is :  [0.63812065 0.37546759 0.3976292  0.40526813 0.60424929]\n",
      "regrets is :  [ 0.          0.2287817   0.1198884   0.09216638 -0.15527661] \n",
      "\n",
      "best reward is :  [0.49820019 0.47980806 0.43187466 0.36880268 0.36743986]\n",
      "reward is :  [0.16218736 0.12757773 0.15574961 0.08756627 0.0633433 ]\n",
      "regrets is :  [0.33601283 0.35223033 0.27612505 0.28123641 0.30409656] \n",
      "\n",
      "best reward is :  [0.71326783 0.63023296 0.48024929 0.47592737 0.41411432]\n",
      "reward is :  [0.71326783 0.413588   0.47592737 0.63023296 0.48024929]\n",
      "regrets is :  [ 0.          0.21664496  0.00432192 -0.15430559 -0.06613497] \n",
      "\n",
      "best reward is :  [0.71326783 0.62095093 0.48024929 0.46664534 0.41411432]\n",
      "reward is :  [0.71326783 0.413588   0.46664534 0.62095093 0.48024929]\n",
      "regrets is :  [ 0.          0.20736293  0.01360396 -0.15430559 -0.06613497] \n",
      "\n",
      "best reward is :  [0.65200107 0.63814935 0.60824647 0.60687531 0.54891486]\n",
      "reward is :  [0.52693347 0.63814935 0.65200107 0.48794989 0.40560503]\n",
      "regrets is :  [ 0.12506761  0.         -0.0437546   0.11892542  0.14330983] \n",
      "\n",
      "best reward is :  [0.67408898 0.46398034 0.45756039 0.45470838 0.43454092]\n",
      "reward is :  [0.20340142 0.1325363  0.08323699 0.28763722 0.12532137]\n",
      "regrets is :  [0.47068756 0.33144405 0.3743234  0.16707116 0.30921955] \n",
      "\n",
      "best reward is :  [0.62759325 0.55835518 0.5292836  0.52418605 0.47736469]\n",
      "reward is :  [0.52418605 0.44635015 0.1844502  0.55835518 0.25076923]\n",
      "regrets is :  [ 0.1034072   0.11200504  0.3448334  -0.03416914  0.22659546] \n",
      "\n",
      "best reward is :  [0.73570553 0.56263153 0.48237552 0.4527649  0.44987467]\n",
      "reward is :  [0.73570553 0.56263153 0.48237552 0.44987467 0.4527649 ]\n",
      "regrets is :  [ 0.          0.          0.          0.00289024 -0.00289024] \n",
      "\n",
      "best reward is :  [0.51201209 0.48954137 0.47507435 0.45841497 0.44798788]\n",
      "reward is :  [0.37247032 0.2984215  0.27234127 0.11835518 0.29987351]\n",
      "regrets is :  [0.13954177 0.19111987 0.20273308 0.34005979 0.14811437] \n",
      "\n",
      "best reward is :  [0.52689362 0.52163731 0.50072613 0.49746806 0.4694997 ]\n",
      "reward is :  [0.49746806 0.28944416 0.32323699 0.37835518 0.25076923]\n",
      "regrets is :  [0.02942556 0.23219315 0.17748913 0.11911287 0.21873047] \n",
      "\n",
      "best reward is :  [0.64       0.62874045 0.61228354 0.5876     0.5719906 ]\n",
      "reward is :  [0.64       0.61228354 0.35514031 0.3998961  0.5876    ]\n",
      "regrets is :  [ 0.          0.0164569   0.25714323  0.1877039  -0.0156094 ] \n",
      "\n",
      "best reward is :  [0.7321046  0.62753313 0.62660839 0.58       0.52896055]\n",
      "reward is :  [0.58       0.38846491 0.49719298 0.45607747 0.50378136]\n",
      "regrets is :  [0.1521046  0.23906822 0.1294154  0.12392253 0.02517919] \n",
      "\n",
      "best reward is :  [0.7676     0.5798961  0.57719298 0.54       0.49014658]\n",
      "reward is :  [0.54       0.48127334 0.57719298 0.5798961  0.7676    ]\n",
      "regrets is :  [ 0.2276      0.09862276  0.         -0.0398961  -0.27745342] \n",
      "\n",
      "best reward is :  [0.7321046  0.62753313 0.62660839 0.58       0.52896055]\n",
      "reward is :  [0.58       0.41228354 0.49719298 0.4798961  0.50378136]\n",
      "regrets is :  [0.1521046  0.21524958 0.1294154  0.1001039  0.02517919] \n",
      "\n",
      "best reward is :  [0.61668852 0.58928203 0.53688203 0.53125897 0.52645219]\n",
      "reward is :  [0.58928203 0.41228354 0.47719298 0.4598961  0.53688203]\n",
      "regrets is :  [ 0.02740649  0.17699849  0.05968905  0.07136286 -0.01042984] \n",
      "\n",
      "best reward is :  [0.74977085 0.61016541 0.59560112 0.53305157 0.46465568]\n",
      "reward is :  [0.74977085 0.59560112 0.43560112 0.53305157 0.43360518]\n",
      "regrets is :  [0.         0.01456429 0.16       0.         0.0310505 ] \n",
      "\n",
      "best reward is :  [0.65420007 0.56819876 0.53121752 0.47524083 0.37121752]\n",
      "reward is :  [0.65420007 0.37121752 0.53121752 0.56819876 0.21461538]\n",
      "regrets is :  [ 0.          0.19698124  0.         -0.09295793  0.15660213] \n",
      "\n",
      "best reward is :  [0.66977085 0.56614609 0.5467883  0.47237896 0.3867883 ]\n",
      "reward is :  [0.66977085 0.3867883  0.5467883  0.56614609 0.21997112]\n",
      "regrets is :  [ 0.          0.17935779  0.         -0.09376713  0.16681718] \n",
      "\n",
      "best reward is :  [0.5216886  0.4984631  0.49770085 0.46165593 0.44870566]\n",
      "reward is :  [0.24491803 0.25988282 0.0828248  0.18186439 0.23461538]\n",
      "regrets is :  [0.27677057 0.23858029 0.41487605 0.27979154 0.21409027] \n",
      "\n",
      "best reward is :  [0.68069044 0.66205729 0.65780928 0.60062753 0.54799941]\n",
      "reward is :  [0.42977085 0.10193548 0.3067883  0.33718855 0.31461538]\n",
      "regrets is :  [0.2509196  0.56012181 0.35102098 0.26343898 0.23338402] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best reward is :  [0.49216009 0.49153526 0.48191774 0.46429019 0.45924101]\n",
      "reward is :  [0.41804608 0.30891566 0.36513827 0.30107784 0.21752989]\n",
      "regrets is :  [0.07411401 0.18261959 0.11677947 0.16321235 0.24171112] \n",
      "\n",
      "best reward is :  [0.80756468 0.80242968 0.67376848 0.66593066 0.62348363]\n",
      "reward is :  [0.80242968 0.67376848 0.80756468 0.66593066 0.59485281]\n",
      "regrets is :  [ 0.005135    0.1286612  -0.1337962   0.          0.02863082] \n",
      "\n",
      "best reward is :  [0.56752536 0.54296008 0.4517714  0.42028704 0.39942916]\n",
      "reward is :  [0.21974791 0.04241672 0.24756468 0.02107784 0.03      ]\n",
      "regrets is :  [0.34777745 0.50054336 0.20420672 0.3992092  0.36942916] \n",
      "\n",
      "best reward is :  [0.69513222 0.46958703 0.4322578  0.40420712 0.39761239]\n",
      "reward is :  [0.20645708 0.06219767 0.17985472 0.02107784 0.04385641]\n",
      "regrets is :  [0.48867514 0.40738935 0.25240308 0.38312928 0.35375598] \n",
      "\n",
      "best reward is :  [0.49152619 0.49031304 0.48235796 0.45924101 0.45056656]\n",
      "reward is :  [0.40876404 0.2342714  0.38271186 0.19466517 0.25      ]\n",
      "regrets is :  [0.08276215 0.25604164 0.0996461  0.26457584 0.20056656] \n",
      "\n",
      "best reward is :  [0.72561798 0.62327044 0.61981156 0.61044753 0.49223412]\n",
      "reward is :  [0.36631382 0.14561901 0.49223412 0.05926803 0.28546038]\n",
      "regrets is :  [0.35930416 0.47765143 0.12757744 0.5511795  0.20677374] \n",
      "\n",
      "best reward is :  [0.66151615 0.56461198 0.56335126 0.46575262 0.46021471]\n",
      "reward is :  [0.56461198 0.12016315 0.66151615 0.22569444 0.46575262]\n",
      "regrets is :  [ 0.09690417  0.44444883 -0.09816489  0.24005818 -0.00553791] \n",
      "\n",
      "best reward is :  [0.72329588 0.68662029 0.54625229 0.53659016 0.50874042]\n",
      "reward is :  [0.27532995 0.72329588 0.1117536  0.53659016 0.05647059]\n",
      "regrets is :  [ 0.44796593 -0.03667559  0.43449869  0.          0.45226983] \n",
      "\n",
      "best reward is :  [0.6168176  0.60439193 0.60144298 0.59570939 0.57      ]\n",
      "reward is :  [0.36431974 0.46148203 0.26910139 0.60144298 0.22575647]\n",
      "regrets is :  [ 0.25249785  0.1429099   0.33234159 -0.00573359  0.34424353] \n",
      "\n",
      "best reward is :  [0.68472088 0.66329588 0.54677632 0.50937833 0.49803562]\n",
      "reward is :  [0.21532995 0.66329588 0.13923308 0.47659016 0.06707719]\n",
      "regrets is :  [0.46939093 0.         0.40754323 0.03278817 0.43095843] \n",
      "\n",
      "best reward is :  [0.7030804  0.59888345 0.49135468 0.47992229 0.46930304]\n",
      "reward is :  [0.44898979 0.7030804  0.24180344 0.22807794 0.07914894]\n",
      "regrets is :  [ 0.2540906  -0.10419694  0.24955124  0.25184435  0.3901541 ] \n",
      "\n",
      "best reward is :  [0.72       0.59634783 0.57416102 0.55918502 0.48186185]\n",
      "reward is :  [0.72       0.41529501 0.57416102 0.55918502 0.39914894]\n",
      "regrets is :  [0.         0.18105282 0.         0.         0.08271291] \n",
      "\n",
      "best reward is :  [0.72906293 0.60300116 0.57366563 0.57281457 0.45157622]\n",
      "reward is :  [0.57366563 0.27431962 0.43318563 0.41820963 0.57281457]\n",
      "regrets is :  [ 0.1553973   0.32868153  0.14048     0.15460494 -0.12123835] \n",
      "\n",
      "best reward is :  [0.74550681 0.60036025 0.49130085 0.48485281 0.47846874]\n",
      "reward is :  [0.48485281 0.74550681 0.25746733 0.23918502 0.07914894]\n",
      "regrets is :  [ 0.26065399 -0.14514655  0.23383352  0.2456678   0.3993198 ] \n",
      "\n",
      "best reward is :  [0.73333333 0.68217292 0.57330441 0.50581243 0.50065399]\n",
      "reward is :  [0.73333333 0.50065399 0.42487574 0.484544   0.41375218]\n",
      "regrets is :  [0.         0.18151893 0.14842867 0.02126843 0.08690181] \n",
      "\n",
      "best reward is :  [0.72731105 0.720417   0.64341866 0.61900534 0.58416   ]\n",
      "reward is :  [0.72731105 0.53454545 0.3571647  0.720417   0.25504518]\n",
      "regrets is :  [ 0.          0.18587155  0.28625396 -0.10141166  0.32911482] \n",
      "\n",
      "best reward is :  [0.62731105 0.600417   0.58700774 0.5620657  0.53065583]\n",
      "reward is :  [0.62731105 0.45454545 0.4171647  0.600417   0.25277372]\n",
      "regrets is :  [ 0.          0.14587155  0.16984304 -0.0383513   0.27788211] \n",
      "\n",
      "best reward is :  [0.6971647  0.6659409  0.55553127 0.46731105 0.46392323]\n",
      "reward is :  [0.46731105 0.29454545 0.6971647  0.320417   0.6659409 ]\n",
      "regrets is :  [ 0.22985365  0.37139545 -0.14163343  0.14689405 -0.20201767] \n",
      "\n",
      "best reward is :  [0.55216387 0.4861545  0.4417561  0.440417   0.41746038]\n",
      "reward is :  [0.55216387 0.37939827 0.4861545  0.440417   0.41746038]\n",
      "regrets is :  [ 0.          0.10675623 -0.0443984   0.          0.        ] \n",
      "\n",
      "best reward is :  [0.52731105 0.4861545  0.4417561  0.41746038 0.39361718]\n",
      "reward is :  [0.52731105 0.37939827 0.4861545  0.380417   0.41746038]\n",
      "regrets is :  [ 0.          0.10675623 -0.0443984   0.03704338 -0.0238432 ] \n",
      "\n",
      "best reward is :  [0.70906088 0.5783221  0.56115315 0.53345127 0.5330909 ]\n",
      "reward is :  [0.27328201 0.41660672 0.4586463  0.17794733 0.12296373]\n",
      "regrets is :  [0.43577886 0.16171537 0.10250686 0.35550394 0.41012717] \n",
      "\n",
      "best reward is :  [0.7003323  0.58928203 0.5729778  0.56915532 0.49662936]\n",
      "reward is :  [0.58928203 0.44588876 0.30257259 0.7003323  0.49662936]\n",
      "regrets is :  [ 0.11105027  0.14339328  0.27040521 -0.13117698  0.        ] \n",
      "\n",
      "best reward is :  [0.74928203 0.55903313 0.524614   0.51891243 0.46257259]\n",
      "reward is :  [0.74928203 0.55903313 0.46257259 0.524614   0.51891243]\n",
      "regrets is :  [ 0.          0.          0.06204141 -0.00570157 -0.05633984] \n",
      "\n",
      "best reward is :  [0.62695619 0.59528302 0.55878926 0.54793879 0.51015775]\n",
      "reward is :  [0.46       0.18196246 0.62695619 0.17618136 0.12524717]\n",
      "regrets is :  [ 0.16695619  0.41332056 -0.06816694  0.37175743  0.38491058] \n",
      "\n",
      "best reward is :  [0.78539014 0.55575974 0.49075    0.47303562 0.45794733]\n",
      "reward is :  [0.45794733 0.45455406 0.27123789 0.55575974 0.78539014]\n",
      "regrets is :  [ 0.32744281  0.10120568  0.21951211 -0.08272412 -0.32744281] \n",
      "\n",
      "best reward is :  [0.62107239 0.61076626 0.60523077 0.58811828 0.55354402]\n",
      "reward is :  [0.44409457 0.61076626 0.60523077 0.55354402 0.62107239]\n",
      "regrets is :  [ 0.17697781  0.          0.          0.03457426 -0.06752837] \n",
      "\n",
      "best reward is :  [0.70058426 0.58670973 0.57621464 0.54092325 0.53480035]\n",
      "reward is :  [0.43619748 0.43905053 0.57621464 0.36037683 0.43205625]\n",
      "regrets is :  [0.26438678 0.1476592  0.         0.18054641 0.1027441 ] \n",
      "\n",
      "best reward is :  [0.49743293 0.47491217 0.47440572 0.45017827 0.41865322]\n",
      "reward is :  [0.47491217 0.49743293 0.31189744 0.39586715 0.47440572]\n",
      "regrets is :  [ 0.02252075 -0.02252075  0.16250828  0.05431112 -0.0557525 ] \n",
      "\n",
      "best reward is :  [0.516122   0.45276602 0.4459252  0.4135883  0.35873484]\n",
      "reward is :  [0.45276602 0.516122   0.23058651 0.32354402 0.4459252 ]\n",
      "regrets is :  [ 0.06335597 -0.06335597  0.21533869  0.09004429 -0.08719036] \n",
      "\n",
      "best reward is :  [0.62549879 0.61189744 0.56642272 0.52562465 0.48916721]\n",
      "reward is :  [0.48791321 0.56642272 0.61189744 0.34253381 0.41006218]\n",
      "regrets is :  [ 0.13758558  0.04547472 -0.04547472  0.18309084  0.07910503] \n",
      "\n",
      "best reward is :  [0.70093399 0.6259441  0.6034154  0.55246018 0.53697631]\n",
      "reward is :  [0.39825033 0.40219784 0.53164145 0.6034154  0.35466237]\n",
      "regrets is :  [ 0.30268367  0.22374626  0.07177395 -0.05095522  0.18231394] \n",
      "\n",
      "best reward is :  [0.68723404 0.61358845 0.57848101 0.48391968 0.46267446]\n",
      "reward is :  [0.61358845 0.39112782 0.38628571 0.68723404 0.57848101]\n",
      "regrets is :  [ 0.0736456   0.22246063  0.1921953  -0.20331436 -0.11580655] \n",
      "\n",
      "best reward is :  [0.88206897 0.63113853 0.57848101 0.51017544 0.50097991]\n",
      "reward is :  [0.88206897 0.51017544 0.63113853 0.38723404 0.57848101]\n",
      "regrets is :  [ 0.          0.12096309 -0.05265752  0.1229414  -0.0775011 ] \n",
      "\n",
      "best reward is :  [0.76628571 0.64206897 0.63684211 0.63466544 0.59848101]\n",
      "reward is :  [0.64206897 0.63684211 0.76628571 0.52723404 0.59848101]\n",
      "regrets is :  [ 0.12421675  0.00522686 -0.12944361  0.10743139  0.        ] \n",
      "\n",
      "best reward is :  [0.60925482 0.55387593 0.44454201 0.43832004 0.43352941]\n",
      "reward is :  [0.19903953 0.37684211 0.13835706 0.28966045 0.11055236]\n",
      "regrets is :  [0.41021529 0.17703382 0.30618495 0.14865959 0.32297705] \n",
      "\n",
      "best reward is :  [0.80030432 0.78548987 0.74993837 0.66734205 0.62228871]\n",
      "reward is :  [0.78548987 0.74993837 0.80030432 0.62228871 0.44701239]\n",
      "regrets is :  [ 0.01481445  0.0355515  -0.05036595  0.04505334  0.17527632] \n",
      "\n",
      "best reward is :  [0.53167761 0.4823972  0.47863425 0.4678042  0.46751196]\n",
      "reward is :  [0.47863425 0.46751196 0.35787791 0.4398623  0.28015677]\n",
      "regrets is :  [0.05304337 0.01488524 0.12075633 0.0279419  0.1873552 ] \n",
      "\n",
      "best reward is :  [0.94228871 0.78258317 0.74993837 0.62106065 0.50909976]\n",
      "reward is :  [0.62106065 0.74993837 0.4199464  0.94228871 0.78258317]\n",
      "regrets is :  [ 0.32122806  0.0326448   0.32999197 -0.32122806 -0.27348341] \n",
      "\n",
      "best reward is :  [0.53167761 0.49620784 0.48508556 0.4823972  0.4678042 ]\n",
      "reward is :  [0.49620784 0.48508556 0.35787791 0.4574359  0.29773036]\n",
      "regrets is :  [0.03546977 0.01112228 0.12720764 0.0249613  0.17007384] \n",
      "\n",
      "best reward is :  [0.77620784 0.77545151 0.72508556 0.66829516 0.61404552]\n",
      "reward is :  [0.77620784 0.72508556 0.77545151 0.5974359  0.43773036]\n",
      "regrets is :  [ 0.          0.05036595 -0.05036595  0.07085926  0.17631516] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best reward is :  [0.79090909 0.78944948 0.71371141 0.55304304 0.53295715]\n",
      "reward is :  [0.78944948 0.53155116 0.71371141 0.79090909 0.38569579]\n",
      "regrets is :  [ 0.00145961  0.25789832  0.         -0.23786605  0.14726135] \n",
      "\n",
      "best reward is :  [0.69211737 0.67155116 0.66431756 0.63346519 0.57371141]\n",
      "reward is :  [0.56944948 0.67155116 0.57371141 0.49989889 0.18542367]\n",
      "regrets is :  [0.12266789 0.         0.09060614 0.1335663  0.38828774] \n",
      "\n",
      "best reward is :  [0.7177588  0.6186698  0.60014659 0.57303624 0.49803346]\n",
      "reward is :  [0.14754016 0.3377373  0.13989756 0.2157619  0.41054861]\n",
      "regrets is :  [0.57021864 0.2809325  0.46024903 0.35727433 0.08748485] \n",
      "\n",
      "best reward is :  [0.63090909 0.60944948 0.59155116 0.55613782 0.48668271]\n",
      "reward is :  [0.60944948 0.59155116 0.55613782 0.63090909 0.38569579]\n",
      "regrets is :  [ 0.02145961  0.01789832  0.03541333 -0.07477127  0.10098691] \n",
      "\n",
      "best reward is :  [0.61454407 0.60270121 0.51843927 0.50189296 0.46604872]\n",
      "reward is :  [0.51843927 0.36054095 0.60270121 0.50189296 0.3589778 ]\n",
      "regrets is :  [ 0.0961048   0.24216026 -0.08426194  0.          0.10707092] \n",
      "\n",
      "best reward is :  [0.69161716 0.67154365 0.61040814 0.58328757 0.53120257]\n",
      "reward is :  [0.46928203 0.29704674 0.23469683 0.21146846 0.05666214]\n",
      "regrets is :  [0.22233513 0.37449692 0.37571131 0.37181911 0.47454043] \n",
      "\n",
      "best reward is :  [0.68168621 0.49236214 0.45070478 0.44535574 0.43126278]\n",
      "reward is :  [0.44535574 0.25776471 0.2267495  0.20352113 0.08186542]\n",
      "regrets is :  [0.23633047 0.23459744 0.22395528 0.24183461 0.34939736] \n",
      "\n",
      "best reward is :  [0.51893476 0.51270672 0.51183399 0.49336965 0.49067415]\n",
      "reward is :  [0.28898979 0.07871916 0.0967495  0.01352113 0.07525906]\n",
      "regrets is :  [0.22994497 0.43398756 0.41508449 0.47984852 0.41541509] \n",
      "\n",
      "best reward is :  [0.58       0.54096367 0.51737052 0.44730104 0.39518246]\n",
      "reward is :  [0.58       0.38240572 0.3467495  0.39352113 0.51737052]\n",
      "regrets is :  [ 0.          0.15855795  0.17062102  0.05377992 -0.12218806] \n",
      "\n",
      "best reward is :  [0.71464102 0.55312044 0.53887686 0.51139051 0.48314172]\n",
      "reward is :  [0.71464102 0.55312044 0.51139051 0.53887686 0.47201153]\n",
      "regrets is :  [ 0.          0.          0.02748635 -0.02748635  0.01113019] \n",
      "\n",
      "best reward is :  [0.70088339 0.5977899  0.57425765 0.56426458 0.47840909]\n",
      "reward is :  [0.42353394 0.20850152 0.10947249 0.24451948 0.56426458]\n",
      "regrets is :  [ 0.27734946  0.38928837  0.46478516  0.3197451  -0.08585549] \n",
      "\n",
      "best reward is :  [0.56248003 0.52466377 0.51334199 0.47764185 0.45182182]\n",
      "reward is :  [0.32485281 0.03579934 0.26372036 0.07988597 0.34426458]\n",
      "regrets is :  [0.23762722 0.48886443 0.24962162 0.39775588 0.10755724] \n",
      "\n",
      "best reward is :  [0.68379222 0.54285223 0.51619048 0.48485281 0.47588683]\n",
      "reward is :  [0.48485281 0.19579934 0.51619048 0.32318615 0.19941176]\n",
      "regrets is :  [0.19893941 0.34705289 0.         0.16166667 0.27647507] \n",
      "\n",
      "best reward is :  [0.63941176 0.59987777 0.51954073 0.51763903 0.47661536]\n",
      "reward is :  [0.44535574 0.29521951 0.10237662 0.23891316 0.63941176]\n",
      "regrets is :  [ 0.19405603  0.30465826  0.41716411  0.27872587 -0.1627964 ] \n",
      "\n",
      "best reward is :  [0.47904701 0.44292683 0.44231624 0.39963861 0.39594045]\n",
      "reward is :  [0.28898979 0.01521951 0.28518027 0.10368907 0.30840156]\n",
      "regrets is :  [0.19005721 0.42770732 0.15713597 0.29594954 0.08753889] \n",
      "\n",
      "best reward is :  [0.66208955 0.64123077 0.62896219 0.54885365 0.54488034]\n",
      "reward is :  [0.30963855 0.31873001 0.08963855 0.27586866 0.41038228]\n",
      "regrets is :  [0.35245099 0.32250076 0.53932364 0.272985   0.13449805] \n",
      "\n",
      "best reward is :  [0.64963855 0.50880689 0.41923518 0.39651436 0.39547151]\n",
      "reward is :  [0.31892059 0.33434641 0.64963855 0.26220302 0.0995738 ]\n",
      "regrets is :  [ 0.33071797  0.17446048 -0.23040338  0.13431133  0.29589772] \n",
      "\n",
      "best reward is :  [0.55251069 0.46330419 0.44094104 0.43873001 0.42330419]\n",
      "reward is :  [0.42330419 0.43873001 0.46330419 0.44094104 0.18692584]\n",
      "regrets is :  [ 0.12920651  0.02457418 -0.02236315 -0.00221103  0.23637835] \n",
      "\n",
      "best reward is :  [0.78963855 0.68705584 0.66991719 0.49449137 0.48995934]\n",
      "reward is :  [0.78963855 0.66991719 0.49449137 0.68705584 0.42112001]\n",
      "regrets is :  [ 0.          0.01713865  0.17542582 -0.19256447  0.06883933] \n",
      "\n",
      "best reward is :  [0.55373159 0.41206496 0.39518261 0.38506438 0.37837838]\n",
      "reward is :  [0.28963855 0.38506438 0.41206496 0.22705584 0.12243094]\n",
      "regrets is :  [ 0.26409304  0.02700058 -0.01688236  0.15800854  0.25594744] \n",
      "\n",
      "End of the simulations, time elapsed: 76.426 seconds.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "regret, regrets, rewards, regrets_normal = run_several_experiments_hist_ML_online(LinearRegression, nb_exp = 20, \n",
    "                                                                                  evolutive_env = False, nb_steps_history=1000)\n",
    "plot_regret(regret, regrets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation 0 started, time elapsed: 0.000 seconds.\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 1s 137us/step - loss: 0.0480 - val_loss: 0.0291\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 53us/step - loss: 0.0290 - val_loss: 0.0289\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0285 - val_loss: 0.0286\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0286 - val_loss: 0.0296\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0286 - val_loss: 0.0293\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0289 - val_loss: 0.0293\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0289 - val_loss: 0.0282\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0292 - val_loss: 0.0281\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0288 - val_loss: 0.0300\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0290 - val_loss: 0.0320\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0295 - val_loss: 0.0280\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0285 - val_loss: 0.0279\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0288 - val_loss: 0.0297\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0285 - val_loss: 0.0329\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0295 - val_loss: 0.0292\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0285 - val_loss: 0.0297\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0287 - val_loss: 0.0299\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 56us/step - loss: 0.0289 - val_loss: 0.0287\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0289 - val_loss: 0.0308\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0289 - val_loss: 0.0297\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0287 - val_loss: 0.0282\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0288 - val_loss: 0.0308\n",
      "best reward is :  [0.667      0.64869565 0.51101322 0.46307692 0.46021053]\n",
      "reward is :  [0.30981466 0.667      0.51101322 0.02086957 0.39190083]\n",
      "regrets is :  [ 0.35718534 -0.01830435  0.          0.44220736  0.0683097 ] \n",
      "\n",
      "best reward is :  [0.84869565 0.66021053 0.49493333 0.4718232  0.44863568]\n",
      "reward is :  [0.06506024 0.24053262 0.4718232  0.02086957 0.41856749]\n",
      "regrets is :  [0.78363541 0.4196779  0.02311013 0.45095364 0.03006819] \n",
      "\n",
      "best reward is :  [0.36869565 0.30426396 0.30086957 0.24653061 0.24506024]\n",
      "reward is :  [0.30426396 0.24506024 0.1918232  0.30086957 0.01190083]\n",
      "regrets is :  [ 0.06443169  0.05920372  0.10904636 -0.05433895  0.23315941] \n",
      "\n",
      "best reward is :  [0.65010526 0.63201229 0.53192982 0.46205689 0.42248009]\n",
      "reward is :  [0.17515789 0.24617068 0.46205689 0.63201229 0.17190083]\n",
      "regrets is :  [ 0.47494737  0.38584161  0.06987293 -0.1699554   0.25057926] \n",
      "\n",
      "best reward is :  [0.50205689 0.41283735 0.37986395 0.37653333 0.37333333]\n",
      "reward is :  [0.41283735 0.01515789 0.18205689 0.01190083 0.30639214]\n",
      "regrets is :  [0.08921955 0.39767945 0.19780705 0.36463251 0.06694119] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 1s 138us/step - loss: 0.0859 - val_loss: 0.0316\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0279 - val_loss: 0.0279\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0273 - val_loss: 0.0284\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0283 - val_loss: 0.0279\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0276 - val_loss: 0.0288\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0285 - val_loss: 0.0290\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0275 - val_loss: 0.0285\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0275 - val_loss: 0.0286\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0274 - val_loss: 0.0298\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0277 - val_loss: 0.0279\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0275 - val_loss: 0.0290\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0282 - val_loss: 0.0315\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0280 - val_loss: 0.0297\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0279 - val_loss: 0.0279\n",
      "best reward is :  [0.62297872 0.61536602 0.61230769 0.59805616 0.52886878]\n",
      "reward is :  [0.4341637  0.05503185 0.01288591 0.16       0.4613913 ]\n",
      "regrets is :  [0.18881502 0.56033417 0.59942179 0.43805616 0.06747747] \n",
      "\n",
      "best reward is :  [0.53617486 0.43503185 0.4        0.37230769 0.33536602]\n",
      "reward is :  [0.0341637  0.43503185 0.29288591 0.4        0.0813913 ]\n",
      "regrets is :  [ 0.50201116  0.          0.10711409 -0.02769231  0.25397471] \n",
      "\n",
      "best reward is :  [0.49010526 0.4695082  0.37230769 0.33536602 0.30498141]\n",
      "reward is :  [0.0341637  0.25288591 0.49010526 0.18021053 0.0813913 ]\n",
      "regrets is :  [ 0.45594156  0.21662229 -0.11779757  0.15515549  0.22359011] \n",
      "\n",
      "best reward is :  [0.39288591 0.33548387 0.3095082  0.2413913  0.21230769]\n",
      "reward is :  [0.0341637  0.39288591 0.33548387 0.2413913  0.02021053]\n",
      "regrets is :  [ 0.3587222  -0.05740204 -0.02597567  0.          0.19209717] \n",
      "\n",
      "best reward is :  [0.37617486 0.29288591 0.25548387 0.21230769 0.2001194 ]\n",
      "reward is :  [0.0341637  0.29288591 0.25548387 0.02021053 0.07085384]\n",
      "regrets is :  [0.34201116 0.         0.         0.19209717 0.12926557] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 96us/step - loss: 0.1143 - val_loss: 0.0349\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0288 - val_loss: 0.0277\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0272 - val_loss: 0.0276\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0270 - val_loss: 0.0270\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0274 - val_loss: 0.0293\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0273 - val_loss: 0.0272\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0274 - val_loss: 0.0278\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 17us/step - loss: 0.0274 - val_loss: 0.0290\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0275 - val_loss: 0.0283\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 17us/step - loss: 0.0274 - val_loss: 0.0270\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0282 - val_loss: 0.0278\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0278 - val_loss: 0.0278\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0274 - val_loss: 0.0278\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0275 - val_loss: 0.0305\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0281 - val_loss: 0.0272\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0275 - val_loss: 0.0277\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0278 - val_loss: 0.0276\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0276 - val_loss: 0.0297\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0283 - val_loss: 0.0288\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500/4500 [==============================] - 0s 17us/step - loss: 0.0280 - val_loss: 0.0294\n",
      "best reward is :  [0.66079422 0.54491593 0.50325581 0.37161644 0.36945455]\n",
      "reward is :  [0.072      0.66079422 0.03732181 0.2829404  0.02258824]\n",
      "regrets is :  [ 0.58879422 -0.11587829  0.465934    0.08867604  0.34686631] \n",
      "\n",
      "best reward is :  [0.64945455 0.5719084  0.50325581 0.5029404  0.3944    ]\n",
      "reward is :  [0.072      0.19732181 0.5029404  0.0091954  0.02258824]\n",
      "regrets is :  [5.77454545e-01 3.74586583e-01 3.15416602e-04 4.93744995e-01\n",
      " 3.71811765e-01] \n",
      "\n",
      "best reward is :  [0.51732181 0.3990984  0.3692549  0.36809852 0.35586207]\n",
      "reward is :  [0.312      0.51732181 0.0659542  0.3692549  0.36809852]\n",
      "regrets is :  [ 0.20532181 -0.11822342  0.3033007  -0.00115638 -0.01223645] \n",
      "\n",
      "best reward is :  [0.71612121 0.63857506 0.57262087 0.40325581 0.39983122]\n",
      "reward is :  [0.072      0.19732181 0.57262087 0.02258824 0.20809852]\n",
      "regrets is :  [0.64412121 0.44125325 0.         0.38066758 0.1917327 ] \n",
      "\n",
      "best reward is :  [0.71612121 0.63857506 0.57262087 0.40325581 0.39983122]\n",
      "reward is :  [0.072      0.19732181 0.57262087 0.02258824 0.20809852]\n",
      "regrets is :  [0.64412121 0.44125325 0.         0.38066758 0.1917327 ] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 100us/step - loss: 0.0573 - val_loss: 0.0260\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0272 - val_loss: 0.0267\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0273 - val_loss: 0.0260\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0273 - val_loss: 0.0269\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0271 - val_loss: 0.0256\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0272 - val_loss: 0.0279\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0269 - val_loss: 0.0275\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0280 - val_loss: 0.0268\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0273 - val_loss: 0.0304\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0273 - val_loss: 0.0272\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0274 - val_loss: 0.0268\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0278 - val_loss: 0.0262\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0273 - val_loss: 0.0253\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 17us/step - loss: 0.0277 - val_loss: 0.0270\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0273 - val_loss: 0.0283\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0274 - val_loss: 0.0269\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0272 - val_loss: 0.0281\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 17us/step - loss: 0.0274 - val_loss: 0.0274\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0272 - val_loss: 0.0294\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0274 - val_loss: 0.0266\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0273 - val_loss: 0.0262\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0276 - val_loss: 0.0271\n",
      "Epoch 23/100\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0279 - val_loss: 0.0262\n",
      "best reward is :  [0.52100629 0.4717193  0.44936937 0.44832215 0.41546012]\n",
      "reward is :  [0.29843318 0.36505263 0.14543933 0.31632653 0.31667954]\n",
      "regrets is :  [0.22257311 0.10666667 0.30393004 0.13199562 0.09878059] \n",
      "\n",
      "best reward is :  [0.4227027  0.41645714 0.38867925 0.33433962 0.32505263]\n",
      "reward is :  [0.04129032 0.00567376 0.41645714 0.32505263 0.30187342]\n",
      "regrets is :  [ 0.38141238  0.41078338 -0.0277779   0.00928699  0.02317921] \n",
      "\n",
      "best reward is :  [0.53914754 0.53532338 0.50191841 0.44614314 0.37958095]\n",
      "reward is :  [0.44614314 0.24567376 0.17914894 0.00505263 0.02187342]\n",
      "regrets is :  [0.0930044  0.28964962 0.32276948 0.4410905  0.35770753] \n",
      "\n",
      "best reward is :  [0.4227027  0.42149254 0.38867925 0.33433962 0.32505263]\n",
      "reward is :  [0.04238961 0.42149254 0.18991098 0.32505263 0.30187342]\n",
      "regrets is :  [0.38031309 0.         0.19876827 0.00928699 0.02317921] \n",
      "\n",
      "best reward is :  [0.5835514  0.5827027  0.46346667 0.43353293 0.42629108]\n",
      "reward is :  [0.04238961 0.02991098 0.5835514  0.32505263 0.30187342]\n",
      "regrets is :  [ 0.54116179  0.55279172 -0.12008474  0.1084803   0.12441766] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 1s 143us/step - loss: 0.1406 - val_loss: 0.0409\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0298 - val_loss: 0.0295\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0259 - val_loss: 0.0273\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0258 - val_loss: 0.0285\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0262 - val_loss: 0.0268\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0260 - val_loss: 0.0288\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0260 - val_loss: 0.0272\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0264 - val_loss: 0.0287\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0261 - val_loss: 0.0291\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0260 - val_loss: 0.0274\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0263 - val_loss: 0.0283\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0261 - val_loss: 0.0264\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0263 - val_loss: 0.0304\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0260 - val_loss: 0.0268\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0262 - val_loss: 0.0288\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0264 - val_loss: 0.0286\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0268 - val_loss: 0.0286\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0265 - val_loss: 0.0264\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0268 - val_loss: 0.0277\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0263 - val_loss: 0.0299\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0265 - val_loss: 0.0265\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0261 - val_loss: 0.0299\n",
      "best reward is :  [0.55797753 0.49220892 0.44780083 0.41928315 0.3611465 ]\n",
      "reward is :  [0.06479705 0.55797753 0.05142857 0.15636364 0.44780083]\n",
      "regrets is :  [ 0.49318048 -0.06576861  0.39637226  0.26291952 -0.08665433] \n",
      "\n",
      "best reward is :  [0.38666667 0.37220892 0.36586667 0.34711111 0.3432    ]\n",
      "reward is :  [0.18479705 0.12586667 0.03636364 0.01142857 0.32780083]\n",
      "regrets is :  [0.20186962 0.24634226 0.32950303 0.33568254 0.01539917] \n",
      "\n",
      "best reward is :  [0.6192     0.49220892 0.44780083 0.41928315 0.3611465 ]\n",
      "reward is :  [0.06479705 0.6192     0.15636364 0.05142857 0.44780083]\n",
      "regrets is :  [ 0.55440295 -0.12699108  0.29143719  0.36785458 -0.08665433] \n",
      "\n",
      "best reward is :  [0.5632     0.52382609 0.52102564 0.5175419  0.50098361]\n",
      "reward is :  [0.02479705 0.19636364 0.17142857 0.37142857 0.3390099 ]\n",
      "regrets is :  [0.53840295 0.32746245 0.34959707 0.14611333 0.16197371] \n",
      "\n",
      "best reward is :  [0.50479705 0.41636364 0.39462687 0.39142857 0.3411465 ]\n",
      "reward is :  [0.50479705 0.41636364 0.39142857 0.05142857 0.01142857]\n",
      "regrets is :  [0.         0.         0.00319829 0.34       0.32971793] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 72us/step - loss: 0.0472 - val_loss: 0.0332\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 17us/step - loss: 0.0259 - val_loss: 0.0321\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 15us/step - loss: 0.0254 - val_loss: 0.0317\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 17us/step - loss: 0.0255 - val_loss: 0.0300\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0256 - val_loss: 0.0305\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0256 - val_loss: 0.0311\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 17us/step - loss: 0.0257 - val_loss: 0.0297\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0256 - val_loss: 0.0301\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 19us/step - loss: 0.0255 - val_loss: 0.0302\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0256 - val_loss: 0.0311\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0252 - val_loss: 0.0304\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0257 - val_loss: 0.0305\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0258 - val_loss: 0.0321\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0257 - val_loss: 0.0300\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0255 - val_loss: 0.0294\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0254 - val_loss: 0.0308\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0256 - val_loss: 0.0316\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0258 - val_loss: 0.0301\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0257 - val_loss: 0.0323\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0257 - val_loss: 0.0308\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0258 - val_loss: 0.0307\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0260 - val_loss: 0.0301\n",
      "Epoch 23/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0255 - val_loss: 0.0309\n",
      "Epoch 24/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0256 - val_loss: 0.0317\n",
      "Epoch 25/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0256 - val_loss: 0.0318\n",
      "best reward is :  [0.60148148 0.47622642 0.47272727 0.44562347 0.42360656]\n",
      "reward is :  [0.16941176 0.01704142 0.06381232 0.02991098 0.10364098]\n",
      "regrets is :  [0.43206972 0.45918499 0.40891496 0.41571249 0.31996558] \n",
      "\n",
      "best reward is :  [0.36991098 0.33704142 0.24112676 0.22722359 0.22312329]\n",
      "reward is :  [0.18941176 0.33704142 0.14381232 0.36991098 0.22291205]\n",
      "regrets is :  [ 0.18049921  0.          0.09731444 -0.14268739  0.00021124] \n",
      "\n",
      "best reward is :  [0.52148148 0.39272727 0.37622642 0.34932039 0.34562347]\n",
      "reward is :  [0.16941176 0.1827668  0.16957871 0.06381232 0.02991098]\n",
      "regrets is :  [0.35206972 0.20996047 0.2066477  0.28550807 0.31571249] \n",
      "\n",
      "best reward is :  [0.57047898 0.30991098 0.28941176 0.20148148 0.18957871]\n",
      "reward is :  [0.28941176 0.18957871 0.1827668  0.57047898 0.30991098]\n",
      "regrets is :  [ 0.28106722  0.12033227  0.10664497 -0.3689975  -0.12033227] \n",
      "\n",
      "best reward is :  [0.29862434 0.28316151 0.28       0.27306667 0.27306667]\n",
      "reward is :  [0.04941176 0.2372093  0.04957871 0.12943347 0.22991098]\n",
      "regrets is :  [0.24921257 0.04595221 0.23042129 0.1436332  0.04315569] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 89us/step - loss: 0.0715 - val_loss: 0.0254\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0264 - val_loss: 0.0234\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0264 - val_loss: 0.0234\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0264 - val_loss: 0.0242\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0266 - val_loss: 0.0275\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0268 - val_loss: 0.0232\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0273 - val_loss: 0.0240\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0269 - val_loss: 0.0228\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0264 - val_loss: 0.0231\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0270 - val_loss: 0.0262\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0275 - val_loss: 0.0237\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0277 - val_loss: 0.0251\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0265 - val_loss: 0.0242\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0264 - val_loss: 0.0232\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0266 - val_loss: 0.0239\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0270 - val_loss: 0.0230\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0265 - val_loss: 0.0259\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0267 - val_loss: 0.0237\n",
      "best reward is :  [0.60972973 0.59610147 0.51093923 0.4174026  0.41216958]\n",
      "reward is :  [0.22180258 0.09103448 0.60972973 0.26272189 0.24      ]\n",
      "regrets is :  [ 0.38792715  0.50506699 -0.0987905   0.1546807   0.17216958] \n",
      "\n",
      "best reward is :  [0.56681081 0.5164557  0.51174935 0.49371429 0.4337133 ]\n",
      "reward is :  [0.065625   0.018      0.24949153 0.34258824 0.24      ]\n",
      "regrets is :  [0.50118581 0.4984557  0.26225782 0.15112605 0.1937133 ] \n",
      "\n",
      "best reward is :  [0.42949153 0.42       0.345625   0.258      0.19174935]\n",
      "reward is :  [0.345625   0.258      0.42949153 0.18258824 0.42      ]\n",
      "regrets is :  [ 0.08386653  0.162      -0.08386653  0.07541176 -0.22825065] \n",
      "\n",
      "best reward is :  [0.62285714 0.58758621 0.56592593 0.54222222 0.53333333]\n",
      "reward is :  [0.06436782 0.17777778 0.088      0.10285714 0.4       ]\n",
      "regrets is :  [0.55848933 0.40980843 0.47792593 0.43936508 0.13333333] \n",
      "\n",
      "best reward is :  [0.56285714 0.51555556 0.50758621 0.49333333 0.43151515]\n",
      "reward is :  [0.06436782 0.01777778 0.248      0.34285714 0.24      ]\n",
      "regrets is :  [0.49848933 0.49777778 0.25958621 0.15047619 0.19151515] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 91us/step - loss: 0.0873 - val_loss: 0.0335\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0278 - val_loss: 0.0289\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0274 - val_loss: 0.0281\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0273 - val_loss: 0.0292\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0275 - val_loss: 0.0289\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0274 - val_loss: 0.0307\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0277 - val_loss: 0.0305\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0278 - val_loss: 0.0290\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0277 - val_loss: 0.0312\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0280 - val_loss: 0.0294\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0279 - val_loss: 0.0316\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0278 - val_loss: 0.0284\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0283 - val_loss: 0.0329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best reward is :  [0.4896     0.48247788 0.41636364 0.30491647 0.26285714]\n",
      "reward is :  [0.41636364 0.4896     0.04645161 0.18535211 0.2376699 ]\n",
      "regrets is :  [ 0.07323636 -0.00712212  0.36991202  0.11956436  0.02518724] \n",
      "\n",
      "best reward is :  [0.6992     0.6516129  0.37818182 0.3576699  0.32247788]\n",
      "reward is :  [0.6992     0.6516129  0.04645161 0.02535211 0.3576699 ]\n",
      "regrets is :  [ 0.          0.          0.33173021  0.33231779 -0.03519203] \n",
      "\n",
      "best reward is :  [0.55297297 0.48247788 0.48142857 0.30491647 0.26285714]\n",
      "reward is :  [0.48142857 0.55297297 0.04645161 0.18535211 0.2376699 ]\n",
      "regrets is :  [ 0.0715444  -0.0704951   0.43497696  0.11956436  0.02518724] \n",
      "\n",
      "best reward is :  [0.62       0.60101695 0.58491647 0.54285714 0.49818182]\n",
      "reward is :  [0.02322581 0.01395349 0.28645161 0.22285714 0.62      ]\n",
      "regrets is :  [ 0.59677419  0.58706346  0.29846485  0.32       -0.12181818] \n",
      "\n",
      "best reward is :  [0.55818182 0.54137741 0.4916129  0.46618182 0.44631579]\n",
      "reward is :  [0.18322581 0.17395349 0.30285714 0.4916129  0.4       ]\n",
      "regrets is :  [ 0.37495601  0.36742392  0.18875576 -0.02543109  0.04631579] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 89us/step - loss: 0.0791 - val_loss: 0.0299\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0277 - val_loss: 0.0285\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0278 - val_loss: 0.0278\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0274 - val_loss: 0.0276\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0274 - val_loss: 0.0273\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0279 - val_loss: 0.0311\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0277 - val_loss: 0.0283\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0285 - val_loss: 0.0307\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0276 - val_loss: 0.0274\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0275 - val_loss: 0.0284\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0279 - val_loss: 0.0296\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0280 - val_loss: 0.0289\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0281 - val_loss: 0.0319\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0278 - val_loss: 0.0277\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0277 - val_loss: 0.0282\n",
      "best reward is :  [0.60285714 0.43284916 0.42363636 0.42       0.39352113]\n",
      "reward is :  [0.38       0.22857143 0.01511811 0.09135952 0.38605505]\n",
      "regrets is :  [0.22285714 0.20427773 0.40851825 0.32864048 0.00746608] \n",
      "\n",
      "best reward is :  [0.65951583 0.55632184 0.53763441 0.51578947 0.50285714]\n",
      "reward is :  [0.40666667 0.06857143 0.01511811 0.09135952 0.51578947]\n",
      "regrets is :  [ 0.25284916  0.48775041  0.5225163   0.42442996 -0.01293233] \n",
      "\n",
      "best reward is :  [0.52465116 0.52       0.51310345 0.49617978 0.37135952]\n",
      "reward is :  [0.07272727 0.14857143 0.19511811 0.37135952 0.07578947]\n",
      "regrets is :  [0.45192389 0.37142857 0.31798534 0.12482026 0.29557004] \n",
      "\n",
      "best reward is :  [0.41710983 0.38857143 0.328      0.32528302 0.32465116]\n",
      "reward is :  [0.23272727 0.38857143 0.25511811 0.41710983 0.07578947]\n",
      "regrets is :  [ 0.18438255  0.          0.07288189 -0.09182681  0.24886169] \n",
      "\n",
      "best reward is :  [0.60285714 0.59284916 0.48965517 0.47096774 0.45578947]\n",
      "reward is :  [0.03348837 0.29272727 0.12857143 0.01511811 0.45578947]\n",
      "regrets is :  [0.56936877 0.30012189 0.36108374 0.45584963 0.        ] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 96us/step - loss: 0.0579 - val_loss: 0.0259\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0267 - val_loss: 0.0265\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0268 - val_loss: 0.0265\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0271 - val_loss: 0.0253\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0271 - val_loss: 0.0262\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0269 - val_loss: 0.0253\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0270 - val_loss: 0.0260\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0273 - val_loss: 0.0260\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0272 - val_loss: 0.0252\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0270 - val_loss: 0.0262\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0275 - val_loss: 0.0255\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0269 - val_loss: 0.0254\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0270 - val_loss: 0.0249\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0271 - val_loss: 0.0259\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0269 - val_loss: 0.0280\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0273 - val_loss: 0.0265\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0272 - val_loss: 0.0251\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0272 - val_loss: 0.0262\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0268 - val_loss: 0.0266\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0268 - val_loss: 0.0275\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0275 - val_loss: 0.0269\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0269 - val_loss: 0.0247\n",
      "Epoch 23/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0269 - val_loss: 0.0264\n",
      "Epoch 24/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0271 - val_loss: 0.0260\n",
      "Epoch 25/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0274 - val_loss: 0.0260\n",
      "Epoch 26/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0269 - val_loss: 0.0273\n",
      "Epoch 27/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0272 - val_loss: 0.0274\n",
      "Epoch 28/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0268 - val_loss: 0.0252\n",
      "Epoch 29/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0271 - val_loss: 0.0257\n",
      "Epoch 30/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0269 - val_loss: 0.0259\n",
      "Epoch 31/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0271 - val_loss: 0.0263\n",
      "Epoch 32/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0268 - val_loss: 0.0258\n",
      "best reward is :  [0.4522686  0.3373913  0.27149425 0.26427586 0.2134748 ]\n",
      "reward is :  [0.17103448 0.03103448 0.10729064 0.27149425 0.4522686 ]\n",
      "regrets is :  [ 0.28123412  0.30635682  0.16420361 -0.00721839 -0.2387938 ] \n",
      "\n",
      "best reward is :  [0.26560194 0.20705882 0.19103448 0.1773913  0.1062069 ]\n",
      "reward is :  [0.01103448 0.19103448 0.04729064 0.05149425 0.26560194]\n",
      "regrets is :  [ 0.25456745  0.01602434  0.14374384  0.12589705 -0.15939504] \n",
      "\n",
      "best reward is :  [0.42629885 0.3373913  0.26427586 0.2134748  0.21320197]\n",
      "reward is :  [0.17103448 0.03310345 0.04729064 0.21149425 0.42629885]\n",
      "regrets is :  [ 0.25526437  0.30428786  0.21698522  0.00198055 -0.21309688] \n",
      "\n",
      "best reward is :  [0.26953347 0.20705882 0.19310345 0.1862069  0.1773913 ]\n",
      "reward is :  [0.01241379 0.19310345 0.04729064 0.05149425 0.26953347]\n",
      "regrets is :  [ 0.25711968  0.01395538  0.14581281  0.13471264 -0.09214216] \n",
      "\n",
      "best reward is :  [0.2782266  0.20705882 0.2062069  0.19310345 0.1773913 ]\n",
      "reward is :  [0.01241379 0.19310345 0.2782266  0.04729064 0.17149425]\n",
      "regrets is :  [ 0.26581281  0.01395538 -0.0720197   0.14581281  0.00589705] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 83us/step - loss: 0.1201 - val_loss: 0.0414\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0292 - val_loss: 0.0303\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0269 - val_loss: 0.0296\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0271 - val_loss: 0.0286\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0270 - val_loss: 0.0298\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0273 - val_loss: 0.0289\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0276 - val_loss: 0.0297\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0274 - val_loss: 0.0302\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0278 - val_loss: 0.0295\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0272 - val_loss: 0.0309\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0271 - val_loss: 0.0293\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0271 - val_loss: 0.0291\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0275 - val_loss: 0.0290\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0275 - val_loss: 0.0294\n",
      "best reward is :  [0.46506329 0.40878049 0.40262295 0.34875576 0.26867925]\n",
      "reward is :  [0.46506329 0.40262295 0.34875576 0.01714286 0.03764706]\n",
      "regrets is :  [0.         0.00615754 0.05386719 0.3316129  0.23103219] \n",
      "\n",
      "best reward is :  [0.47544715 0.36806452 0.28867925 0.28105263 0.28      ]\n",
      "reward is :  [0.04881356 0.28105263 0.36806452 0.01714286 0.03764706]\n",
      "regrets is :  [ 0.4266336   0.08701188 -0.07938527  0.26390977  0.24235294] \n",
      "\n",
      "best reward is :  [0.61534591 0.46878049 0.44       0.32864865 0.32706897]\n",
      "reward is :  [0.28105263 0.24806452 0.04881356 0.01714286 0.19764706]\n",
      "regrets is :  [0.33429328 0.22071597 0.39118644 0.31150579 0.12942191] \n",
      "\n",
      "best reward is :  [0.44105263 0.41081081 0.28867925 0.22705882 0.20881356]\n",
      "reward is :  [0.44105263 0.41081081 0.20881356 0.17714286 0.03764706]\n",
      "regrets is :  [0.         0.         0.07986569 0.04991597 0.1711665 ] \n",
      "\n",
      "best reward is :  [0.64864865 0.55813953 0.52881356 0.51935484 0.49395349]\n",
      "reward is :  [0.05221757 0.09333333 0.52881356 0.33714286 0.31764706]\n",
      "regrets is :  [0.59643108 0.4648062  0.         0.18221198 0.17630643] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 79us/step - loss: 0.0742 - val_loss: 0.0287\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0277 - val_loss: 0.0275\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0286 - val_loss: 0.0293\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0282 - val_loss: 0.0287\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0278 - val_loss: 0.0268\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0281 - val_loss: 0.0278\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0280 - val_loss: 0.0281\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0279 - val_loss: 0.0286\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0284 - val_loss: 0.0292\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0280 - val_loss: 0.0269\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0291 - val_loss: 0.0290\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0285 - val_loss: 0.0264\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0278 - val_loss: 0.0301\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0285 - val_loss: 0.0274\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0283 - val_loss: 0.0267\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0282 - val_loss: 0.0278\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0288 - val_loss: 0.0271\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0279 - val_loss: 0.0297\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 50us/step - loss: 0.0279 - val_loss: 0.0274\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0282 - val_loss: 0.0285\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0289 - val_loss: 0.0278\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0278 - val_loss: 0.0289\n",
      "best reward is :  [0.55808358 0.44653659 0.40761905 0.404      0.40213333]\n",
      "reward is :  [0.1792     0.09268966 0.55808358 0.39217391 0.404     ]\n",
      "regrets is :  [ 0.37888358  0.35384693 -0.15046454  0.01182609 -0.00186667] \n",
      "\n",
      "best reward is :  [0.43323077 0.42653659 0.4192     0.38912    0.38101695]\n",
      "reward is :  [0.4192     0.25268966 0.43323077 0.38101695 0.38912   ]\n",
      "regrets is :  [ 0.01403077  0.17384693 -0.01403077  0.00810305 -0.00810305] \n",
      "\n",
      "best reward is :  [0.55808358 0.46912    0.46101695 0.44653659 0.40761905]\n",
      "reward is :  [0.1792     0.09357983 0.55808358 0.46101695 0.46912   ]\n",
      "regrets is :  [ 0.37888358  0.37554017 -0.09706663 -0.01448036 -0.06150095] \n",
      "\n",
      "best reward is :  [0.4825128  0.41840203 0.34101695 0.26653659 0.26086957]\n",
      "reward is :  [0.26086957 0.25357983 0.4825128  0.34101695 0.41840203]\n",
      "regrets is :  [ 0.22164324  0.1648222  -0.14149585 -0.07448036 -0.15753247] \n",
      "\n",
      "best reward is :  [0.51428571 0.5088     0.41578667 0.40768362 0.37323077]\n",
      "reward is :  [0.18086957 0.25442623 0.37323077 0.40768362 0.41578667]\n",
      "regrets is :  [ 0.33341615  0.25437377  0.0425559   0.         -0.0425559 ] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 87us/step - loss: 0.0468 - val_loss: 0.0269\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0277 - val_loss: 0.0261\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0280 - val_loss: 0.0262\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0280 - val_loss: 0.0264\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 51us/step - loss: 0.0284 - val_loss: 0.0252\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0278 - val_loss: 0.0258\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0287 - val_loss: 0.0267\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0280 - val_loss: 0.0254\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0281 - val_loss: 0.0281\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0281 - val_loss: 0.0258\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0277 - val_loss: 0.0259\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0280 - val_loss: 0.0252\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0280 - val_loss: 0.0252\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.0277 - val_loss: 0.0259\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0279 - val_loss: 0.0265\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0284 - val_loss: 0.0278\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 54us/step - loss: 0.0282 - val_loss: 0.0272\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0277 - val_loss: 0.0257\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0279 - val_loss: 0.0255\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0279 - val_loss: 0.0319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0279 - val_loss: 0.0264\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0286 - val_loss: 0.0267\n",
      "Epoch 23/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0291 - val_loss: 0.0256\n",
      "best reward is :  [0.70285714 0.48666667 0.48       0.4247619  0.38358974]\n",
      "reward is :  [0.24666667 0.38358974 0.35027027 0.4247619  0.10039216]\n",
      "regrets is :  [0.45619048 0.10307692 0.12972973 0.         0.28319759] \n",
      "\n",
      "best reward is :  [0.5636036  0.41758865 0.36727273 0.32671329 0.32      ]\n",
      "reward is :  [0.00666667 0.17025641 0.5636036  0.09142857 0.23372549]\n",
      "regrets is :  [ 0.55693694  0.24733224 -0.19633088  0.23528472  0.08627451] \n",
      "\n",
      "best reward is :  [0.66666667 0.56952381 0.56695652 0.56410256 0.53037037]\n",
      "reward is :  [0.32666667 0.19025641 0.19027027 0.27142857 0.10039216]\n",
      "regrets is :  [0.34       0.3792674  0.37668625 0.29267399 0.42997821] \n",
      "\n",
      "best reward is :  [0.51692308 0.40410256 0.40285714 0.4        0.39142857]\n",
      "reward is :  [0.32969697 0.51692308 0.35027027 0.39142857 0.10039216]\n",
      "regrets is :  [ 0.18722611 -0.11282051  0.05258687  0.00857143  0.29103641] \n",
      "\n",
      "best reward is :  [0.5374359  0.53333333 0.49777778 0.43619048 0.38358974]\n",
      "reward is :  [0.25142857 0.38358974 0.35027027 0.17142857 0.10039216]\n",
      "regrets is :  [0.28600733 0.14974359 0.14750751 0.2647619  0.28319759] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 92us/step - loss: 0.0925 - val_loss: 0.0371\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0286 - val_loss: 0.0273\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0272 - val_loss: 0.0276\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0270 - val_loss: 0.0292\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0278 - val_loss: 0.0285\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0285 - val_loss: 0.0282\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0274 - val_loss: 0.0273\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0276 - val_loss: 0.0288\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0273 - val_loss: 0.0288\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0270 - val_loss: 0.0268\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0274 - val_loss: 0.0290\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0279 - val_loss: 0.0278\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0272 - val_loss: 0.0267\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0272 - val_loss: 0.0280\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0277 - val_loss: 0.0275\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0282 - val_loss: 0.0301\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 50us/step - loss: 0.0272 - val_loss: 0.0287\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0278 - val_loss: 0.0287\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0272 - val_loss: 0.0267\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 50us/step - loss: 0.0273 - val_loss: 0.0267\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0272 - val_loss: 0.0265\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0277 - val_loss: 0.0274\n",
      "Epoch 23/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0271 - val_loss: 0.0274\n",
      "Epoch 24/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0278 - val_loss: 0.0279\n",
      "Epoch 25/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0273 - val_loss: 0.0269\n",
      "Epoch 26/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0274 - val_loss: 0.0283\n",
      "Epoch 27/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0273 - val_loss: 0.0271\n",
      "Epoch 28/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0277 - val_loss: 0.0268\n",
      "Epoch 29/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0274 - val_loss: 0.0272\n",
      "Epoch 30/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0274 - val_loss: 0.0309\n",
      "Epoch 31/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0274 - val_loss: 0.0265\n",
      "Epoch 32/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0276 - val_loss: 0.0271\n",
      "Epoch 33/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0275 - val_loss: 0.0278\n",
      "Epoch 34/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0275 - val_loss: 0.0276\n",
      "Epoch 35/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0270 - val_loss: 0.0277\n",
      "Epoch 36/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0274 - val_loss: 0.0274\n",
      "Epoch 37/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0276 - val_loss: 0.0277\n",
      "Epoch 38/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0274 - val_loss: 0.0263\n",
      "Epoch 39/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0272 - val_loss: 0.0268\n",
      "Epoch 40/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0272 - val_loss: 0.0278\n",
      "Epoch 41/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0271 - val_loss: 0.0277\n",
      "Epoch 42/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0271 - val_loss: 0.0278\n",
      "Epoch 43/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0279 - val_loss: 0.0286\n",
      "Epoch 44/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0272 - val_loss: 0.0281\n",
      "Epoch 45/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0269 - val_loss: 0.0261\n",
      "Epoch 46/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0273 - val_loss: 0.0280\n",
      "Epoch 47/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0276 - val_loss: 0.0273\n",
      "Epoch 48/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0271 - val_loss: 0.0271\n",
      "Epoch 49/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0272 - val_loss: 0.0263\n",
      "Epoch 50/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0274 - val_loss: 0.0274\n",
      "Epoch 51/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0270 - val_loss: 0.0276\n",
      "Epoch 52/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0271 - val_loss: 0.0262\n",
      "Epoch 53/100\n",
      "4500/4500 [==============================] - 0s 51us/step - loss: 0.0271 - val_loss: 0.0270\n",
      "Epoch 54/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0271 - val_loss: 0.0284\n",
      "Epoch 55/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0273 - val_loss: 0.0275\n",
      "best reward is :  [0.67478261 0.6410566  0.61505376 0.54107527 0.5254902 ]\n",
      "reward is :  [0.12       0.17745455 0.03037975 0.0192     0.25391304]\n",
      "regrets is :  [0.55478261 0.46360206 0.58467402 0.52187527 0.27157715] \n",
      "\n",
      "best reward is :  [0.41904762 0.3610566  0.35731544 0.33745455 0.33333333]\n",
      "reward is :  [0.33333333 0.33745455 0.24371308 0.0992     0.17391304]\n",
      "regrets is :  [0.08571429 0.02360206 0.11360236 0.23825455 0.15942029] \n",
      "\n",
      "best reward is :  [0.62666667 0.25745455 0.22571429 0.21047619 0.21037975]\n",
      "reward is :  [0.62666667 0.25745455 0.21037975 0.1992     0.17391304]\n",
      "regrets is :  [0.         0.         0.01533454 0.01127619 0.0364667 ] \n",
      "\n",
      "best reward is :  [0.52057971 0.41521127 0.3610566  0.30093458 0.29975309]\n",
      "reward is :  [0.28       0.02285714 0.03310345 0.0192     0.52057971]\n",
      "regrets is :  [ 0.24057971  0.39235412  0.32795316  0.28173458 -0.22082662] \n",
      "\n",
      "best reward is :  [0.41904762 0.3610566  0.35731544 0.34285714 0.33333333]\n",
      "reward is :  [0.33333333 0.34285714 0.24643678 0.0992     0.17391304]\n",
      "regrets is :  [0.08571429 0.01819946 0.11087865 0.24365714 0.15942029] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 107us/step - loss: 0.0624 - val_loss: 0.0318\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0272 - val_loss: 0.0301\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 19us/step - loss: 0.0264 - val_loss: 0.0321\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 17us/step - loss: 0.0265 - val_loss: 0.0281\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0268 - val_loss: 0.0289\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0264 - val_loss: 0.0298\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0269 - val_loss: 0.0303\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0271 - val_loss: 0.0302\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0268 - val_loss: 0.0300\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0275 - val_loss: 0.0302\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0274 - val_loss: 0.0312\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0267 - val_loss: 0.0280\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0267 - val_loss: 0.0303\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0267 - val_loss: 0.0288\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0272 - val_loss: 0.0295\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0267 - val_loss: 0.0281\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0269 - val_loss: 0.0292\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0267 - val_loss: 0.0287\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 70us/step - loss: 0.0271 - val_loss: 0.0311\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0268 - val_loss: 0.0303\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0268 - val_loss: 0.0279\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0269 - val_loss: 0.0278\n",
      "Epoch 23/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0272 - val_loss: 0.0293\n",
      "Epoch 24/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0265 - val_loss: 0.0297\n",
      "Epoch 25/100\n",
      "4500/4500 [==============================] - 0s 68us/step - loss: 0.0268 - val_loss: 0.0294\n",
      "Epoch 26/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0267 - val_loss: 0.0310\n",
      "Epoch 27/100\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0266 - val_loss: 0.0282\n",
      "Epoch 28/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0267 - val_loss: 0.0283\n",
      "Epoch 29/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0264 - val_loss: 0.0298\n",
      "Epoch 30/100\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.0265 - val_loss: 0.0291\n",
      "Epoch 31/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0266 - val_loss: 0.0294\n",
      "Epoch 32/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0268 - val_loss: 0.0282\n",
      "best reward is :  [0.45245421 0.40515654 0.38280702 0.38023981 0.35994065]\n",
      "reward is :  [0.28495677 0.22861538 0.16806723 0.15191011 0.17116279]\n",
      "regrets is :  [0.16749744 0.17654115 0.21473979 0.2283297  0.18877786] \n",
      "\n",
      "best reward is :  [0.45180745 0.40503976 0.38262366 0.38019048 0.35953488]\n",
      "reward is :  [0.28413013 0.28861538 0.16793388 0.15146402 0.17103448]\n",
      "regrets is :  [0.16767732 0.11642437 0.21468977 0.22872646 0.1885004 ] \n",
      "\n",
      "best reward is :  [0.46892308 0.38126722 0.29942909 0.29180745 0.29103448]\n",
      "reward is :  [0.20413013 0.18861538 0.29103448 0.23146402 0.17103448]\n",
      "regrets is :  [0.26479295 0.19265183 0.0083946  0.06034343 0.12      ] \n",
      "\n",
      "best reward is :  [0.48793388 0.45103448 0.44225641 0.44152025 0.42159359]\n",
      "reward is :  [0.04926316 0.12861538 0.18551724 0.45103448 0.07146402]\n",
      "regrets is :  [ 0.43867073  0.3224191   0.25673917 -0.00951423  0.35012957] \n",
      "\n",
      "best reward is :  [0.55953488 0.51847411 0.5133758  0.47170642 0.45655172]\n",
      "reward is :  [0.28926316 0.28861538 0.00551724 0.17103448 0.35146402]\n",
      "regrets is :  [0.27027173 0.22985873 0.50785855 0.30067194 0.1050877 ] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 98us/step - loss: 0.1453 - val_loss: 0.0412\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0319 - val_loss: 0.0248\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0276 - val_loss: 0.0260\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0273 - val_loss: 0.0253\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0277 - val_loss: 0.0242\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0276 - val_loss: 0.0249\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0274 - val_loss: 0.0246\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0274 - val_loss: 0.0246\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0276 - val_loss: 0.0244\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0280 - val_loss: 0.0248\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0277 - val_loss: 0.0247\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0275 - val_loss: 0.0253\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0280 - val_loss: 0.0247\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0281 - val_loss: 0.0266\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0279 - val_loss: 0.0250\n",
      "best reward is :  [0.42980069 0.41016198 0.33336343 0.28330827 0.26896664]\n",
      "reward is :  [0.06991597 0.42980069 0.016      0.03120743 0.28330827]\n",
      "regrets is :  [ 0.35988472 -0.01963871  0.31736343  0.25210084 -0.01434163] \n",
      "\n",
      "best reward is :  [0.54991597 0.416      0.3537931  0.35336343 0.34976744]\n",
      "reward is :  [0.54991597 0.416      0.31120743 0.04330827 0.2583908 ]\n",
      "regrets is :  [0.         0.         0.04258567 0.31005516 0.09137664] \n",
      "\n",
      "best reward is :  [0.32979151 0.31336343 0.2883208  0.26709133 0.22976744]\n",
      "reward is :  [0.32979151 0.2883208  0.07120743 0.18330827 0.12505747]\n",
      "regrets is :  [0.         0.02504263 0.21711337 0.08378306 0.10470997] \n",
      "\n",
      "best reward is :  [0.4166416  0.41016198 0.33336343 0.26896664 0.26368   ]\n",
      "reward is :  [0.02630137 0.03120743 0.4166416  0.18543046 0.1783908 ]\n",
      "regrets is :  [ 0.39034023  0.37895455 -0.08327817  0.08353618  0.0852892 ] \n",
      "\n",
      "best reward is :  [0.39157895 0.36749117 0.35636364 0.33142857 0.26817447]\n",
      "reward is :  [0.39157895 0.02594595 0.         0.03092025 0.36749117]\n",
      "regrets is :  [ 0.          0.34154522  0.35636364  0.30050833 -0.09931669] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 87us/step - loss: 0.0968 - val_loss: 0.0398\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0256 - val_loss: 0.0356\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0258 - val_loss: 0.0383\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0254 - val_loss: 0.0372\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0256 - val_loss: 0.0361\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0254 - val_loss: 0.0390\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0257 - val_loss: 0.0363\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0255 - val_loss: 0.0379\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0257 - val_loss: 0.0394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0257 - val_loss: 0.0367\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0259 - val_loss: 0.0418\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0261 - val_loss: 0.0372\n",
      "best reward is :  [0.24       0.21662198 0.20481928 0.19272727 0.12816327]\n",
      "reward is :  [0.07058824 0.21662198 0.01714286 0.01613445 0.04280255]\n",
      "regrets is :  [0.16941176 0.         0.18767642 0.17659282 0.08536072] \n",
      "\n",
      "best reward is :  [0.24       0.23058824 0.22816327 0.20481928 0.17714286]\n",
      "reward is :  [0.23058824 0.05662198 0.17714286 0.17613445 0.04280255]\n",
      "regrets is :  [0.00941176 0.17396625 0.05102041 0.02868482 0.13434031] \n",
      "\n",
      "best reward is :  [0.72       0.60857143 0.57564356 0.55227799 0.54872727]\n",
      "reward is :  [0.45058824 0.29662198 0.39714286 0.17613445 0.48280255]\n",
      "regrets is :  [0.26941176 0.31194944 0.17850071 0.37614354 0.06592472] \n",
      "\n",
      "best reward is :  [0.4        0.36481928 0.35482993 0.27764706 0.25564356]\n",
      "reward is :  [0.07058824 0.05662198 0.01714286 0.01613445 0.20280255]\n",
      "regrets is :  [0.32941176 0.30819729 0.33768707 0.26151261 0.05284102] \n",
      "\n",
      "best reward is :  [0.72       0.60857143 0.57564356 0.55227799 0.54872727]\n",
      "reward is :  [0.45058824 0.29662198 0.39714286 0.1827668  0.48280255]\n",
      "regrets is :  [0.26941176 0.31194944 0.17850071 0.36951119 0.06592472] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 83us/step - loss: 0.0326 - val_loss: 0.0251\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0251 - val_loss: 0.0256\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0264 - val_loss: 0.0242\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0252 - val_loss: 0.0245\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0251 - val_loss: 0.0241\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0253 - val_loss: 0.0248\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0253 - val_loss: 0.0234\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0253 - val_loss: 0.0248\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0260 - val_loss: 0.0252\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0251 - val_loss: 0.0243\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0251 - val_loss: 0.0243\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0252 - val_loss: 0.0280\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0252 - val_loss: 0.0291\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0255 - val_loss: 0.0244\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0261 - val_loss: 0.0240\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 52us/step - loss: 0.0253 - val_loss: 0.0243\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0255 - val_loss: 0.0259\n",
      "best reward is :  [0.4        0.33905097 0.24121475 0.21096774 0.18865672]\n",
      "reward is :  [0.33905097 0.10537445 0.21096774 0.02537445 0.01594684]\n",
      "regrets is :  [0.06094903 0.23367652 0.03024701 0.18559329 0.17270987] \n",
      "\n",
      "best reward is :  [0.47096774 0.328      0.30537445 0.24470588 0.24      ]\n",
      "reward is :  [0.30537445 0.47096774 0.18021053 0.02537445 0.17594684]\n",
      "regrets is :  [ 0.16559329 -0.14296774  0.12516392  0.21933143  0.06405316] \n",
      "\n",
      "best reward is :  [0.4        0.26264151 0.24121475 0.21096774 0.18865672]\n",
      "reward is :  [0.26264151 0.21096774 0.02837438 0.02537445 0.01594684]\n",
      "regrets is :  [0.13735849 0.05167377 0.21284037 0.18559329 0.17270987] \n",
      "\n",
      "best reward is :  [0.51254962 0.488      0.46837438 0.44341709 0.43096774]\n",
      "reward is :  [0.19096774 0.02264151 0.46837438 0.20537445 0.35594684]\n",
      "regrets is :  [0.32158188 0.46535849 0.         0.23804264 0.0750209 ] \n",
      "\n",
      "best reward is :  [0.47096774 0.328      0.24470588 0.24450262 0.24      ]\n",
      "reward is :  [0.24450262 0.47096774 0.20264151 0.19555556 0.17594684]\n",
      "regrets is :  [ 0.22646512 -0.14296774  0.04206437  0.04894706  0.06405316] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 107us/step - loss: 0.0744 - val_loss: 0.0268\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0272 - val_loss: 0.0260\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0271 - val_loss: 0.0255\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0271 - val_loss: 0.0265\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0275 - val_loss: 0.0242\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0275 - val_loss: 0.0259\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0276 - val_loss: 0.0266\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0274 - val_loss: 0.0265\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0272 - val_loss: 0.0280\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0279 - val_loss: 0.0255\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0277 - val_loss: 0.0264\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0280 - val_loss: 0.0277\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0276 - val_loss: 0.0259\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0284 - val_loss: 0.0285\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0276 - val_loss: 0.0259\n",
      "best reward is :  [0.68883721 0.6        0.55336245 0.5525     0.54      ]\n",
      "reward is :  [0.0116129  0.24917073 0.268      0.4172093  0.20634483]\n",
      "regrets is :  [0.67722431 0.35082927 0.28536245 0.1352907  0.33365517] \n",
      "\n",
      "best reward is :  [0.528      0.4        0.3516129  0.235      0.20285714]\n",
      "reward is :  [0.3516129  0.16917073 0.528      0.108      0.04634483]\n",
      "regrets is :  [ 0.1763871   0.23082927 -0.1763871   0.127       0.15651232] \n",
      "\n",
      "best reward is :  [0.63336245 0.62883721 0.58746269 0.56       0.54      ]\n",
      "reward is :  [0.0116129  0.02133333 0.29917073 0.348      0.28634483]\n",
      "regrets is :  [0.62174954 0.60750388 0.28829195 0.212      0.25365517] \n",
      "\n",
      "best reward is :  [0.58746269 0.58666667 0.58307483 0.55301149 0.52285714]\n",
      "reward is :  [0.0116129  0.02133333 0.1558374  0.448      0.55301149]\n",
      "regrets is :  [ 0.57584978  0.56533333  0.42723743  0.10501149 -0.03015435] \n",
      "\n",
      "best reward is :  [0.74666667 0.58166667 0.53238095 0.52       0.50666667]\n",
      "reward is :  [0.1716129  0.18133333 0.08917073 0.188      0.22634483]\n",
      "regrets is :  [0.57505376 0.40033333 0.44321022 0.332      0.28032184] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 84us/step - loss: 0.0921 - val_loss: 0.0362\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0253 - val_loss: 0.0269\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0232 - val_loss: 0.0288\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0238 - val_loss: 0.0259\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0236 - val_loss: 0.0266\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0235 - val_loss: 0.0263\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0240 - val_loss: 0.0284\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0236 - val_loss: 0.0280\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0238 - val_loss: 0.0275\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0236 - val_loss: 0.0284\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0237 - val_loss: 0.0271\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0237 - val_loss: 0.0279\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0245 - val_loss: 0.0269\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0241 - val_loss: 0.0279\n",
      "best reward is :  [0.54652921 0.43035413 0.40091954 0.34       0.34      ]\n",
      "reward is :  [0.05005587 0.05174129 0.16470588 0.43035413 0.12121212]\n",
      "regrets is :  [ 0.49647334  0.37861284  0.23621366 -0.09035413  0.21878788] \n",
      "\n",
      "best reward is :  [0.54652921 0.40091954 0.34       0.34       0.26262626]\n",
      "reward is :  [0.05005587 0.03130435 0.05174129 0.16470588 0.12121212]\n",
      "regrets is :  [0.49647334 0.36961519 0.28825871 0.17529412 0.14141414] \n",
      "\n",
      "best reward is :  [0.37005587 0.29333333 0.29174129 0.29090909 0.27130435]\n",
      "reward is :  [0.37005587 0.27130435 0.29174129 0.16676056 0.04121212]\n",
      "regrets is :  [0.         0.02202899 0.         0.12414853 0.23009223] \n",
      "\n",
      "best reward is :  [0.51986254 0.45230769 0.44585366 0.44       0.42644295]\n",
      "reward is :  [0.21127469 0.19130435 0.21508828 0.00676056 0.38121212]\n",
      "regrets is :  [0.30858786 0.26100334 0.23076538 0.43323944 0.04523083] \n",
      "\n",
      "best reward is :  [0.51130435 0.33508828 0.29333333 0.29127469 0.29090909]\n",
      "reward is :  [0.29127469 0.51130435 0.33508828 0.18676056 0.04121212]\n",
      "regrets is :  [ 0.22002966 -0.17621607 -0.04175495  0.10451412  0.24969697] \n",
      "\n",
      "End of the simulations, time elapsed: 174.058 seconds.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "layers = [64]\n",
    "regret, regrets, _, _ = run_several_experiments_hist_DL(layers, evolutive_env = True, nb_exp = 20, nb_steps_history=1000)\n",
    "plot_regret(regret, regrets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation 0 started, time elapsed: 0.000 seconds.\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 99us/step - loss: 0.0598 - val_loss: 0.0253\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0275 - val_loss: 0.0286\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0274 - val_loss: 0.0309\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0273 - val_loss: 0.0257\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0273 - val_loss: 0.0263\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0279 - val_loss: 0.0325\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0274 - val_loss: 0.0258\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0275 - val_loss: 0.0261\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0270 - val_loss: 0.0270\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0273 - val_loss: 0.0302\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0275 - val_loss: 0.0245\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0273 - val_loss: 0.0256\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0276 - val_loss: 0.0278\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0276 - val_loss: 0.0253\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0274 - val_loss: 0.0247\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0276 - val_loss: 0.0289\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0278 - val_loss: 0.0271\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0274 - val_loss: 0.0265\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0272 - val_loss: 0.0260\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0276 - val_loss: 0.0259\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0272 - val_loss: 0.0266\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 40us/step - loss: 0.0269 - val_loss: 0.0294\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 41us/step - loss: 0.0276 - val_loss: 0.0251\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 43us/step - loss: 0.0275 - val_loss: 0.0297\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 43us/step - loss: 0.0270 - val_loss: 0.0287\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 43us/step - loss: 0.0271 - val_loss: 0.0263\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.0278 - val_loss: 0.0246\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.0280 - val_loss: 0.0222\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 37us/step - loss: 0.0272 - val_loss: 0.0228\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 42us/step - loss: 0.0276 - val_loss: 0.0236\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 46us/step - loss: 0.0277 - val_loss: 0.0216\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 35us/step - loss: 0.0270 - val_loss: 0.0296\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 39us/step - loss: 0.0271 - val_loss: 0.0294\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 42us/step - loss: 0.0269 - val_loss: 0.0256\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 46us/step - loss: 0.0266 - val_loss: 0.0298\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 34us/step - loss: 0.0269 - val_loss: 0.0272\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 33us/step - loss: 0.0266 - val_loss: 0.0324\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 46us/step - loss: 0.0267 - val_loss: 0.0316\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 36us/step - loss: 0.0266 - val_loss: 0.0339\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 28us/step - loss: 0.0269 - val_loss: 0.0315\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 27us/step - loss: 0.0269 - val_loss: 0.0323\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.0272 - val_loss: 0.0278\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 44us/step - loss: 0.0271 - val_loss: 0.0273\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.0275 - val_loss: 0.0286\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.0268 - val_loss: 0.0271\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.0271 - val_loss: 0.0261\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 36us/step - loss: 0.0269 - val_loss: 0.0247\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 26us/step - loss: 0.0269 - val_loss: 0.0259\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 35us/step - loss: 0.0268 - val_loss: 0.0254\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 45us/step - loss: 0.0268 - val_loss: 0.0321\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 43us/step - loss: 0.0271 - val_loss: 0.0302\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 38us/step - loss: 0.0270 - val_loss: 0.0255\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 49us/step - loss: 0.0270 - val_loss: 0.0282\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 45us/step - loss: 0.0271 - val_loss: 0.0263\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 41us/step - loss: 0.0271 - val_loss: 0.0237\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 40us/step - loss: 0.0275 - val_loss: 0.0287\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 32us/step - loss: 0.0267 - val_loss: 0.0250\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 39us/step - loss: 0.0269 - val_loss: 0.0264\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 39us/step - loss: 0.0270 - val_loss: 0.0259\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 45us/step - loss: 0.0268 - val_loss: 0.0272\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 34us/step - loss: 0.0268 - val_loss: 0.0248\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 34us/step - loss: 0.0267 - val_loss: 0.0268\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 37us/step - loss: 0.0268 - val_loss: 0.0271\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 37us/step - loss: 0.0268 - val_loss: 0.0275\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 42us/step - loss: 0.0267 - val_loss: 0.0268\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 43us/step - loss: 0.0264 - val_loss: 0.0272\n",
      "best reward is :  [0.29586777 0.24       0.20760331 0.18630137 0.17991701]\n",
      "reward is :  [0.02603978 0.29586777 0.02257053 0.02418136 0.02796117]\n",
      "regrets is :  [ 0.26982799 -0.05586777  0.18503277  0.16212001  0.15195585] \n",
      "\n",
      "best reward is :  [0.24       0.20760331 0.1914741  0.18630137 0.17991701]\n",
      "reward is :  [0.02603978 0.17586777 0.02257053 0.02418136 0.02796117]\n",
      "regrets is :  [0.21396022 0.03173554 0.16890357 0.16212001 0.15195585] \n",
      "\n",
      "best reward is :  [0.71401813 0.55010526 0.53052632 0.52       0.50944785]\n",
      "reward is :  [0.18603978 0.17586777 0.18257053 0.50418136 0.50944785]\n",
      "regrets is :  [0.52797834 0.37423749 0.34795578 0.01581864 0.        ] \n",
      "\n",
      "best reward is :  [0.2552381  0.20923077 0.20571429 0.18313253 0.17804511]\n",
      "reward is :  [0.08170213 0.02491349 0.2552381  0.02093023 0.02653266]\n",
      "regrets is :  [ 0.17353597  0.18431727 -0.04952381  0.1622023   0.15151245] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 0s 33us/step - loss: 0.0265 - val_loss: 0.0277\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.0267 - val_loss: 0.0280\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.0268 - val_loss: 0.0281\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.0265 - val_loss: 0.0288\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 45us/step - loss: 0.0266 - val_loss: 0.0270\n",
      "best reward is :  [0.69525606 0.59138548 0.5496     0.528      0.48923077]\n",
      "reward is :  [0.40170213 0.18491349 0.1752381  0.18093023 0.59138548]\n",
      "regrets is :  [ 0.29355394  0.40647198  0.3743619   0.34706977 -0.10215471] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 87us/step - loss: 0.0879 - val_loss: 0.0269\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0245 - val_loss: 0.0270\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0245 - val_loss: 0.0307\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0253 - val_loss: 0.0271\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0246 - val_loss: 0.0280\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0251 - val_loss: 0.0298\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0250 - val_loss: 0.0275\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 54us/step - loss: 0.0248 - val_loss: 0.0278\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0248 - val_loss: 0.0308\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0250 - val_loss: 0.0283\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0251 - val_loss: 0.0285\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 34us/step - loss: 0.0255 - val_loss: 0.0276\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 43us/step - loss: 0.0256 - val_loss: 0.0289\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 37us/step - loss: 0.0257 - val_loss: 0.0276\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 44us/step - loss: 0.0254 - val_loss: 0.0308\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 41us/step - loss: 0.0251 - val_loss: 0.0327\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 30us/step - loss: 0.0260 - val_loss: 0.0293\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.0256 - val_loss: 0.0287\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.0254 - val_loss: 0.0273\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.0254 - val_loss: 0.0281\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 42us/step - loss: 0.0259 - val_loss: 0.0299\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 38us/step - loss: 0.0263 - val_loss: 0.0301\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 39us/step - loss: 0.0258 - val_loss: 0.0292\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 43us/step - loss: 0.0266 - val_loss: 0.0354\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 46us/step - loss: 0.0260 - val_loss: 0.0271\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 33us/step - loss: 0.0255 - val_loss: 0.0316\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 32us/step - loss: 0.0261 - val_loss: 0.0273\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 40us/step - loss: 0.0262 - val_loss: 0.0278\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 43us/step - loss: 0.0263 - val_loss: 0.0284\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 41us/step - loss: 0.0264 - val_loss: 0.0277\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 36us/step - loss: 0.0264 - val_loss: 0.0291\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.0264 - val_loss: 0.0312\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 42us/step - loss: 0.0266 - val_loss: 0.0306\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 43us/step - loss: 0.0267 - val_loss: 0.0293\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 43us/step - loss: 0.0266 - val_loss: 0.0298\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0263 - val_loss: 0.0296\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 33us/step - loss: 0.0269 - val_loss: 0.0283\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 42us/step - loss: 0.0274 - val_loss: 0.0332\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 25us/step - loss: 0.0264 - val_loss: 0.0297\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 24us/step - loss: 0.0266 - val_loss: 0.0308\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 35us/step - loss: 0.0267 - val_loss: 0.0293\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 40us/step - loss: 0.0267 - val_loss: 0.0311\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 40us/step - loss: 0.0271 - val_loss: 0.0270\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 42us/step - loss: 0.0265 - val_loss: 0.0305\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 43us/step - loss: 0.0265 - val_loss: 0.0261\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 53us/step - loss: 0.0264 - val_loss: 0.0288\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 35us/step - loss: 0.0268 - val_loss: 0.0252\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 47us/step - loss: 0.0270 - val_loss: 0.0246\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 41us/step - loss: 0.0269 - val_loss: 0.0248\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 27us/step - loss: 0.0267 - val_loss: 0.0254\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 37us/step - loss: 0.0269 - val_loss: 0.0259\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 56us/step - loss: 0.0266 - val_loss: 0.0273\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 46us/step - loss: 0.0266 - val_loss: 0.0268\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 33us/step - loss: 0.0266 - val_loss: 0.0268\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 23us/step - loss: 0.0268 - val_loss: 0.0287\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 29us/step - loss: 0.0265 - val_loss: 0.0267\n",
      "best reward is :  [0.60579057 0.58933333 0.58045876 0.52240437 0.52121212]\n",
      "reward is :  [0.22296651 0.06235052 0.32840336 0.17385827 0.02516854]\n",
      "regrets is :  [0.38282406 0.52698282 0.2520554  0.3485461  0.49604358] \n",
      "\n",
      "best reward is :  [0.572      0.52545994 0.49103797 0.45907285 0.43737705]\n",
      "reward is :  [0.12010936 0.34235052 0.04840336 0.41385827 0.30516854]\n",
      "regrets is :  [0.45189064 0.18310943 0.44263461 0.04521458 0.13220851] \n",
      "\n",
      "best reward is :  [0.48296651 0.38840336 0.35415077 0.32933333 0.31737705]\n",
      "reward is :  [0.48296651 0.0187013  0.22536965 0.38840336 0.02516854]\n",
      "regrets is :  [ 0.          0.36970206  0.12878112 -0.05907003  0.29220851] \n",
      "\n",
      "best reward is :  [0.60579057 0.58933333 0.58045876 0.52240437 0.52121212]\n",
      "reward is :  [0.22420168 0.06536965 0.0187013  0.32942574 0.08516854]\n",
      "regrets is :  [0.38158889 0.52396368 0.56175746 0.19297863 0.43604358] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.0267 - val_loss: 0.0282\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 44us/step - loss: 0.0266 - val_loss: 0.0305\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 30us/step - loss: 0.0266 - val_loss: 0.0291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.0264 - val_loss: 0.0306\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 24us/step - loss: 0.0265 - val_loss: 0.0304\n",
      "best reward is :  [0.5791239  0.51267887 0.496      0.41775493 0.38081744]\n",
      "reward is :  [0.51267887 0.14420168 0.06536965 0.1787013  0.18516854]\n",
      "regrets is :  [0.06644504 0.36847719 0.43063035 0.23905363 0.1956489 ] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 76us/step - loss: 0.0733 - val_loss: 0.0285\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0278 - val_loss: 0.0271\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0273 - val_loss: 0.0257\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0278 - val_loss: 0.0264\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0276 - val_loss: 0.0276\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0282 - val_loss: 0.0266\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.0276 - val_loss: 0.0268\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 51us/step - loss: 0.0279 - val_loss: 0.0264\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 51us/step - loss: 0.0281 - val_loss: 0.0264\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0277 - val_loss: 0.0270\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 54us/step - loss: 0.0277 - val_loss: 0.0268\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0280 - val_loss: 0.0257\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0279 - val_loss: 0.0274\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0282 - val_loss: 0.0277\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 58us/step - loss: 0.0278 - val_loss: 0.0259\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0280 - val_loss: 0.0270\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 50us/step - loss: 0.0284 - val_loss: 0.0267\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0278 - val_loss: 0.0315\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0289 - val_loss: 0.0261\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0279 - val_loss: 0.0261\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0277 - val_loss: 0.0285\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0281 - val_loss: 0.0258\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 34us/step - loss: 0.0274 - val_loss: 0.0284\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 53us/step - loss: 0.0277 - val_loss: 0.0288\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 47us/step - loss: 0.0277 - val_loss: 0.0284\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 55us/step - loss: 0.0276 - val_loss: 0.0284\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 46us/step - loss: 0.0279 - val_loss: 0.0277\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.0278 - val_loss: 0.0295\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 49us/step - loss: 0.0275 - val_loss: 0.0305\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 69us/step - loss: 0.0278 - val_loss: 0.0248\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 51us/step - loss: 0.0282 - val_loss: 0.0281\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 60us/step - loss: 0.0279 - val_loss: 0.0277\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 63us/step - loss: 0.0276 - val_loss: 0.0288\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 84us/step - loss: 0.0278 - val_loss: 0.0271\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 82us/step - loss: 0.0277 - val_loss: 0.0280\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 70us/step - loss: 0.0280 - val_loss: 0.0301\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 30us/step - loss: 0.0277 - val_loss: 0.0249\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 44us/step - loss: 0.0275 - val_loss: 0.0261\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 51us/step - loss: 0.0278 - val_loss: 0.0262\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 33us/step - loss: 0.0274 - val_loss: 0.0259\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 33us/step - loss: 0.0274 - val_loss: 0.0268\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 54us/step - loss: 0.0273 - val_loss: 0.0280\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.0275 - val_loss: 0.0277\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 50us/step - loss: 0.0276 - val_loss: 0.0269\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 49us/step - loss: 0.0272 - val_loss: 0.0262\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 49us/step - loss: 0.0272 - val_loss: 0.0264\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 51us/step - loss: 0.0274 - val_loss: 0.0269\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 54us/step - loss: 0.0273 - val_loss: 0.0298\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 58us/step - loss: 0.0275 - val_loss: 0.0285\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 54us/step - loss: 0.0275 - val_loss: 0.0290\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 45us/step - loss: 0.0274 - val_loss: 0.0281\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 51us/step - loss: 0.0274 - val_loss: 0.0301\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 38us/step - loss: 0.0275 - val_loss: 0.0335\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 49us/step - loss: 0.0276 - val_loss: 0.0356\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 34us/step - loss: 0.0274 - val_loss: 0.0316\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 36us/step - loss: 0.0271 - val_loss: 0.0302\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - ETA: 0s - loss: 0.027 - 0s 54us/step - loss: 0.0274 - val_loss: 0.0325\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 45us/step - loss: 0.0278 - val_loss: 0.0282\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 37us/step - loss: 0.0274 - val_loss: 0.0259\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 46us/step - loss: 0.0274 - val_loss: 0.0278\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 50us/step - loss: 0.0275 - val_loss: 0.0271\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 49us/step - loss: 0.0274 - val_loss: 0.0259\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 46us/step - loss: 0.0275 - val_loss: 0.0267\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 51us/step - loss: 0.0276 - val_loss: 0.0268\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 50us/step - loss: 0.0276 - val_loss: 0.0269\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 48us/step - loss: 0.0273 - val_loss: 0.0271\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 37us/step - loss: 0.0274 - val_loss: 0.0275\n",
      "best reward is :  [0.51752443 0.47549296 0.34765432 0.34618182 0.33118447]\n",
      "reward is :  [0.51752443 0.01704142 0.00914286 0.02618182 0.00914286]\n",
      "regrets is :  [0.         0.45845154 0.33851146 0.32       0.32204161] \n",
      "\n",
      "best reward is :  [0.63053763 0.52501961 0.51416667 0.50666667 0.50666667]\n",
      "reward is :  [0.03752443 0.25704142 0.08914286 0.37284848 0.18914286]\n",
      "regrets is :  [0.5930132  0.26797819 0.42502381 0.13381818 0.31752381] \n",
      "\n",
      "best reward is :  [0.55704142 0.53432099 0.41668287 0.36501961 0.3625    ]\n",
      "reward is :  [0.31752443 0.55704142 0.34914286 0.53432099 0.24914286]\n",
      "regrets is :  [ 0.23951699 -0.02272043  0.06754002 -0.16930138  0.11335714] \n",
      "\n",
      "best reward is :  [0.51927273 0.35961722 0.33881081 0.31549296 0.30765432]\n",
      "reward is :  [0.51927273 0.1825     0.175      0.18887218 0.16914286]\n",
      "regrets is :  [0.         0.17711722 0.16381081 0.12662078 0.13851146] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.0276 - val_loss: 0.0317\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.0274 - val_loss: 0.0294\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.0275 - val_loss: 0.0296\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.0274 - val_loss: 0.0296\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.0272 - val_loss: 0.0301\n",
      "best reward is :  [0.42989619 0.34781857 0.3025     0.29641558 0.295     ]\n",
      "reward is :  [0.29641558 0.27964286 0.21907285 0.42989619 0.295     ]\n",
      "regrets is :  [ 0.13348061  0.06817572  0.08342715 -0.13348061  0.        ] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 75us/step - loss: 0.1283 - val_loss: 0.0302\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0290 - val_loss: 0.0289\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0280 - val_loss: 0.0293\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0282 - val_loss: 0.0278\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0282 - val_loss: 0.0284\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0282 - val_loss: 0.0264\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0286 - val_loss: 0.0271\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0282 - val_loss: 0.0292\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0284 - val_loss: 0.0315\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0282 - val_loss: 0.0313\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0286 - val_loss: 0.0296\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0284 - val_loss: 0.0304\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0286 - val_loss: 0.0276\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0281 - val_loss: 0.0264\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0289 - val_loss: 0.0247\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0288 - val_loss: 0.0302\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0284 - val_loss: 0.0324\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0290 - val_loss: 0.0291\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0285 - val_loss: 0.0280\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0285 - val_loss: 0.0349\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0286 - val_loss: 0.0318\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 54us/step - loss: 0.0289 - val_loss: 0.0259\n",
      "Epoch 23/100\n",
      "4500/4500 [==============================] - 0s 50us/step - loss: 0.0286 - val_loss: 0.0255\n",
      "Epoch 24/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0290 - val_loss: 0.0270\n",
      "Epoch 25/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0289 - val_loss: 0.0295\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 33us/step - loss: 0.0289 - val_loss: 0.0313\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 33us/step - loss: 0.0284 - val_loss: 0.0302\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 33us/step - loss: 0.0283 - val_loss: 0.0315\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 36us/step - loss: 0.0286 - val_loss: 0.0321\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 38us/step - loss: 0.0283 - val_loss: 0.0307\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 30us/step - loss: 0.0295 - val_loss: 0.0301\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.0284 - val_loss: 0.0281\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.0287 - val_loss: 0.0297\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 36us/step - loss: 0.0290 - val_loss: 0.0289\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 42us/step - loss: 0.0288 - val_loss: 0.0328\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 31us/step - loss: 0.0288 - val_loss: 0.0275\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 32us/step - loss: 0.0286 - val_loss: 0.0287\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 40us/step - loss: 0.0286 - val_loss: 0.0286\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 30us/step - loss: 0.0286 - val_loss: 0.0264\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 27us/step - loss: 0.0285 - val_loss: 0.0287\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 21us/step - loss: 0.0284 - val_loss: 0.0285\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 23us/step - loss: 0.0289 - val_loss: 0.0303\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 23us/step - loss: 0.0284 - val_loss: 0.0269\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 23us/step - loss: 0.0288 - val_loss: 0.0297\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 26us/step - loss: 0.0288 - val_loss: 0.0302\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.0289 - val_loss: 0.0296\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.0283 - val_loss: 0.0293\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 44us/step - loss: 0.0284 - val_loss: 0.0306\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.0282 - val_loss: 0.0312\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.0283 - val_loss: 0.0302\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 41us/step - loss: 0.0283 - val_loss: 0.0305\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 40us/step - loss: 0.0286 - val_loss: 0.0296\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 41us/step - loss: 0.0286 - val_loss: 0.0282\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 44us/step - loss: 0.0285 - val_loss: 0.0297\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 41us/step - loss: 0.0283 - val_loss: 0.0315\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 33us/step - loss: 0.0285 - val_loss: 0.0287\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 26us/step - loss: 0.0287 - val_loss: 0.0271\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 25us/step - loss: 0.0284 - val_loss: 0.0323\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 25us/step - loss: 0.0286 - val_loss: 0.0298\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 29us/step - loss: 0.0285 - val_loss: 0.0303\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 32us/step - loss: 0.0283 - val_loss: 0.0301\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 39us/step - loss: 0.0283 - val_loss: 0.0299\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 24us/step - loss: 0.0283 - val_loss: 0.0287\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 26us/step - loss: 0.0285 - val_loss: 0.0304\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 26us/step - loss: 0.0282 - val_loss: 0.0292\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 36us/step - loss: 0.0286 - val_loss: 0.0268\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 38us/step - loss: 0.0288 - val_loss: 0.0275\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8550/8550 [==============================] - 0s 40us/step - loss: 0.0284 - val_loss: 0.0252\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 37us/step - loss: 0.0285 - val_loss: 0.0294\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 40us/step - loss: 0.0287 - val_loss: 0.0239\n",
      "best reward is :  [0.59294118 0.57148211 0.56696629 0.50205689 0.48061069]\n",
      "reward is :  [0.01043478 0.05071038 0.48061069 0.59294118 0.43      ]\n",
      "regrets is :  [ 0.58250639  0.52077173  0.08635561 -0.09088428  0.05061069] \n",
      "\n",
      "best reward is :  [0.65960236 0.46188925 0.42767296 0.41507853 0.40601504]\n",
      "reward is :  [0.17035971 0.05052632 0.26030418 0.39294118 0.21290086]\n",
      "regrets is :  [0.48924265 0.41136294 0.16736877 0.02213736 0.19311418] \n",
      "\n",
      "best reward is :  [0.65940426 0.46172414 0.45294118 0.42733333 0.415     ]\n",
      "reward is :  [0.17028571 0.05034358 0.26       0.45294118 0.21262136]\n",
      "regrets is :  [ 0.48911854  0.41138056  0.19294118 -0.02560784  0.20237864] \n",
      "\n",
      "best reward is :  [0.55294118 0.5088     0.48867824 0.46608696 0.45208054]\n",
      "reward is :  [0.01028571 0.27034358 0.3        0.55294118 0.37262136]\n",
      "regrets is :  [ 0.54265546  0.23845642  0.18867824 -0.08685422  0.07945918] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.0283 - val_loss: 0.0221\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 43us/step - loss: 0.0284 - val_loss: 0.0231\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.0285 - val_loss: 0.0219\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.0283 - val_loss: 0.0224\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.0282 - val_loss: 0.0213\n",
      "best reward is :  [0.59294118 0.575      0.50172414 0.494      0.4937931 ]\n",
      "reward is :  [0.17028571 0.32       0.01339535 0.59294118 0.41557647]\n",
      "regrets is :  [ 0.42265546  0.255       0.48832879 -0.09894118  0.07821663] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 70us/step - loss: 0.1068 - val_loss: 0.0315\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0262 - val_loss: 0.0310\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 19us/step - loss: 0.0260 - val_loss: 0.0300\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0260 - val_loss: 0.0309\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0259 - val_loss: 0.0312\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0259 - val_loss: 0.0306\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 19us/step - loss: 0.0259 - val_loss: 0.0304\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0260 - val_loss: 0.0309\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0258 - val_loss: 0.0300\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0261 - val_loss: 0.0300\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0266 - val_loss: 0.0310\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0263 - val_loss: 0.0321\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0261 - val_loss: 0.0318\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 32us/step - loss: 0.0265 - val_loss: 0.0471\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 36us/step - loss: 0.0269 - val_loss: 0.0352\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 36us/step - loss: 0.0262 - val_loss: 0.0367\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 38us/step - loss: 0.0268 - val_loss: 0.0437\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 30us/step - loss: 0.0265 - val_loss: 0.0358\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 30us/step - loss: 0.0272 - val_loss: 0.0313\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 32us/step - loss: 0.0273 - val_loss: 0.0384\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 25us/step - loss: 0.0273 - val_loss: 0.0396\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 26us/step - loss: 0.0271 - val_loss: 0.0343\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 23us/step - loss: 0.0273 - val_loss: 0.0357\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 34us/step - loss: 0.0284 - val_loss: 0.0252\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 42us/step - loss: 0.0283 - val_loss: 0.0278\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - ETA: 0s - loss: 0.027 - 0s 44us/step - loss: 0.0277 - val_loss: 0.0246\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 41us/step - loss: 0.0277 - val_loss: 0.0255\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 41us/step - loss: 0.0275 - val_loss: 0.0286\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 33us/step - loss: 0.0282 - val_loss: 0.0257\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 33us/step - loss: 0.0283 - val_loss: 0.0265\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 35us/step - loss: 0.0277 - val_loss: 0.0275\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 40us/step - loss: 0.0277 - val_loss: 0.0297\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 40us/step - loss: 0.0279 - val_loss: 0.0238\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.0274 - val_loss: 0.0321\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.0276 - val_loss: 0.0312\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.0274 - val_loss: 0.0332\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.0278 - val_loss: 0.0321\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.0274 - val_loss: 0.0361\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 30us/step - loss: 0.0277 - val_loss: 0.0288\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 36us/step - loss: 0.0279 - val_loss: 0.0291\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 45us/step - loss: 0.0280 - val_loss: 0.0283\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 69us/step - loss: 0.0278 - val_loss: 0.0280\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 25us/step - loss: 0.0275 - val_loss: 0.0278\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 36us/step - loss: 0.0278 - val_loss: 0.0257\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 35us/step - loss: 0.0279 - val_loss: 0.0271\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 39us/step - loss: 0.0278 - val_loss: 0.0253\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 41us/step - loss: 0.0276 - val_loss: 0.0257\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 38us/step - loss: 0.0278 - val_loss: 0.0266\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 35us/step - loss: 0.0281 - val_loss: 0.0284\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 41us/step - loss: 0.0276 - val_loss: 0.0290\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 40us/step - loss: 0.0276 - val_loss: 0.0287\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 38us/step - loss: 0.0276 - val_loss: 0.0265\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 45us/step - loss: 0.0275 - val_loss: 0.0289\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 36us/step - loss: 0.0275 - val_loss: 0.0303\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 36us/step - loss: 0.0274 - val_loss: 0.0296\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8550/8550 [==============================] - 0s 31us/step - loss: 0.0277 - val_loss: 0.0296\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 22us/step - loss: 0.0276 - val_loss: 0.0290\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 21us/step - loss: 0.0275 - val_loss: 0.0296\n",
      "best reward is :  [0.55741935 0.51626734 0.49485714 0.46149254 0.46013986]\n",
      "reward is :  [0.42408602 0.41152    0.55741935 0.35772926 0.22545455]\n",
      "regrets is :  [ 0.13333333  0.10474734 -0.06256221  0.10376328  0.23468531] \n",
      "\n",
      "best reward is :  [0.58293401 0.56152381 0.5281592  0.51818667 0.47829126]\n",
      "reward is :  [0.04963072 0.33766871 0.47829126 0.41870968 0.31030736]\n",
      "regrets is :  [0.53330328 0.2238551  0.04986794 0.09947699 0.1679839 ] \n",
      "\n",
      "best reward is :  [0.47000102 0.43005747 0.39466667 0.37333333 0.30869757]\n",
      "reward is :  [0.39466667 0.0173494  0.22926686 0.0384     0.47000102]\n",
      "regrets is :  [ 0.07533435  0.41270807  0.1653998   0.33493333 -0.16130345] \n",
      "\n",
      "best reward is :  [0.52652874 0.52370809 0.47478261 0.4729771  0.4145746 ]\n",
      "reward is :  [0.33704142 0.0489083  0.27809524 0.23466667 0.22484472]\n",
      "regrets is :  [0.18948732 0.47479979 0.19668737 0.23831043 0.18972988] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 33us/step - loss: 0.0277 - val_loss: 0.0296\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.0276 - val_loss: 0.0304\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.0279 - val_loss: 0.0302\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.0275 - val_loss: 0.0316\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.0277 - val_loss: 0.0320\n",
      "best reward is :  [0.55466667 0.54515837 0.45794393 0.44897196 0.44      ]\n",
      "reward is :  [0.01704142 0.4289083  0.03809524 0.55466667 0.54515837]\n",
      "regrets is :  [ 0.53762525  0.11625007  0.41984869 -0.1056947  -0.10515837] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 74us/step - loss: 0.0902 - val_loss: 0.0314\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0277 - val_loss: 0.0290\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0276 - val_loss: 0.0293\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0271 - val_loss: 0.0282\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0273 - val_loss: 0.0274\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0273 - val_loss: 0.0279\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0283 - val_loss: 0.0292\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0279 - val_loss: 0.0273\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0273 - val_loss: 0.0301\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0275 - val_loss: 0.0287\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0275 - val_loss: 0.0288\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0278 - val_loss: 0.0279\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0271 - val_loss: 0.0292\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0281 - val_loss: 0.0299\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0276 - val_loss: 0.0277\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0276 - val_loss: 0.0277\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0274 - val_loss: 0.0290\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0280 - val_loss: 0.0296\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 40us/step - loss: 0.0275 - val_loss: 0.0290\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 40us/step - loss: 0.0274 - val_loss: 0.0285\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 27us/step - loss: 0.0273 - val_loss: 0.0273\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 26us/step - loss: 0.0282 - val_loss: 0.0283\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 27us/step - loss: 0.0280 - val_loss: 0.0321\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 36us/step - loss: 0.0276 - val_loss: 0.0325\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 36us/step - loss: 0.0281 - val_loss: 0.0334\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.0281 - val_loss: 0.0314\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.0276 - val_loss: 0.0334\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.0276 - val_loss: 0.0324\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 30us/step - loss: 0.0283 - val_loss: 0.0284\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 37us/step - loss: 0.0282 - val_loss: 0.0284\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 40us/step - loss: 0.0281 - val_loss: 0.0279\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 42us/step - loss: 0.0277 - val_loss: 0.0279\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 34us/step - loss: 0.0280 - val_loss: 0.0278\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 29us/step - loss: 0.0283 - val_loss: 0.0312\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 37us/step - loss: 0.0282 - val_loss: 0.0301\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 44us/step - loss: 0.0284 - val_loss: 0.0306\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 38us/step - loss: 0.0282 - val_loss: 0.0296\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 38us/step - loss: 0.0278 - val_loss: 0.0308\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0278 - val_loss: 0.0341\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.0287 - val_loss: 0.0348\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.0280 - val_loss: 0.0332\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 43us/step - loss: 0.0280 - val_loss: 0.0336\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 48us/step - loss: 0.0284 - val_loss: 0.0397\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 33us/step - loss: 0.0286 - val_loss: 0.0284\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 40us/step - loss: 0.0285 - val_loss: 0.0301\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 38us/step - loss: 0.0283 - val_loss: 0.0280\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 26us/step - loss: 0.0285 - val_loss: 0.0287\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 30us/step - loss: 0.0286 - val_loss: 0.0287\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 33us/step - loss: 0.0284 - val_loss: 0.0250\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 39us/step - loss: 0.0284 - val_loss: 0.0257\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 45us/step - loss: 0.0286 - val_loss: 0.0261\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 38us/step - loss: 0.0284 - val_loss: 0.0266\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 39us/step - loss: 0.0286 - val_loss: 0.0251\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 27us/step - loss: 0.0284 - val_loss: 0.0268\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 23us/step - loss: 0.0281 - val_loss: 0.0270\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 25us/step - loss: 0.0284 - val_loss: 0.0263\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8100/8100 [==============================] - 0s 28us/step - loss: 0.0285 - val_loss: 0.0270\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 34us/step - loss: 0.0285 - val_loss: 0.0278\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 32us/step - loss: 0.0282 - val_loss: 0.0281\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 41us/step - loss: 0.0281 - val_loss: 0.0286\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 39us/step - loss: 0.0283 - val_loss: 0.0283\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 42us/step - loss: 0.0280 - val_loss: 0.0285\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 37us/step - loss: 0.0280 - val_loss: 0.0284\n",
      "best reward is :  [0.43672131 0.40958838 0.34619423 0.27351351 0.25586314]\n",
      "reward is :  [0.43672131 0.40958838 0.14292683 0.13884993 0.18085439]\n",
      "regrets is :  [0.         0.         0.2032674  0.13466358 0.07500875] \n",
      "\n",
      "best reward is :  [0.61586314 0.41119482 0.39286089 0.37085464 0.35492228]\n",
      "reward is :  [0.31876923 0.28958838 0.08292683 0.17884993 0.34085439]\n",
      "regrets is :  [0.29709391 0.12160644 0.30993406 0.19200471 0.01406789] \n",
      "\n",
      "best reward is :  [0.57786149 0.54085439 0.53752131 0.52158895 0.51311828]\n",
      "reward is :  [0.20075815 0.29263914 0.18292683 0.17884993 0.54085439]\n",
      "regrets is :  [ 0.37710334  0.24821525  0.35459448  0.34273902 -0.02773611] \n",
      "\n",
      "best reward is :  [0.69322314 0.64920716 0.51865169 0.45884993 0.41351351]\n",
      "reward is :  [0.04075815 0.00292683 0.45884993 0.00961603 0.06295082]\n",
      "regrets is :  [0.65246499 0.64628033 0.05980176 0.4492339  0.35056269] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 32us/step - loss: 0.0281 - val_loss: 0.0274\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.0280 - val_loss: 0.0273\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 34us/step - loss: 0.0280 - val_loss: 0.0283\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.0279 - val_loss: 0.0287\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.0281 - val_loss: 0.0280\n",
      "best reward is :  [0.58018018 0.42493506 0.33322314 0.29037037 0.28920716]\n",
      "reward is :  [0.20075815 0.00961603 0.00292683 0.18098361 0.06295082]\n",
      "regrets is :  [0.37942203 0.41531904 0.33029631 0.10938676 0.22625634] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 83us/step - loss: 0.0662 - val_loss: 0.0291\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0279 - val_loss: 0.0281\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0275 - val_loss: 0.0312\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0279 - val_loss: 0.0282\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0279 - val_loss: 0.0339\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0283 - val_loss: 0.0277\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0277 - val_loss: 0.0279\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0275 - val_loss: 0.0296\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0278 - val_loss: 0.0303\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0282 - val_loss: 0.0285\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0279 - val_loss: 0.0276\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0277 - val_loss: 0.0286\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0289 - val_loss: 0.0279\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0282 - val_loss: 0.0272\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0276 - val_loss: 0.0276\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0280 - val_loss: 0.0280\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0278 - val_loss: 0.0279\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0280 - val_loss: 0.0302\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0280 - val_loss: 0.0308\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0283 - val_loss: 0.0296\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0278 - val_loss: 0.0288\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0282 - val_loss: 0.0269\n",
      "Epoch 23/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0280 - val_loss: 0.0284\n",
      "Epoch 24/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0276 - val_loss: 0.0286\n",
      "Epoch 25/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0281 - val_loss: 0.0275\n",
      "Epoch 26/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0279 - val_loss: 0.0306\n",
      "Epoch 27/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0279 - val_loss: 0.0290\n",
      "Epoch 28/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0276 - val_loss: 0.0269\n",
      "Epoch 29/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0284 - val_loss: 0.0281\n",
      "Epoch 30/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0276 - val_loss: 0.0338\n",
      "Epoch 31/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0281 - val_loss: 0.0299\n",
      "Epoch 32/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0278 - val_loss: 0.0288\n",
      "Epoch 33/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0286 - val_loss: 0.0266\n",
      "Epoch 34/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0282 - val_loss: 0.0277\n",
      "Epoch 35/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0274 - val_loss: 0.0296\n",
      "Epoch 36/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0275 - val_loss: 0.0283\n",
      "Epoch 37/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0279 - val_loss: 0.0291\n",
      "Epoch 38/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0288 - val_loss: 0.0288\n",
      "Epoch 39/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0277 - val_loss: 0.0291\n",
      "Epoch 40/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0276 - val_loss: 0.0280\n",
      "Epoch 41/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0276 - val_loss: 0.0277\n",
      "Epoch 42/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0276 - val_loss: 0.0290\n",
      "Epoch 43/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0279 - val_loss: 0.0276\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 27us/step - loss: 0.0279 - val_loss: 0.0274\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 38us/step - loss: 0.0278 - val_loss: 0.0281\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 40us/step - loss: 0.0279 - val_loss: 0.0264\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 41us/step - loss: 0.0274 - val_loss: 0.0270\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 41us/step - loss: 0.0276 - val_loss: 0.0269\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 29us/step - loss: 0.0276 - val_loss: 0.0281\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 37us/step - loss: 0.0272 - val_loss: 0.0285\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 42us/step - loss: 0.0274 - val_loss: 0.0288\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.0276 - val_loss: 0.0293\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.0273 - val_loss: 0.0294\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5850/5850 [==============================] - 0s 35us/step - loss: 0.0276 - val_loss: 0.0289\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 36us/step - loss: 0.0275 - val_loss: 0.0289\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 36us/step - loss: 0.0278 - val_loss: 0.0281\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 41us/step - loss: 0.0279 - val_loss: 0.0266\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 40us/step - loss: 0.0279 - val_loss: 0.0267\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 32us/step - loss: 0.0276 - val_loss: 0.0271\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 37us/step - loss: 0.0273 - val_loss: 0.0286\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 37us/step - loss: 0.0276 - val_loss: 0.0266\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 38us/step - loss: 0.0275 - val_loss: 0.0266\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 38us/step - loss: 0.0272 - val_loss: 0.0271\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 32us/step - loss: 0.0274 - val_loss: 0.0277\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 22us/step - loss: 0.0273 - val_loss: 0.0282\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 23us/step - loss: 0.0277 - val_loss: 0.0270\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 23us/step - loss: 0.0274 - val_loss: 0.0266\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 23us/step - loss: 0.0274 - val_loss: 0.0269\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 34us/step - loss: 0.0275 - val_loss: 0.0282\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 38us/step - loss: 0.0274 - val_loss: 0.0295\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 38us/step - loss: 0.0274 - val_loss: 0.0275\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 33us/step - loss: 0.0275 - val_loss: 0.0284\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 25us/step - loss: 0.0274 - val_loss: 0.0305\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 30us/step - loss: 0.0274 - val_loss: 0.0280\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 39us/step - loss: 0.0278 - val_loss: 0.0237\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 39us/step - loss: 0.0273 - val_loss: 0.0290\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 40us/step - loss: 0.0276 - val_loss: 0.0240\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 41us/step - loss: 0.0273 - val_loss: 0.0279\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 30us/step - loss: 0.0276 - val_loss: 0.0239\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 34us/step - loss: 0.0275 - val_loss: 0.0260\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 38us/step - loss: 0.0276 - val_loss: 0.0240\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 40us/step - loss: 0.0274 - val_loss: 0.0234\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 30us/step - loss: 0.0278 - val_loss: 0.0228\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 31us/step - loss: 0.0276 - val_loss: 0.0272\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 37us/step - loss: 0.0272 - val_loss: 0.0266\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 42us/step - loss: 0.0271 - val_loss: 0.0257\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 29us/step - loss: 0.0272 - val_loss: 0.0268\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 24us/step - loss: 0.0272 - val_loss: 0.0275\n",
      "best reward is :  [0.53409524 0.46941176 0.37584    0.35259259 0.34708559]\n",
      "reward is :  [0.46941176 0.34708559 0.31450479 0.27974268 0.37584   ]\n",
      "regrets is :  [ 0.06468347  0.12232617  0.06133521  0.07284991 -0.02875441] \n",
      "\n",
      "best reward is :  [0.37584    0.34       0.32941176 0.3003183  0.29610738]\n",
      "reward is :  [0.24       0.32941176 0.22740426 0.19450479 0.37584   ]\n",
      "regrets is :  [ 0.13584     0.01058824  0.10200751  0.10581351 -0.07973262] \n",
      "\n",
      "best reward is :  [0.37584    0.34       0.32941176 0.3003183  0.29610738]\n",
      "reward is :  [0.24       0.32941176 0.2877116  0.19450479 0.37584   ]\n",
      "regrets is :  [ 0.13584     0.01058824  0.04170017  0.10581351 -0.07973262] \n",
      "\n",
      "best reward is :  [0.46800821 0.39636364 0.32895442 0.31252174 0.31010753]\n",
      "reward is :  [0.10666667 0.19897436 0.46800821 0.39636364 0.23584   ]\n",
      "regrets is :  [ 0.36134155  0.19738928 -0.13905379 -0.0838419   0.07426753] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 21us/step - loss: 0.0271 - val_loss: 0.0278\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.0273 - val_loss: 0.0256\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 24us/step - loss: 0.0270 - val_loss: 0.0265\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.0272 - val_loss: 0.0259\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.0269 - val_loss: 0.0269\n",
      "best reward is :  [0.66482759 0.64489796 0.49252174 0.48979592 0.39384615]\n",
      "reward is :  [0.         0.25230769 0.24829465 0.19636364 0.03918367]\n",
      "regrets is :  [0.66482759 0.39259027 0.24422709 0.29343228 0.35466248] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 87us/step - loss: 0.0919 - val_loss: 0.0265\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0261 - val_loss: 0.0258\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0259 - val_loss: 0.0264\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0261 - val_loss: 0.0258\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0262 - val_loss: 0.0265\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0266 - val_loss: 0.0266\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0262 - val_loss: 0.0268\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0264 - val_loss: 0.0289\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.0265 - val_loss: 0.0260\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0264 - val_loss: 0.0268\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0266 - val_loss: 0.0268\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0267 - val_loss: 0.0268\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0266 - val_loss: 0.0268\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0267 - val_loss: 0.0270\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 34us/step - loss: 0.0266 - val_loss: 0.0356\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 41us/step - loss: 0.0270 - val_loss: 0.0339\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 52us/step - loss: 0.0268 - val_loss: 0.0348\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 51us/step - loss: 0.0265 - val_loss: 0.0334\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 43us/step - loss: 0.0268 - val_loss: 0.0366\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 27us/step - loss: 0.0273 - val_loss: 0.0300\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 45us/step - loss: 0.0269 - val_loss: 0.0307\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 33us/step - loss: 0.0273 - val_loss: 0.0295\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 43us/step - loss: 0.0269 - val_loss: 0.0303\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.0271 - val_loss: 0.0291\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5850/5850 [==============================] - 0s 32us/step - loss: 0.0273 - val_loss: 0.0290\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 37us/step - loss: 0.0275 - val_loss: 0.0271\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 36us/step - loss: 0.0273 - val_loss: 0.0267\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 37us/step - loss: 0.0275 - val_loss: 0.0291\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 41us/step - loss: 0.0276 - val_loss: 0.0262\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 34us/step - loss: 0.0279 - val_loss: 0.0249\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 38us/step - loss: 0.0278 - val_loss: 0.0252\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 38us/step - loss: 0.0274 - val_loss: 0.0281\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 37us/step - loss: 0.0276 - val_loss: 0.0242\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 39us/step - loss: 0.0271 - val_loss: 0.0245\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 25us/step - loss: 0.0274 - val_loss: 0.0304\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.0276 - val_loss: 0.0291\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.0272 - val_loss: 0.0328\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.0274 - val_loss: 0.0317\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 42us/step - loss: 0.0270 - val_loss: 0.0340\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 34us/step - loss: 0.0274 - val_loss: 0.0333\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 37us/step - loss: 0.0274 - val_loss: 0.0318\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 42us/step - loss: 0.0281 - val_loss: 0.0310\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 43us/step - loss: 0.0275 - val_loss: 0.0305\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 42us/step - loss: 0.0274 - val_loss: 0.0321\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 28us/step - loss: 0.0276 - val_loss: 0.0326\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 33us/step - loss: 0.0275 - val_loss: 0.0312\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 40us/step - loss: 0.0274 - val_loss: 0.0326\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 39us/step - loss: 0.0273 - val_loss: 0.0308\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 45us/step - loss: 0.0274 - val_loss: 0.0311\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 32us/step - loss: 0.0278 - val_loss: 0.0316\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 38us/step - loss: 0.0278 - val_loss: 0.0299\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 38us/step - loss: 0.0277 - val_loss: 0.0322\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 52us/step - loss: 0.0279 - val_loss: 0.0309\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 57us/step - loss: 0.0276 - val_loss: 0.0303\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 31us/step - loss: 0.0276 - val_loss: 0.0289\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 38us/step - loss: 0.0277 - val_loss: 0.0329\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 40us/step - loss: 0.0278 - val_loss: 0.0300\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 40us/step - loss: 0.0275 - val_loss: 0.0294\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 39us/step - loss: 0.0279 - val_loss: 0.0298\n",
      "best reward is :  [0.5557377  0.51992933 0.4260241  0.25442623 0.2302439 ]\n",
      "reward is :  [0.5557377  0.51992933 0.4260241  0.02360656 0.17170732]\n",
      "regrets is :  [0.         0.         0.         0.23081967 0.05853659] \n",
      "\n",
      "best reward is :  [0.55882353 0.51992933 0.43570248 0.25442623 0.2302439 ]\n",
      "reward is :  [0.55882353 0.51992933 0.18691589 0.43570248 0.02360656]\n",
      "regrets is :  [ 0.          0.          0.24878659 -0.18127625  0.20663735] \n",
      "\n",
      "best reward is :  [0.62597015 0.57675174 0.54786885 0.48385787 0.47988131]\n",
      "reward is :  [0.02086957 0.32       0.03570248 0.34691589 0.34360656]\n",
      "regrets is :  [0.60510058 0.25675174 0.51216637 0.13694198 0.13627475] \n",
      "\n",
      "best reward is :  [0.47570248 0.38965174 0.34086957 0.25442623 0.23707317]\n",
      "reward is :  [0.34086957 0.16786885 0.47570248 0.18691589 0.02360656]\n",
      "regrets is :  [ 0.13483291  0.22178289 -0.13483291  0.06751034  0.21346661] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 31us/step - loss: 0.0279 - val_loss: 0.0310\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.0278 - val_loss: 0.0295\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.0281 - val_loss: 0.0322\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.0281 - val_loss: 0.0320\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.0278 - val_loss: 0.0327\n",
      "best reward is :  [0.72360656 0.46538813 0.42597015 0.4171912  0.41707317]\n",
      "reward is :  [0.02232558 0.28786885 0.04385787 0.18938776 0.72360656]\n",
      "regrets is :  [ 0.70128098  0.17751928  0.38211228  0.22780345 -0.30653339] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 84us/step - loss: 0.0521 - val_loss: 0.0292\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0270 - val_loss: 0.0283\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0272 - val_loss: 0.0286\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0270 - val_loss: 0.0283\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0278 - val_loss: 0.0298\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0269 - val_loss: 0.0305\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0269 - val_loss: 0.0293\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0271 - val_loss: 0.0286\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0271 - val_loss: 0.0303\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0275 - val_loss: 0.0288\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0275 - val_loss: 0.0278\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0272 - val_loss: 0.0296\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0275 - val_loss: 0.0313\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0274 - val_loss: 0.0351\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0282 - val_loss: 0.0321\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0269 - val_loss: 0.0288\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0271 - val_loss: 0.0294\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0271 - val_loss: 0.0291\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0272 - val_loss: 0.0293\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0272 - val_loss: 0.0283\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0270 - val_loss: 0.0282\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 32us/step - loss: 0.0272 - val_loss: 0.0305\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 69us/step - loss: 0.0271 - val_loss: 0.0328\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 54us/step - loss: 0.0274 - val_loss: 0.0332\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4950/4950 [==============================] - 0s 41us/step - loss: 0.0275 - val_loss: 0.0301\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 42us/step - loss: 0.0276 - val_loss: 0.0292\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 50us/step - loss: 0.0272 - val_loss: 0.0326\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 79us/step - loss: 0.0271 - val_loss: 0.0349\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 58us/step - loss: 0.0276 - val_loss: 0.0306\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.0275 - val_loss: 0.0267\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 62us/step - loss: 0.0274 - val_loss: 0.0329\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 43us/step - loss: 0.0280 - val_loss: 0.0256\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 68us/step - loss: 0.0280 - val_loss: 0.0297\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 38us/step - loss: 0.0277 - val_loss: 0.0240\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 42us/step - loss: 0.0273 - val_loss: 0.0378\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 43us/step - loss: 0.0279 - val_loss: 0.0441\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 56us/step - loss: 0.0277 - val_loss: 0.0219\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 71us/step - loss: 0.0278 - val_loss: 0.0240\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 52us/step - loss: 0.0275 - val_loss: 0.0254\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 29us/step - loss: 0.0274 - val_loss: 0.0243\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 29us/step - loss: 0.0282 - val_loss: 0.0250\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 45us/step - loss: 0.0270 - val_loss: 0.0250\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 46us/step - loss: 0.0273 - val_loss: 0.0279\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.0273 - val_loss: 0.0254\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 47us/step - loss: 0.0272 - val_loss: 0.0286\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 45us/step - loss: 0.0273 - val_loss: 0.0261\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 38us/step - loss: 0.0270 - val_loss: 0.0279\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 43us/step - loss: 0.0272 - val_loss: 0.0285\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 45us/step - loss: 0.0273 - val_loss: 0.0269\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 53us/step - loss: 0.0274 - val_loss: 0.0280\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 50us/step - loss: 0.0270 - val_loss: 0.0275\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 32us/step - loss: 0.0269 - val_loss: 0.0350\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 27us/step - loss: 0.0268 - val_loss: 0.0323\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 26us/step - loss: 0.0269 - val_loss: 0.0332\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 27us/step - loss: 0.0268 - val_loss: 0.0340\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 32us/step - loss: 0.0270 - val_loss: 0.0329\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 39us/step - loss: 0.0271 - val_loss: 0.0353\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 42us/step - loss: 0.0269 - val_loss: 0.0342\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 39us/step - loss: 0.0271 - val_loss: 0.0325\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 31us/step - loss: 0.0272 - val_loss: 0.0323\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 38us/step - loss: 0.0272 - val_loss: 0.0332\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 22us/step - loss: 0.0275 - val_loss: 0.0313\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 35us/step - loss: 0.0277 - val_loss: 0.0302\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 49us/step - loss: 0.0276 - val_loss: 0.0300\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 42us/step - loss: 0.0273 - val_loss: 0.0298\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 45us/step - loss: 0.0273 - val_loss: 0.0300\n",
      "best reward is :  [0.57090909 0.54588235 0.53454545 0.52516129 0.50642857]\n",
      "reward is :  [0.36       0.53454545 0.024      0.03692308 0.        ]\n",
      "regrets is :  [0.21090909 0.0113369  0.51054545 0.48823821 0.50642857] \n",
      "\n",
      "best reward is :  [0.50424242 0.47921569 0.45849462 0.42642857 0.41619048]\n",
      "reward is :  [0.20137931 0.33454545 0.024      0.         0.03692308]\n",
      "regrets is :  [0.30286311 0.14467023 0.43449462 0.42642857 0.3792674 ] \n",
      "\n",
      "best reward is :  [0.41025641 0.39733333 0.29234043 0.26706468 0.23597484]\n",
      "reward is :  [0.01090909 0.06315789 0.39733333 0.21333333 0.41025641]\n",
      "regrets is :  [ 0.39934732  0.33417544 -0.10499291  0.05373134 -0.17428157] \n",
      "\n",
      "best reward is :  [0.55916667 0.52642857 0.47090909 0.44588235 0.44315789]\n",
      "reward is :  [0.44315789 0.29090909 0.02823529 0.         0.03692308]\n",
      "regrets is :  [0.11600877 0.23551948 0.4426738  0.44588235 0.40623482] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.0276 - val_loss: 0.0292\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 46us/step - loss: 0.0276 - val_loss: 0.0287\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 46us/step - loss: 0.0279 - val_loss: 0.0286\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 48us/step - loss: 0.0275 - val_loss: 0.0296\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.0276 - val_loss: 0.0298\n",
      "best reward is :  [0.41333333 0.3597619  0.35515152 0.34315789 0.33829787]\n",
      "reward is :  [0.34315789 0.21846154 0.06823529 0.2        0.21025641]\n",
      "regrets is :  [0.07017544 0.14130037 0.28691622 0.14315789 0.12804146] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 87us/step - loss: 0.1810 - val_loss: 0.0440\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 55us/step - loss: 0.0332 - val_loss: 0.0264\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0258 - val_loss: 0.0247\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0254 - val_loss: 0.0247\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0254 - val_loss: 0.0261\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 54us/step - loss: 0.0253 - val_loss: 0.0256\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0256 - val_loss: 0.0247\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0257 - val_loss: 0.0247\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0258 - val_loss: 0.0259\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 51us/step - loss: 0.0256 - val_loss: 0.0268\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0257 - val_loss: 0.0246\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0256 - val_loss: 0.0260\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0257 - val_loss: 0.0241\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0260 - val_loss: 0.0248\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0257 - val_loss: 0.0258\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0262 - val_loss: 0.0268\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0259 - val_loss: 0.0252\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0267 - val_loss: 0.0272\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0260 - val_loss: 0.0247\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0260 - val_loss: 0.0245\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0260 - val_loss: 0.0255\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0261 - val_loss: 0.0303\n",
      "Epoch 23/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0264 - val_loss: 0.0257\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 35us/step - loss: 0.0264 - val_loss: 0.0275\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 37us/step - loss: 0.0261 - val_loss: 0.0271\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 38us/step - loss: 0.0259 - val_loss: 0.0276\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 42us/step - loss: 0.0259 - val_loss: 0.0284\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 40us/step - loss: 0.0257 - val_loss: 0.0296\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 34us/step - loss: 0.0260 - val_loss: 0.0329\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 37us/step - loss: 0.0259 - val_loss: 0.0306\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 42us/step - loss: 0.0261 - val_loss: 0.0344\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.0262 - val_loss: 0.0355\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.0263 - val_loss: 0.0361\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 51us/step - loss: 0.0264 - val_loss: 0.0254\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 54us/step - loss: 0.0264 - val_loss: 0.0236\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 51us/step - loss: 0.0263 - val_loss: 0.0211\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 1s 184us/step - loss: 0.0263 - val_loss: 0.0220\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 46us/step - loss: 0.0263 - val_loss: 0.0264\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 29us/step - loss: 0.0268 - val_loss: 0.0260\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 24us/step - loss: 0.0264 - val_loss: 0.0253\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 24us/step - loss: 0.0264 - val_loss: 0.0251\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 23us/step - loss: 0.0266 - val_loss: 0.0268\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 24us/step - loss: 0.0262 - val_loss: 0.0307\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 22us/step - loss: 0.0261 - val_loss: 0.0300\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 22us/step - loss: 0.0262 - val_loss: 0.0267\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 23us/step - loss: 0.0262 - val_loss: 0.0299\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 22us/step - loss: 0.0263 - val_loss: 0.0273\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 23us/step - loss: 0.0261 - val_loss: 0.0269\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 33us/step - loss: 0.0264 - val_loss: 0.0302\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 36us/step - loss: 0.0263 - val_loss: 0.0291\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 37us/step - loss: 0.0261 - val_loss: 0.0309\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 39us/step - loss: 0.0263 - val_loss: 0.0305\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 37us/step - loss: 0.0260 - val_loss: 0.0283\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 31us/step - loss: 0.0262 - val_loss: 0.0333\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 34us/step - loss: 0.0261 - val_loss: 0.0335\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 35us/step - loss: 0.0265 - val_loss: 0.0311\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 48us/step - loss: 0.0260 - val_loss: 0.0292\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 40us/step - loss: 0.0262 - val_loss: 0.0289\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 32us/step - loss: 0.0266 - val_loss: 0.0252\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 34us/step - loss: 0.0265 - val_loss: 0.0279\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 42us/step - loss: 0.0265 - val_loss: 0.0275\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 40us/step - loss: 0.0264 - val_loss: 0.0285\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 55us/step - loss: 0.0263 - val_loss: 0.0271\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 24us/step - loss: 0.0266 - val_loss: 0.0266\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 40us/step - loss: 0.0264 - val_loss: 0.0277\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 38us/step - loss: 0.0264 - val_loss: 0.0282\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 44us/step - loss: 0.0265 - val_loss: 0.0294\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 38us/step - loss: 0.0263 - val_loss: 0.0300\n",
      "best reward is :  [0.81149304 0.74666667 0.64       0.52249084 0.51620309]\n",
      "reward is :  [0.01137441 0.28517647 0.04324324 0.18527473 0.26716981]\n",
      "regrets is :  [0.80011863 0.4614902  0.59675676 0.33721612 0.24903328] \n",
      "\n",
      "best reward is :  [0.41137441 0.38691824 0.38324324 0.27293891 0.24      ]\n",
      "reward is :  [0.41137441 0.04517647 0.38324324 0.00527473 0.02716981]\n",
      "regrets is :  [0.         0.34174177 0.         0.26766419 0.21283019] \n",
      "\n",
      "best reward is :  [0.4        0.33149304 0.25195021 0.2405997  0.22691824]\n",
      "reward is :  [0.25195021 0.04517647 0.22324324 0.00527473 0.02716981]\n",
      "regrets is :  [0.14804979 0.28631657 0.02870696 0.23532497 0.19974843] \n",
      "\n",
      "best reward is :  [0.42324324 0.41195021 0.29358491 0.26717201 0.26189944]\n",
      "reward is :  [0.41195021 0.20517647 0.42324324 0.16527473 0.18716981]\n",
      "regrets is :  [ 0.01129304  0.20677374 -0.12965834  0.10189729  0.07472963] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 30us/step - loss: 0.0263 - val_loss: 0.0309\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.0263 - val_loss: 0.0298\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.0265 - val_loss: 0.0295\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.0265 - val_loss: 0.0295\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.0265 - val_loss: 0.0302\n",
      "best reward is :  [0.61149304 0.58       0.44       0.42517647 0.37173554]\n",
      "reward is :  [0.01239852 0.42517647 0.04551724 0.00676056 0.26960352]\n",
      "regrets is :  [0.59909452 0.15482353 0.39448276 0.41841591 0.10213201] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 81us/step - loss: 0.0573 - val_loss: 0.0249\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0279 - val_loss: 0.0231\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0279 - val_loss: 0.0239\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0280 - val_loss: 0.0251\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0280 - val_loss: 0.0230\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0283 - val_loss: 0.0239\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0287 - val_loss: 0.0239\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0279 - val_loss: 0.0230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0283 - val_loss: 0.0230\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0279 - val_loss: 0.0229\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0281 - val_loss: 0.0221\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0280 - val_loss: 0.0251\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0284 - val_loss: 0.0250\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0282 - val_loss: 0.0236\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0281 - val_loss: 0.0259\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0278 - val_loss: 0.0231\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0281 - val_loss: 0.0233\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0280 - val_loss: 0.0255\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0282 - val_loss: 0.0232\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0284 - val_loss: 0.0245\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0284 - val_loss: 0.0228\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 29us/step - loss: 0.0274 - val_loss: 0.0337\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 37us/step - loss: 0.0277 - val_loss: 0.0335\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 41us/step - loss: 0.0278 - val_loss: 0.0336\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 44us/step - loss: 0.0277 - val_loss: 0.0316\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 42us/step - loss: 0.0276 - val_loss: 0.0313\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.0276 - val_loss: 0.0295\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.0278 - val_loss: 0.0280\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.0276 - val_loss: 0.0286\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.0281 - val_loss: 0.0270\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 46us/step - loss: 0.0282 - val_loss: 0.0289\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 34us/step - loss: 0.0280 - val_loss: 0.0259\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 36us/step - loss: 0.0278 - val_loss: 0.0267\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 38us/step - loss: 0.0280 - val_loss: 0.0269\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 38us/step - loss: 0.0279 - val_loss: 0.0256\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 35us/step - loss: 0.0278 - val_loss: 0.0258\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 33us/step - loss: 0.0281 - val_loss: 0.0304\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 31us/step - loss: 0.0276 - val_loss: 0.0293\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 41us/step - loss: 0.0279 - val_loss: 0.0299\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 42us/step - loss: 0.0276 - val_loss: 0.0313\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 40us/step - loss: 0.0282 - val_loss: 0.0288\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 32us/step - loss: 0.0276 - val_loss: 0.0324\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.0276 - val_loss: 0.0262\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.0277 - val_loss: 0.0317\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.0275 - val_loss: 0.0254\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.0280 - val_loss: 0.0289\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 36us/step - loss: 0.0278 - val_loss: 0.0270\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 36us/step - loss: 0.0278 - val_loss: 0.0267\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 40us/step - loss: 0.0279 - val_loss: 0.0280\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 42us/step - loss: 0.0276 - val_loss: 0.0304\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 1s 72us/step - loss: 0.0277 - val_loss: 0.0278\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 19us/step - loss: 0.0277 - val_loss: 0.0305\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 21us/step - loss: 0.0274 - val_loss: 0.0300\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 26us/step - loss: 0.0273 - val_loss: 0.0292\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 25us/step - loss: 0.0276 - val_loss: 0.0287\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 26us/step - loss: 0.0275 - val_loss: 0.0309\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 34us/step - loss: 0.0279 - val_loss: 0.0286\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 31us/step - loss: 0.0277 - val_loss: 0.0279\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 24us/step - loss: 0.0275 - val_loss: 0.0289\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 26us/step - loss: 0.0274 - val_loss: 0.0282\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 25us/step - loss: 0.0277 - val_loss: 0.0290\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 24us/step - loss: 0.0276 - val_loss: 0.0284\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 34us/step - loss: 0.0275 - val_loss: 0.0311\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 38us/step - loss: 0.0278 - val_loss: 0.0290\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 39us/step - loss: 0.0275 - val_loss: 0.0282\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 39us/step - loss: 0.0276 - val_loss: 0.0298\n",
      "best reward is :  [0.58179104 0.5235514  0.41341365 0.408403   0.39655172]\n",
      "reward is :  [0.1844586  0.36125    0.06285714 0.19538462 0.58179104]\n",
      "regrets is :  [ 0.39733245  0.1623014   0.35055651  0.21301839 -0.18523932] \n",
      "\n",
      "best reward is :  [0.5435514  0.520625   0.44985885 0.44508475 0.43341365]\n",
      "reward is :  [0.0244586  0.32125    0.22285714 0.35627119 0.28179104]\n",
      "regrets is :  [0.5190928  0.199375   0.22700171 0.08881356 0.15162261] \n",
      "\n",
      "best reward is :  [0.5835514  0.50318841 0.47515584 0.47341365 0.45655172]\n",
      "reward is :  [0.0244586  0.22125    0.22285714 0.47515584 0.32179104]\n",
      "regrets is :  [ 0.5590928   0.28193841  0.2522987  -0.00174219  0.13476068] \n",
      "\n",
      "best reward is :  [0.82285714 0.71423423 0.52412121 0.51555556 0.3044586 ]\n",
      "reward is :  [0.3044586  0.04125    0.82285714 0.17753425 0.04539007]\n",
      "regrets is :  [ 0.51839854  0.67298423 -0.29873593  0.33802131  0.25906853] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 20us/step - loss: 0.0276 - val_loss: 0.0294\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 24us/step - loss: 0.0275 - val_loss: 0.0302\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.0276 - val_loss: 0.0285\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.0274 - val_loss: 0.0283\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.0274 - val_loss: 0.0319\n",
      "best reward is :  [0.5835514  0.50318841 0.47341365 0.45655172 0.45133333]\n",
      "reward is :  [0.19449102 0.0244586  0.22125    0.45133333 0.38864865]\n",
      "regrets is :  [0.38906038 0.47872981 0.25216365 0.00521839 0.06268468] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500/4500 [==============================] - 0s 92us/step - loss: 0.0699 - val_loss: 0.0299\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0287 - val_loss: 0.0305\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0284 - val_loss: 0.0293\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0286 - val_loss: 0.0303\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0287 - val_loss: 0.0296\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0293 - val_loss: 0.0307\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0290 - val_loss: 0.0310\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0287 - val_loss: 0.0295\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0286 - val_loss: 0.0317\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0291 - val_loss: 0.0300\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0291 - val_loss: 0.0315\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0291 - val_loss: 0.0312\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0287 - val_loss: 0.0304\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 19us/step - loss: 0.0287 - val_loss: 0.0321\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 20us/step - loss: 0.0293 - val_loss: 0.0295\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 20us/step - loss: 0.0290 - val_loss: 0.0325\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 21us/step - loss: 0.0301 - val_loss: 0.0294\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 22us/step - loss: 0.0294 - val_loss: 0.0301\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 34us/step - loss: 0.0291 - val_loss: 0.0278\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 37us/step - loss: 0.0287 - val_loss: 0.0290\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.0294 - val_loss: 0.0302\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 36us/step - loss: 0.0293 - val_loss: 0.0334\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.0289 - val_loss: 0.0292\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 28us/step - loss: 0.0289 - val_loss: 0.0297\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 36us/step - loss: 0.0286 - val_loss: 0.0318\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 36us/step - loss: 0.0294 - val_loss: 0.0320\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 28us/step - loss: 0.0292 - val_loss: 0.0291\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 24us/step - loss: 0.0289 - val_loss: 0.0260\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 18us/step - loss: 0.0293 - val_loss: 0.0251\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 23us/step - loss: 0.0292 - val_loss: 0.0259\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 22us/step - loss: 0.0290 - val_loss: 0.0257\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 25us/step - loss: 0.0291 - val_loss: 0.0251\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 24us/step - loss: 0.0291 - val_loss: 0.0263\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 23us/step - loss: 0.0289 - val_loss: 0.0248\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 22us/step - loss: 0.0292 - val_loss: 0.0253\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 24us/step - loss: 0.0289 - val_loss: 0.0249\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 23us/step - loss: 0.0287 - val_loss: 0.0280\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 24us/step - loss: 0.0289 - val_loss: 0.0262\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 20us/step - loss: 0.0285 - val_loss: 0.0291\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 21us/step - loss: 0.0287 - val_loss: 0.0280\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 38us/step - loss: 0.0285 - val_loss: 0.0299\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 36us/step - loss: 0.0287 - val_loss: 0.0282\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 36us/step - loss: 0.0289 - val_loss: 0.0274\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 35us/step - loss: 0.0286 - val_loss: 0.0249\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 39us/step - loss: 0.0287 - val_loss: 0.0257\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 37us/step - loss: 0.0288 - val_loss: 0.0257\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 30us/step - loss: 0.0288 - val_loss: 0.0239\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 40us/step - loss: 0.0290 - val_loss: 0.0257\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 31us/step - loss: 0.0286 - val_loss: 0.0251\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 40us/step - loss: 0.0286 - val_loss: 0.0263\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 39us/step - loss: 0.0281 - val_loss: 0.0258\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 44us/step - loss: 0.0282 - val_loss: 0.0286\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 38us/step - loss: 0.0282 - val_loss: 0.0257\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 30us/step - loss: 0.0285 - val_loss: 0.0261\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 23us/step - loss: 0.0279 - val_loss: 0.0262\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 24us/step - loss: 0.0280 - val_loss: 0.0298\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 41us/step - loss: 0.0283 - val_loss: 0.0277\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 44us/step - loss: 0.0281 - val_loss: 0.0299\n",
      "best reward is :  [0.54373851 0.42       0.37185617 0.36337662 0.28421053]\n",
      "reward is :  [0.54373851 0.18861538 0.22030457 0.12421053 0.02262626]\n",
      "regrets is :  [0.         0.23138462 0.1515516  0.2391661  0.26158426] \n",
      "\n",
      "best reward is :  [0.47373253 0.45333333 0.34214067 0.26337662 0.24940849]\n",
      "reward is :  [0.47373253 0.34214067 0.24030457 0.14421053 0.02262626]\n",
      "regrets is :  [0.         0.11119266 0.1018361  0.1191661  0.22678223] \n",
      "\n",
      "best reward is :  [0.55506276 0.54184957 0.42       0.37787234 0.37066667]\n",
      "reward is :  [0.55506276 0.35562932 0.54184957 0.12421053 0.02262626]\n",
      "regrets is :  [ 0.          0.18622025 -0.12184957  0.25366181  0.3480404 ] \n",
      "\n",
      "best reward is :  [0.24       0.2359596  0.21333333 0.20262626 0.20101327]\n",
      "reward is :  [0.17832061 0.00909091 0.06184957 0.04421053 0.20262626]\n",
      "regrets is :  [ 0.06167939  0.22686869  0.15148376  0.15841574 -0.00161299] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 54us/step - loss: 0.0281 - val_loss: 0.0312\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 50us/step - loss: 0.0280 - val_loss: 0.0302\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 46us/step - loss: 0.0281 - val_loss: 0.0282\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.0283 - val_loss: 0.0308\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 55us/step - loss: 0.0281 - val_loss: 0.0290\n",
      "best reward is :  [0.56105263 0.54184957 0.42       0.37787234 0.37066667]\n",
      "reward is :  [0.56105263 0.35575758 0.54184957 0.12421053 0.02262626]\n",
      "regrets is :  [ 0.          0.18609199 -0.12184957  0.25366181  0.3480404 ] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 92us/step - loss: 0.0735 - val_loss: 0.0251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0266 - val_loss: 0.0248\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0259 - val_loss: 0.0244\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0271 - val_loss: 0.0249\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 68us/step - loss: 0.0260 - val_loss: 0.0249\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0259 - val_loss: 0.0247\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0260 - val_loss: 0.0246\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0260 - val_loss: 0.0244\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 55us/step - loss: 0.0260 - val_loss: 0.0253\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 58us/step - loss: 0.0259 - val_loss: 0.0248\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0259 - val_loss: 0.0268\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0263 - val_loss: 0.0255\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0258 - val_loss: 0.0252\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0272 - val_loss: 0.0260\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0264 - val_loss: 0.0246\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0262 - val_loss: 0.0248\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0261 - val_loss: 0.0249\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0259 - val_loss: 0.0256\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 33us/step - loss: 0.0262 - val_loss: 0.0288\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 45us/step - loss: 0.0264 - val_loss: 0.0297\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 51us/step - loss: 0.0262 - val_loss: 0.0299\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 46us/step - loss: 0.0261 - val_loss: 0.0272\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 44us/step - loss: 0.0259 - val_loss: 0.0280\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 27us/step - loss: 0.0260 - val_loss: 0.0297\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.0261 - val_loss: 0.0303\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.0263 - val_loss: 0.0309\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 45us/step - loss: 0.0268 - val_loss: 0.0307\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 48us/step - loss: 0.0267 - val_loss: 0.0298\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 27us/step - loss: 0.0266 - val_loss: 0.0300\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 37us/step - loss: 0.0268 - val_loss: 0.0283\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 34us/step - loss: 0.0264 - val_loss: 0.0262\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 39us/step - loss: 0.0265 - val_loss: 0.0265\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 45us/step - loss: 0.0264 - val_loss: 0.0283\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 25us/step - loss: 0.0264 - val_loss: 0.0192\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 32us/step - loss: 0.0263 - val_loss: 0.0239\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 42us/step - loss: 0.0270 - val_loss: 0.0192\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 46us/step - loss: 0.0266 - val_loss: 0.0225\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 44us/step - loss: 0.0267 - val_loss: 0.0205\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.0262 - val_loss: 0.0297\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 49us/step - loss: 0.0260 - val_loss: 0.0275\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 48us/step - loss: 0.0260 - val_loss: 0.0296\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 47us/step - loss: 0.0261 - val_loss: 0.0283\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 48us/step - loss: 0.0259 - val_loss: 0.0303\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 26us/step - loss: 0.0261 - val_loss: 0.0306\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 37us/step - loss: 0.0260 - val_loss: 0.0309\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 50us/step - loss: 0.0261 - val_loss: 0.0316\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 46us/step - loss: 0.0261 - val_loss: 0.0288\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 42us/step - loss: 0.0261 - val_loss: 0.0299\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 30us/step - loss: 0.0269 - val_loss: 0.0262\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 44us/step - loss: 0.0266 - val_loss: 0.0271\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 52us/step - loss: 0.0264 - val_loss: 0.0286\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 55us/step - loss: 0.0263 - val_loss: 0.0264\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 46us/step - loss: 0.0268 - val_loss: 0.0295\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 37us/step - loss: 0.0267 - val_loss: 0.0275\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 48us/step - loss: 0.0263 - val_loss: 0.0281\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 46us/step - loss: 0.0264 - val_loss: 0.0295\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 48us/step - loss: 0.0265 - val_loss: 0.0275\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 46us/step - loss: 0.0265 - val_loss: 0.0282\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 24us/step - loss: 0.0266 - val_loss: 0.0347\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 40us/step - loss: 0.0264 - val_loss: 0.0356\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 48us/step - loss: 0.0266 - val_loss: 0.0336\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 48us/step - loss: 0.0263 - val_loss: 0.0367\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 45us/step - loss: 0.0265 - val_loss: 0.0338\n",
      "best reward is :  [0.39397849 0.22613333 0.2230303  0.18635294 0.18352941]\n",
      "reward is :  [0.10253521 0.2230303  0.1309699  0.39397849 0.18635294]\n",
      "regrets is :  [ 0.29144328  0.00310303  0.0920604  -0.20762555 -0.00282353] \n",
      "\n",
      "best reward is :  [0.52920188 0.3430303  0.29538462 0.2909699  0.22613333]\n",
      "reward is :  [0.12383562 0.52920188 0.3430303  0.2909699  0.02635294]\n",
      "regrets is :  [ 0.40536626 -0.18617157 -0.04764569  0.          0.19978039] \n",
      "\n",
      "best reward is :  [0.54117647 0.28155844 0.20607595 0.1856     0.17230769]\n",
      "reward is :  [0.06857143 0.54117647 0.20607595 0.28155844 0.1856    ]\n",
      "regrets is :  [ 0.47260504 -0.25961803  0.         -0.09595844 -0.01329231] \n",
      "\n",
      "best reward is :  [0.65230769 0.38624204 0.38155844 0.32864865 0.27089109]\n",
      "reward is :  [0.38624204 0.12607595 0.38155844 0.06857143 0.0256    ]\n",
      "regrets is :  [0.26606565 0.26016609 0.         0.26007722 0.24529109] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 31us/step - loss: 0.0265 - val_loss: 0.0339\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 34us/step - loss: 0.0266 - val_loss: 0.0309\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 33us/step - loss: 0.0267 - val_loss: 0.0325\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.0265 - val_loss: 0.0316\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.0264 - val_loss: 0.0319\n",
      "best reward is :  [0.60624204 0.28444444 0.20607595 0.1856     0.17230769]\n",
      "reward is :  [0.60624204 0.20607595 0.28444444 0.1856     0.06857143]\n",
      "regrets is :  [ 0.          0.0783685  -0.0783685   0.          0.10373626] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 84us/step - loss: 0.1131 - val_loss: 0.0371\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0297 - val_loss: 0.0300\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0279 - val_loss: 0.0274\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0282 - val_loss: 0.0295\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0280 - val_loss: 0.0298\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0283 - val_loss: 0.0283\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0282 - val_loss: 0.0300\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0282 - val_loss: 0.0291\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0285 - val_loss: 0.0289\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0279 - val_loss: 0.0285\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0284 - val_loss: 0.0298\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0284 - val_loss: 0.0281\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0279 - val_loss: 0.0287\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 30us/step - loss: 0.0286 - val_loss: 0.0287\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 34us/step - loss: 0.0289 - val_loss: 0.0282\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 41us/step - loss: 0.0284 - val_loss: 0.0282\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 46us/step - loss: 0.0284 - val_loss: 0.0275\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 43us/step - loss: 0.0282 - val_loss: 0.0289\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 34us/step - loss: 0.0296 - val_loss: 0.0239\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 36us/step - loss: 0.0287 - val_loss: 0.0244\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.0286 - val_loss: 0.0238\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.0284 - val_loss: 0.0268\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.0287 - val_loss: 0.0266\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 19us/step - loss: 0.0285 - val_loss: 0.0305\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 34us/step - loss: 0.0287 - val_loss: 0.0359\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 39us/step - loss: 0.0281 - val_loss: 0.0280\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 37us/step - loss: 0.0282 - val_loss: 0.0322\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 38us/step - loss: 0.0283 - val_loss: 0.0295\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 31us/step - loss: 0.0285 - val_loss: 0.0278\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 35us/step - loss: 0.0282 - val_loss: 0.0298\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 41us/step - loss: 0.0283 - val_loss: 0.0254\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 38us/step - loss: 0.0285 - val_loss: 0.0261\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 40us/step - loss: 0.0280 - val_loss: 0.0266\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 29us/step - loss: 0.0285 - val_loss: 0.0260\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 29us/step - loss: 0.0282 - val_loss: 0.0249\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 24us/step - loss: 0.0288 - val_loss: 0.0266\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 22us/step - loss: 0.0281 - val_loss: 0.0269\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 33us/step - loss: 0.0282 - val_loss: 0.0264\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 34us/step - loss: 0.0283 - val_loss: 0.0335\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 36us/step - loss: 0.0280 - val_loss: 0.0320\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 38us/step - loss: 0.0279 - val_loss: 0.0313\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 39us/step - loss: 0.0279 - val_loss: 0.0315\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 40us/step - loss: 0.0282 - val_loss: 0.0314\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 30us/step - loss: 0.0281 - val_loss: 0.0314\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 39us/step - loss: 0.0281 - val_loss: 0.0321\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 27us/step - loss: 0.0282 - val_loss: 0.0322\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 25us/step - loss: 0.0283 - val_loss: 0.0306\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 26us/step - loss: 0.0282 - val_loss: 0.0317\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 35us/step - loss: 0.0283 - val_loss: 0.0295\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 36us/step - loss: 0.0285 - val_loss: 0.0292\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 39us/step - loss: 0.0283 - val_loss: 0.0294\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 38us/step - loss: 0.0283 - val_loss: 0.0301\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 37us/step - loss: 0.0282 - val_loss: 0.0304\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 27us/step - loss: 0.0284 - val_loss: 0.0283\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 34us/step - loss: 0.0283 - val_loss: 0.0292\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 40us/step - loss: 0.0284 - val_loss: 0.0298\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 38us/step - loss: 0.0284 - val_loss: 0.0291\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 36us/step - loss: 0.0283 - val_loss: 0.0286\n",
      "best reward is :  [0.38016736 0.31363725 0.24794872 0.24685714 0.24182648]\n",
      "reward is :  [0.24182648 0.31363725 0.38016736 0.24685714 0.13482234]\n",
      "regrets is :  [ 0.13834088  0.         -0.13221865  0.          0.10700415] \n",
      "\n",
      "best reward is :  [0.40794872 0.31639871 0.30572127 0.30352159 0.29395349]\n",
      "reward is :  [0.08182648 0.15363725 0.22016736 0.24741617 0.13482234]\n",
      "regrets is :  [0.32612223 0.16276147 0.08555391 0.05610542 0.15913115] \n",
      "\n",
      "best reward is :  [0.58947368 0.50776471 0.50215827 0.48987013 0.47529412]\n",
      "reward is :  [0.40182648 0.47529412 0.04016736 0.19408284 0.21482234]\n",
      "regrets is :  [0.1876472  0.03247059 0.46199091 0.29578729 0.26047178] \n",
      "\n",
      "best reward is :  [0.53653333 0.4677135  0.42693135 0.38206061 0.34709137]\n",
      "reward is :  [0.15529412 0.21950617 0.38206061 0.4677135  0.42693135]\n",
      "regrets is :  [ 0.38123922  0.24820733  0.04487074 -0.08565289 -0.07983998] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.0282 - val_loss: 0.0283\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.0285 - val_loss: 0.0288\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.0284 - val_loss: 0.0285\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.0283 - val_loss: 0.0280\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.0284 - val_loss: 0.0281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best reward is :  [0.50709137 0.47004926 0.4062069  0.40084507 0.39529412]\n",
      "reward is :  [0.39529412 0.03950617 0.19481865 0.16872727 0.22084507]\n",
      "regrets is :  [0.11179725 0.43054309 0.21138824 0.2321178  0.17444905] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 83us/step - loss: 0.0816 - val_loss: 0.0300\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0277 - val_loss: 0.0294\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0279 - val_loss: 0.0291\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0278 - val_loss: 0.0306\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0281 - val_loss: 0.0331\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0279 - val_loss: 0.0353\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0282 - val_loss: 0.0299\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0282 - val_loss: 0.0320\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0280 - val_loss: 0.0313\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0280 - val_loss: 0.0281\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0287 - val_loss: 0.0315\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0280 - val_loss: 0.0320\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0277 - val_loss: 0.0337\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0277 - val_loss: 0.0289\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0281 - val_loss: 0.0314\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0289 - val_loss: 0.0324\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0279 - val_loss: 0.0332\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0282 - val_loss: 0.0310\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0284 - val_loss: 0.0335\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0284 - val_loss: 0.0286\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 32us/step - loss: 0.0284 - val_loss: 0.0348\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 31us/step - loss: 0.0282 - val_loss: 0.0318\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 39us/step - loss: 0.0281 - val_loss: 0.0369\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 36us/step - loss: 0.0286 - val_loss: 0.0272\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 42us/step - loss: 0.0286 - val_loss: 0.0390\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 32us/step - loss: 0.0291 - val_loss: 0.0259\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.0281 - val_loss: 0.0258\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 42us/step - loss: 0.0286 - val_loss: 0.0250\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.0283 - val_loss: 0.0251\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.0289 - val_loss: 0.0238\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 19us/step - loss: 0.0279 - val_loss: 0.0278\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 23us/step - loss: 0.0282 - val_loss: 0.0319\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 24us/step - loss: 0.0285 - val_loss: 0.0282\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 25us/step - loss: 0.0284 - val_loss: 0.0277\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 25us/step - loss: 0.0284 - val_loss: 0.0288\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 19us/step - loss: 0.0281 - val_loss: 0.0324\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 23us/step - loss: 0.0281 - val_loss: 0.0300\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 23us/step - loss: 0.0279 - val_loss: 0.0305\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 24us/step - loss: 0.0283 - val_loss: 0.0320\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 23us/step - loss: 0.0287 - val_loss: 0.0304\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.0283 - val_loss: 0.0288\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.0290 - val_loss: 0.0297\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.0283 - val_loss: 0.0294\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 41us/step - loss: 0.0283 - val_loss: 0.0302\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 42us/step - loss: 0.0284 - val_loss: 0.0300\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 36us/step - loss: 0.0286 - val_loss: 0.0291\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 40us/step - loss: 0.0286 - val_loss: 0.0292\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 35us/step - loss: 0.0285 - val_loss: 0.0287\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 43us/step - loss: 0.0283 - val_loss: 0.0285\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 40us/step - loss: 0.0287 - val_loss: 0.0274\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 35us/step - loss: 0.0286 - val_loss: 0.0284\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 39us/step - loss: 0.0284 - val_loss: 0.0295\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 26us/step - loss: 0.0287 - val_loss: 0.0269\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 24us/step - loss: 0.0282 - val_loss: 0.0281\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 27us/step - loss: 0.0287 - val_loss: 0.0285\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 26us/step - loss: 0.0287 - val_loss: 0.0312\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 36us/step - loss: 0.0282 - val_loss: 0.0314\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 39us/step - loss: 0.0284 - val_loss: 0.0278\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 39us/step - loss: 0.0282 - val_loss: 0.0292\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 39us/step - loss: 0.0284 - val_loss: 0.0282\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 31us/step - loss: 0.0282 - val_loss: 0.0306\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 34us/step - loss: 0.0283 - val_loss: 0.0280\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 37us/step - loss: 0.0281 - val_loss: 0.0280\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 37us/step - loss: 0.0288 - val_loss: 0.0268\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 42us/step - loss: 0.0284 - val_loss: 0.0311\n",
      "best reward is :  [0.418327   0.29790885 0.27115294 0.2218267  0.21113514]\n",
      "reward is :  [0.418327   0.01811321 0.29790885 0.03344948 0.02608696]\n",
      "regrets is :  [ 0.          0.27979564 -0.02675591  0.18837722  0.18504818] \n",
      "\n",
      "best reward is :  [0.52895439 0.52477987 0.48242424 0.44833333 0.440668  ]\n",
      "reward is :  [0.52477987 0.198327   0.21790885 0.19344948 0.18608696]\n",
      "regrets is :  [0.00417451 0.32645288 0.2645154  0.25488386 0.25458105] \n",
      "\n",
      "best reward is :  [0.45371429 0.452      0.44       0.42273151 0.40181818]\n",
      "reward is :  [0.40181818 0.038327   0.05790885 0.42273151 0.34608696]\n",
      "regrets is :  [0.0518961  0.413673   0.38209115 0.         0.05573123] \n",
      "\n",
      "best reward is :  [0.4018267  0.39384615 0.37115294 0.35371429 0.352     ]\n",
      "reward is :  [0.038327   0.05790885 0.39384615 0.2736     0.26608696]\n",
      "regrets is :  [ 0.3634997   0.33593731 -0.02269321  0.08011429  0.08591304] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 0s 34us/step - loss: 0.0280 - val_loss: 0.0295\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.0282 - val_loss: 0.0308\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.0283 - val_loss: 0.0307\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.0282 - val_loss: 0.0300\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.0283 - val_loss: 0.0308\n",
      "best reward is :  [0.58909091 0.58861789 0.43516003 0.40448627 0.38704762]\n",
      "reward is :  [0.038327   0.05790885 0.27845281 0.30608696 0.01371429]\n",
      "regrets is :  [0.55076391 0.53070904 0.15670722 0.09839932 0.37333333] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 84us/step - loss: 0.0702 - val_loss: 0.0281\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0270 - val_loss: 0.0269\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0269 - val_loss: 0.0278\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0273 - val_loss: 0.0269\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0273 - val_loss: 0.0268\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0271 - val_loss: 0.0288\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0280 - val_loss: 0.0278\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0270 - val_loss: 0.0272\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0269 - val_loss: 0.0265\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0273 - val_loss: 0.0280\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0274 - val_loss: 0.0271\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0272 - val_loss: 0.0264\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0275 - val_loss: 0.0268\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0271 - val_loss: 0.0268\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0276 - val_loss: 0.0266\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0276 - val_loss: 0.0272\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0269 - val_loss: 0.0276\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0271 - val_loss: 0.0282\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0269 - val_loss: 0.0278\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0273 - val_loss: 0.0280\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0278 - val_loss: 0.0267\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0268 - val_loss: 0.0272\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 35us/step - loss: 0.0275 - val_loss: 0.0287\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 45us/step - loss: 0.0273 - val_loss: 0.0309\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 34us/step - loss: 0.0270 - val_loss: 0.0301\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 24us/step - loss: 0.0271 - val_loss: 0.0331\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 28us/step - loss: 0.0270 - val_loss: 0.0285\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 34us/step - loss: 0.0278 - val_loss: 0.0289\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 35us/step - loss: 0.0273 - val_loss: 0.0298\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.0273 - val_loss: 0.0301\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.0279 - val_loss: 0.0286\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 28us/step - loss: 0.0274 - val_loss: 0.0290\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 36us/step - loss: 0.0277 - val_loss: 0.0295\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 37us/step - loss: 0.0274 - val_loss: 0.0280\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 37us/step - loss: 0.0276 - val_loss: 0.0275\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 37us/step - loss: 0.0277 - val_loss: 0.0285\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 38us/step - loss: 0.0276 - val_loss: 0.0346\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 35us/step - loss: 0.0278 - val_loss: 0.0292\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 42us/step - loss: 0.0277 - val_loss: 0.0261\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 41us/step - loss: 0.0276 - val_loss: 0.0275\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 33us/step - loss: 0.0273 - val_loss: 0.0236\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 25us/step - loss: 0.0274 - val_loss: 0.0238\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 34us/step - loss: 0.0274 - val_loss: 0.0265\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.0273 - val_loss: 0.0306\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 34us/step - loss: 0.0280 - val_loss: 0.0266\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 41us/step - loss: 0.0275 - val_loss: 0.0292\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0276 - val_loss: 0.0273\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 36us/step - loss: 0.0278 - val_loss: 0.0255\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 33us/step - loss: 0.0275 - val_loss: 0.0380\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 26us/step - loss: 0.0275 - val_loss: 0.0379\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 26us/step - loss: 0.0274 - val_loss: 0.0271\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 32us/step - loss: 0.0275 - val_loss: 0.0287\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 33us/step - loss: 0.0275 - val_loss: 0.0240\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 42us/step - loss: 0.0278 - val_loss: 0.0237\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 35us/step - loss: 0.0274 - val_loss: 0.0270\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 27us/step - loss: 0.0273 - val_loss: 0.0317\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 29us/step - loss: 0.0272 - val_loss: 0.0272\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 18us/step - loss: 0.0275 - val_loss: 0.0335\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 23us/step - loss: 0.0276 - val_loss: 0.0288\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 24us/step - loss: 0.0274 - val_loss: 0.0274\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 26us/step - loss: 0.0270 - val_loss: 0.0286\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 26us/step - loss: 0.0273 - val_loss: 0.0278\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 30us/step - loss: 0.0274 - val_loss: 0.0304\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 37us/step - loss: 0.0273 - val_loss: 0.0301\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 40us/step - loss: 0.0275 - val_loss: 0.0318\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 29us/step - loss: 0.0275 - val_loss: 0.0331\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 27us/step - loss: 0.0272 - val_loss: 0.0307\n",
      "best reward is :  [0.56060086 0.53278592 0.48       0.39368669 0.37333333]\n",
      "reward is :  [0.26901583 0.26506527 0.16680047 0.25137529 0.56060086]\n",
      "regrets is :  [ 0.29158503  0.26772065  0.31319953  0.1423114  -0.18726753] \n",
      "\n",
      "best reward is :  [0.64901583 0.51057325 0.45428571 0.40680047 0.39278592]\n",
      "reward is :  [0.51057325 0.64901583 0.40680047 0.39040327 0.36060086]\n",
      "regrets is :  [ 0.13844258 -0.13844258  0.04748524  0.01639721  0.03218507] \n",
      "\n",
      "best reward is :  [0.54420857 0.50666667 0.5037366  0.40363636 0.39945259]\n",
      "reward is :  [0.3558209  0.06060086 0.25330254 0.5037366  0.36952381]\n",
      "regrets is :  [ 0.18838767  0.44606581  0.25043406 -0.10010024  0.02992878] \n",
      "\n",
      "best reward is :  [0.30060086 0.27428571 0.25927711 0.25737557 0.25566404]\n",
      "reward is :  [0.20082625 0.30060086 0.17330254 0.0437366  0.18285714]\n",
      "regrets is :  [ 0.09977461 -0.02631514  0.08597457  0.21363897  0.0728069 ] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 0s 31us/step - loss: 0.0271 - val_loss: 0.0309\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.0274 - val_loss: 0.0340\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.0273 - val_loss: 0.0316\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.0275 - val_loss: 0.0318\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.0273 - val_loss: 0.0318\n",
      "best reward is :  [0.50363636 0.38233071 0.34637168 0.34176678 0.29476923]\n",
      "reward is :  [0.04082625 0.12952381 0.01330254 0.2037366  0.02285714]\n",
      "regrets is :  [0.46281012 0.2528069  0.33306914 0.13803018 0.27191209] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 85us/step - loss: 0.1054 - val_loss: 0.0310\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0291 - val_loss: 0.0318\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0276 - val_loss: 0.0322\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0278 - val_loss: 0.0318\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0280 - val_loss: 0.0330\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0278 - val_loss: 0.0346\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0280 - val_loss: 0.0315\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0281 - val_loss: 0.0323\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0278 - val_loss: 0.0355\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0282 - val_loss: 0.0320\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0283 - val_loss: 0.0304\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0281 - val_loss: 0.0345\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0284 - val_loss: 0.0336\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0281 - val_loss: 0.0351\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0289 - val_loss: 0.0309\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0281 - val_loss: 0.0340\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0284 - val_loss: 0.0317\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0281 - val_loss: 0.0324\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0283 - val_loss: 0.0326\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0282 - val_loss: 0.0320\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0281 - val_loss: 0.0319\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 18us/step - loss: 0.0289 - val_loss: 0.0309\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 27us/step - loss: 0.0289 - val_loss: 0.0281\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 34us/step - loss: 0.0289 - val_loss: 0.0275\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 38us/step - loss: 0.0284 - val_loss: 0.0287\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 38us/step - loss: 0.0288 - val_loss: 0.0331\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 19us/step - loss: 0.0289 - val_loss: 0.0336\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 35us/step - loss: 0.0289 - val_loss: 0.0263\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.0286 - val_loss: 0.0253\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 43us/step - loss: 0.0288 - val_loss: 0.0275\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 44us/step - loss: 0.0288 - val_loss: 0.0239\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 33us/step - loss: 0.0288 - val_loss: 0.0276\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 41us/step - loss: 0.0283 - val_loss: 0.0282\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 36us/step - loss: 0.0289 - val_loss: 0.0285\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 37us/step - loss: 0.0285 - val_loss: 0.0276\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 39us/step - loss: 0.0284 - val_loss: 0.0278\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 30us/step - loss: 0.0289 - val_loss: 0.0262\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 37us/step - loss: 0.0284 - val_loss: 0.0260\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 37us/step - loss: 0.0286 - val_loss: 0.0259\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 42us/step - loss: 0.0286 - val_loss: 0.0238\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 39us/step - loss: 0.0286 - val_loss: 0.0275\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0282 - val_loss: 0.0272\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.0284 - val_loss: 0.0293\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 47us/step - loss: 0.0282 - val_loss: 0.0255\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 42us/step - loss: 0.0282 - val_loss: 0.0254\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 57us/step - loss: 0.0284 - val_loss: 0.0276\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 28us/step - loss: 0.0280 - val_loss: 0.0227\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 25us/step - loss: 0.0280 - val_loss: 0.0246\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 26us/step - loss: 0.0283 - val_loss: 0.0223\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 26us/step - loss: 0.0279 - val_loss: 0.0245\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 31us/step - loss: 0.0282 - val_loss: 0.0233\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 50us/step - loss: 0.0278 - val_loss: 0.0241\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 51us/step - loss: 0.0275 - val_loss: 0.0266\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 33us/step - loss: 0.0278 - val_loss: 0.0254\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 27us/step - loss: 0.0277 - val_loss: 0.0269\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 24us/step - loss: 0.0278 - val_loss: 0.0250\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 34us/step - loss: 0.0277 - val_loss: 0.0272\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 36us/step - loss: 0.0274 - val_loss: 0.0263\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 31us/step - loss: 0.0276 - val_loss: 0.0262\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 27us/step - loss: 0.0276 - val_loss: 0.0283\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 49us/step - loss: 0.0274 - val_loss: 0.0264\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 33us/step - loss: 0.0275 - val_loss: 0.0264\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 40us/step - loss: 0.0274 - val_loss: 0.0260\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 38us/step - loss: 0.0275 - val_loss: 0.0250\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 41us/step - loss: 0.0273 - val_loss: 0.0261\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 29us/step - loss: 0.0275 - val_loss: 0.0246\n",
      "best reward is :  [0.53875246 0.53243173 0.48603774 0.47310924 0.46609795]\n",
      "reward is :  [0.02967033 0.26709957 0.21208385 0.102881   0.25780591]\n",
      "regrets is :  [0.50908213 0.26533216 0.27395389 0.37022824 0.20829204] \n",
      "\n",
      "best reward is :  [0.5077686  0.48808321 0.48603774 0.47393939 0.43493934]\n",
      "reward is :  [0.02967033 0.04709957 0.05208385 0.26473324 0.04173913]\n",
      "regrets is :  [0.47809827 0.44098364 0.43395389 0.20920615 0.39320021] \n",
      "\n",
      "best reward is :  [0.53875246 0.53243173 0.48603774 0.47310924 0.46609795]\n",
      "reward is :  [0.02967033 0.2681337  0.21208385 0.1665232  0.26173913]\n",
      "regrets is :  [0.50908213 0.26429802 0.27395389 0.30658604 0.20435882] \n",
      "\n",
      "best reward is :  [0.61318987 0.54060606 0.42403756 0.39632735 0.3942029 ]\n",
      "reward is :  [0.26967033 0.2281337  0.23208385 0.61318987 0.25874726]\n",
      "regrets is :  [ 0.34351954  0.31247236  0.19195371 -0.21686252  0.13545564] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 0s 21us/step - loss: 0.0274 - val_loss: 0.0268\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 21us/step - loss: 0.0273 - val_loss: 0.0269\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.0270 - val_loss: 0.0273\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 21us/step - loss: 0.0272 - val_loss: 0.0274\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.0273 - val_loss: 0.0266\n",
      "best reward is :  [0.67493934 0.54060606 0.46141654 0.46016474 0.38480744]\n",
      "reward is :  [0.46016474 0.02967033 0.04909825 0.05208385 0.04541393]\n",
      "regrets is :  [0.2147746  0.51093573 0.41231829 0.4080809  0.33939351] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 69us/step - loss: 0.0817 - val_loss: 0.0300\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0272 - val_loss: 0.0254\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0266 - val_loss: 0.0267\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0267 - val_loss: 0.0266\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0268 - val_loss: 0.0252\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0271 - val_loss: 0.0257\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0268 - val_loss: 0.0259\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0267 - val_loss: 0.0253\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0266 - val_loss: 0.0258\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0273 - val_loss: 0.0269\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0272 - val_loss: 0.0266\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0271 - val_loss: 0.0257\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0268 - val_loss: 0.0257\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0267 - val_loss: 0.0265\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0269 - val_loss: 0.0262\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 31us/step - loss: 0.0268 - val_loss: 0.0235\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 41us/step - loss: 0.0273 - val_loss: 0.0259\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 37us/step - loss: 0.0269 - val_loss: 0.0331\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 44us/step - loss: 0.0268 - val_loss: 0.0245\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 35us/step - loss: 0.0267 - val_loss: 0.0257\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 32us/step - loss: 0.0264 - val_loss: 0.0271\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.0271 - val_loss: 0.0256\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.0266 - val_loss: 0.0287\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 37us/step - loss: 0.0269 - val_loss: 0.0284\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.0269 - val_loss: 0.0250\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 30us/step - loss: 0.0264 - val_loss: 0.0270\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 37us/step - loss: 0.0269 - val_loss: 0.0256\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 40us/step - loss: 0.0271 - val_loss: 0.0274\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 38us/step - loss: 0.0267 - val_loss: 0.0282\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 40us/step - loss: 0.0270 - val_loss: 0.0255\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 35us/step - loss: 0.0267 - val_loss: 0.0244\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 38us/step - loss: 0.0265 - val_loss: 0.0252\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 28us/step - loss: 0.0266 - val_loss: 0.0250\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 24us/step - loss: 0.0269 - val_loss: 0.0243\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 25us/step - loss: 0.0264 - val_loss: 0.0261\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0269 - val_loss: 0.0276\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.0264 - val_loss: 0.0280\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.0264 - val_loss: 0.0293\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.0270 - val_loss: 0.0289\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 41us/step - loss: 0.0268 - val_loss: 0.0268\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 19us/step - loss: 0.0265 - val_loss: 0.0266\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 25us/step - loss: 0.0265 - val_loss: 0.0284\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 26us/step - loss: 0.0265 - val_loss: 0.0256\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 27us/step - loss: 0.0265 - val_loss: 0.0268\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 27us/step - loss: 0.0265 - val_loss: 0.0294\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 23us/step - loss: 0.0264 - val_loss: 0.0258\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 25us/step - loss: 0.0265 - val_loss: 0.0253\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 26us/step - loss: 0.0266 - val_loss: 0.0266\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 25us/step - loss: 0.0265 - val_loss: 0.0272\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 25us/step - loss: 0.0266 - val_loss: 0.0275\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 20us/step - loss: 0.0266 - val_loss: 0.0270\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 25us/step - loss: 0.0263 - val_loss: 0.0266\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 36us/step - loss: 0.0264 - val_loss: 0.0268\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 37us/step - loss: 0.0266 - val_loss: 0.0259\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 45us/step - loss: 0.0265 - val_loss: 0.0258\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 30us/step - loss: 0.0261 - val_loss: 0.0275\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 35us/step - loss: 0.0262 - val_loss: 0.0297\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 34us/step - loss: 0.0263 - val_loss: 0.0280\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 27us/step - loss: 0.0262 - val_loss: 0.0275\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 25us/step - loss: 0.0261 - val_loss: 0.0292\n",
      "best reward is :  [0.52190476 0.49777778 0.40857143 0.40430108 0.39908676]\n",
      "reward is :  [0.29092805 0.0691358  0.23076923 0.15272727 0.40857143]\n",
      "regrets is :  [ 0.23097671  0.42864198  0.1778022   0.2515738  -0.00948467] \n",
      "\n",
      "best reward is :  [0.29239216 0.288      0.268      0.24776471 0.23733333]\n",
      "reward is :  [0.288      0.0672     0.268      0.15272727 0.24776471]\n",
      "regrets is :  [ 0.00439216  0.2208      0.          0.09503743 -0.01043137] \n",
      "\n",
      "best reward is :  [0.60333333 0.59272727 0.51466667 0.5072     0.4533202 ]\n",
      "reward is :  [0.4533202  0.5072     0.51466667 0.59272727 0.06776471]\n",
      "regrets is :  [ 0.15001314  0.08552727  0.         -0.08552727  0.38555549] \n",
      "\n",
      "best reward is :  [0.556      0.52861538 0.49485714 0.47972414 0.47272727]\n",
      "reward is :  [0.224      0.3872     0.47272727 0.22776471 0.31096774]\n",
      "regrets is :  [0.332      0.14141538 0.02212987 0.25195943 0.16175953] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.0263 - val_loss: 0.0318\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.0261 - val_loss: 0.0265\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.0264 - val_loss: 0.0287\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.0264 - val_loss: 0.0270\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.0262 - val_loss: 0.0276\n",
      "best reward is :  [0.62884848 0.53698246 0.50776471 0.46239269 0.45476923]\n",
      "reward is :  [0.35542857 0.15272727 0.396      0.50776471 0.25905882]\n",
      "regrets is :  [ 0.27341991  0.38425518  0.11176471 -0.04537201  0.19571041] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 82us/step - loss: 0.1168 - val_loss: 0.0313\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0301 - val_loss: 0.0263\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0285 - val_loss: 0.0265\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0283 - val_loss: 0.0258\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0285 - val_loss: 0.0257\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0282 - val_loss: 0.0265\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0283 - val_loss: 0.0268\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0285 - val_loss: 0.0269\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0288 - val_loss: 0.0267\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0290 - val_loss: 0.0252\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0287 - val_loss: 0.0276\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0286 - val_loss: 0.0269\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0285 - val_loss: 0.0271\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0287 - val_loss: 0.0296\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 51us/step - loss: 0.0290 - val_loss: 0.0268\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0288 - val_loss: 0.0269\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0290 - val_loss: 0.0273\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0286 - val_loss: 0.0270\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0290 - val_loss: 0.0277\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 51us/step - loss: 0.0287 - val_loss: 0.0277\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 45us/step - loss: 0.0287 - val_loss: 0.0268\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 47us/step - loss: 0.0287 - val_loss: 0.0281\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 39us/step - loss: 0.0285 - val_loss: 0.0278\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 66us/step - loss: 0.0289 - val_loss: 0.0291\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 49us/step - loss: 0.0286 - val_loss: 0.0308\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 35us/step - loss: 0.0286 - val_loss: 0.0279\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 43us/step - loss: 0.0287 - val_loss: 0.0293\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.0291 - val_loss: 0.0299\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 43us/step - loss: 0.0288 - val_loss: 0.0308\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 58us/step - loss: 0.0288 - val_loss: 0.0320\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 53us/step - loss: 0.0287 - val_loss: 0.0273\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 45us/step - loss: 0.0286 - val_loss: 0.0263\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 43us/step - loss: 0.0289 - val_loss: 0.0268\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 38us/step - loss: 0.0289 - val_loss: 0.0269\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 35us/step - loss: 0.0284 - val_loss: 0.0277\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 25us/step - loss: 0.0284 - val_loss: 0.0320\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 29us/step - loss: 0.0290 - val_loss: 0.0300\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 32us/step - loss: 0.0284 - val_loss: 0.0316\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 33us/step - loss: 0.0285 - val_loss: 0.0299\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 41us/step - loss: 0.0284 - val_loss: 0.0350\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0288 - val_loss: 0.0299\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 46us/step - loss: 0.0287 - val_loss: 0.0284\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 42us/step - loss: 0.0287 - val_loss: 0.0300\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.0288 - val_loss: 0.0283\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 51us/step - loss: 0.0284 - val_loss: 0.0282\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 33us/step - loss: 0.0286 - val_loss: 0.0312\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 35us/step - loss: 0.0289 - val_loss: 0.0331\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 36us/step - loss: 0.0292 - val_loss: 0.0309\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 46us/step - loss: 0.0289 - val_loss: 0.0305\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 45us/step - loss: 0.0286 - val_loss: 0.0288\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 42us/step - loss: 0.0286 - val_loss: 0.0299\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 35us/step - loss: 0.0285 - val_loss: 0.0317\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 38us/step - loss: 0.0286 - val_loss: 0.0298\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 52us/step - loss: 0.0284 - val_loss: 0.0291\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 41us/step - loss: 0.0285 - val_loss: 0.0288\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 45us/step - loss: 0.0287 - val_loss: 0.0301\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 52us/step - loss: 0.0285 - val_loss: 0.0280\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 49us/step - loss: 0.0285 - val_loss: 0.0318\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 45us/step - loss: 0.0286 - val_loss: 0.0431\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 39us/step - loss: 0.0289 - val_loss: 0.0323\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 36us/step - loss: 0.0290 - val_loss: 0.0326\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 35us/step - loss: 0.0285 - val_loss: 0.0290\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 45us/step - loss: 0.0286 - val_loss: 0.0299\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 43us/step - loss: 0.0287 - val_loss: 0.0340\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 36us/step - loss: 0.0284 - val_loss: 0.0375\n",
      "best reward is :  [0.62753769 0.51544615 0.49764706 0.48919904 0.44648732]\n",
      "reward is :  [0.02185958 0.18335135 0.19153285 0.00802228 0.48919904]\n",
      "regrets is :  [ 0.60567811  0.3320948   0.30611421  0.48117676 -0.04271173] \n",
      "\n",
      "best reward is :  [0.51933884 0.44       0.39764706 0.38753769 0.36280255]\n",
      "reward is :  [0.02335135 0.03153285 0.02185958 0.00802228 0.33991701]\n",
      "regrets is :  [0.49598749 0.40846715 0.37578748 0.3795154  0.02288554] \n",
      "\n",
      "best reward is :  [0.51933884 0.44       0.39764706 0.38753769 0.36280255]\n",
      "reward is :  [0.02335135 0.03153285 0.02185958 0.00802228 0.33991701]\n",
      "regrets is :  [0.49598749 0.40846715 0.37578748 0.3795154  0.02288554] \n",
      "\n",
      "best reward is :  [0.56802228 0.5312     0.50185958 0.43153285 0.42335135]\n",
      "reward is :  [0.42335135 0.43153285 0.50185958 0.56802228 0.17991701]\n",
      "regrets is :  [ 0.14467093  0.09966715  0.         -0.13648944  0.24343434] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.0285 - val_loss: 0.0254\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.0286 - val_loss: 0.0250\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.0285 - val_loss: 0.0260\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.0284 - val_loss: 0.0290\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.0287 - val_loss: 0.0243\n",
      "best reward is :  [0.52431373 0.50753769 0.40583333 0.40373043 0.3712    ]\n",
      "reward is :  [0.18335135 0.19153285 0.02185958 0.01116279 0.29991701]\n",
      "regrets is :  [0.34096237 0.31600484 0.38397375 0.39256763 0.07128299] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 89us/step - loss: 0.1063 - val_loss: 0.0315\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0283 - val_loss: 0.0276\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0272 - val_loss: 0.0277\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0273 - val_loss: 0.0281\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0273 - val_loss: 0.0275\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0275 - val_loss: 0.0280\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0276 - val_loss: 0.0281\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0274 - val_loss: 0.0311\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0277 - val_loss: 0.0270\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0275 - val_loss: 0.0258\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0277 - val_loss: 0.0269\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0280 - val_loss: 0.0277\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0278 - val_loss: 0.0282\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0280 - val_loss: 0.0289\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0278 - val_loss: 0.0288\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0279 - val_loss: 0.0279\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0281 - val_loss: 0.0264\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0276 - val_loss: 0.0289\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0282 - val_loss: 0.0284\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0276 - val_loss: 0.0262\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 36us/step - loss: 0.0280 - val_loss: 0.0342\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 39us/step - loss: 0.0284 - val_loss: 0.0249\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 37us/step - loss: 0.0278 - val_loss: 0.0302\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 39us/step - loss: 0.0279 - val_loss: 0.0258\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 40us/step - loss: 0.0277 - val_loss: 0.0287\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.0277 - val_loss: 0.0331\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 37us/step - loss: 0.0280 - val_loss: 0.0327\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 37us/step - loss: 0.0279 - val_loss: 0.0305\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 37us/step - loss: 0.0277 - val_loss: 0.0317\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.0276 - val_loss: 0.0329\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 29us/step - loss: 0.0282 - val_loss: 0.0329\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 37us/step - loss: 0.0278 - val_loss: 0.0294\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 37us/step - loss: 0.0282 - val_loss: 0.0313\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 34us/step - loss: 0.0279 - val_loss: 0.0304\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 25us/step - loss: 0.0277 - val_loss: 0.0309\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 34us/step - loss: 0.0283 - val_loss: 0.0287\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 35us/step - loss: 0.0281 - val_loss: 0.0249\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 40us/step - loss: 0.0282 - val_loss: 0.0301\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 25us/step - loss: 0.0283 - val_loss: 0.0315\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 24us/step - loss: 0.0281 - val_loss: 0.0295\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 34us/step - loss: 0.0279 - val_loss: 0.0328\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 26us/step - loss: 0.0281 - val_loss: 0.0372\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 27us/step - loss: 0.0282 - val_loss: 0.0333\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 26us/step - loss: 0.0284 - val_loss: 0.0341\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 28us/step - loss: 0.0282 - val_loss: 0.0323\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 34us/step - loss: 0.0285 - val_loss: 0.0301\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 38us/step - loss: 0.0283 - val_loss: 0.0308\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 39us/step - loss: 0.0286 - val_loss: 0.0302\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 43us/step - loss: 0.0283 - val_loss: 0.0300\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 37us/step - loss: 0.0284 - val_loss: 0.0302\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 33us/step - loss: 0.0284 - val_loss: 0.0299\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 38us/step - loss: 0.0288 - val_loss: 0.0297\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 38us/step - loss: 0.0286 - val_loss: 0.0333\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 39us/step - loss: 0.0288 - val_loss: 0.0311\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 42us/step - loss: 0.0287 - val_loss: 0.0309\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 20us/step - loss: 0.0286 - val_loss: 0.0291\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 25us/step - loss: 0.0287 - val_loss: 0.0313\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 30us/step - loss: 0.0285 - val_loss: 0.0299\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 26us/step - loss: 0.0285 - val_loss: 0.0286\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 39us/step - loss: 0.0284 - val_loss: 0.0287\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 37us/step - loss: 0.0288 - val_loss: 0.0292\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 37us/step - loss: 0.0284 - val_loss: 0.0313\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 42us/step - loss: 0.0285 - val_loss: 0.0284\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 43us/step - loss: 0.0287 - val_loss: 0.0288\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 37us/step - loss: 0.0288 - val_loss: 0.0287\n",
      "best reward is :  [0.4        0.3322293  0.32235294 0.29047273 0.28089478]\n",
      "reward is :  [0.19789474 0.1966879  0.3322293  0.03939808 0.25430464]\n",
      "regrets is :  [ 0.20210526  0.1355414  -0.00987636  0.25107464  0.02659014] \n",
      "\n",
      "best reward is :  [0.65939808 0.56848629 0.5316129  0.5025     0.46990654]\n",
      "reward is :  [0.35789474 0.41744    0.1722293  0.65939808 0.01430464]\n",
      "regrets is :  [ 0.30150335  0.15104629  0.3593836  -0.15689808  0.45560191] \n",
      "\n",
      "best reward is :  [0.4        0.39735467 0.36961487 0.36235294 0.30089478]\n",
      "reward is :  [0.19789474 0.19744    0.2522293  0.04736842 0.29430464]\n",
      "regrets is :  [0.20210526 0.19991467 0.11738557 0.31498452 0.00659014] \n",
      "\n",
      "best reward is :  [0.58521193 0.58       0.43744    0.39551807 0.37657321]\n",
      "reward is :  [0.58521193 0.43744    0.0122293  0.36736842 0.01430464]\n",
      "regrets is :  [0.         0.14256    0.4252107  0.02814965 0.36226857] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.0285 - val_loss: 0.0300\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.0285 - val_loss: 0.0294\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.0284 - val_loss: 0.0301\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.0285 - val_loss: 0.0301\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.0284 - val_loss: 0.0308\n",
      "best reward is :  [0.52235294 0.51713939 0.46089478 0.44947368 0.44      ]\n",
      "reward is :  [0.05189189 0.03810964 0.4122293  0.29430464 0.1825    ]\n",
      "regrets is :  [0.47046105 0.47902975 0.04866548 0.15516905 0.2575    ] \n",
      "\n",
      "End of the simulations, time elapsed: 457.508 seconds.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdeXzcdZ348dc7SXO1ue/7ao7maAtUwNVd8Vw8Vtz1Fg9WfuIBrgcqIC6nKCAgKAgWEDkERJQVWQQVdcETqG1pkzT3MZNkcp+TOZKZz++P7ySkbdJO0kyuvp+PRx7JfM/PVJz3fD/H+y3GGJRSSimAsNVugFJKqbVDg4JSSqlZGhSUUkrN0qCglFJqlgYFpZRSszQoKKWUmqVBQSml1CwNCmpFiEi7iHhFJPWI7ftExIhI4eq0bPUE/k3esojjK0XkZREZDvz8TkQq5+z/qogcFJFxEWkTka8ecX6hiPxBRCZF5NCx7i0iUSLyIxEZExGHiHx5zr5IEXk80H4jImct8q2rNUyDglpJbcCHZ16ISA0Qs3rNeZWIRKzl6wV0A+8DkoFU4Eng0bm3BT4OJAFnAxeJyIfm7H8E2AukAJcDj4tI2gL3ugooBQqANwJfE5Gz5+z/E/BRwHFib0mtNRoU1Ep6EOtDa8YngAfmHhD4hnqTiHSKSK+I3CUiMYF9SSLylIj0B74pPyUiuXPO/aOIXCsifw58W/7NkU8mc449S0TsInKJiDiA+wLb3xV4ehkRkb+IyPY555wqInsD1/6ZiPxURL65lOuJyINAPvArEZkQka8d7x/PGDNijGk3VhoCAXzA1jn7bzTG/MMYM22MaQB+CbwucL8y4FTgSmOMyxjzc+AA8N4Fbvdx4FpjzLAxph64GzgvcB+vMeZWY8yfAm1QG4gGBbWS/gbEi8g2EQkHPgg8dMQxNwBlwE6sD7wc4IrAvjCsD9sCrA9UF3D7Eed/BPhPIB2IBL5yjPZkYn3rLgAuEJFTgR8Bn8b6Nv1D4MlAoIoEngB+HDjnEeDfl3o9Y8zHgE7g34wxW4wxNwKIyCsi8pFjtBkRGQHcwPeBby1wjAD/DNQGNlUBrcaY8TmH7Q9sP/LcJCA7sP+Yx6qNR4OCWmkzTwtvBQ4BXTM7Ah9knwK+ZIwZCnyAfQv4EIAxZtAY83NjzGRg33XAG464/n3GmEZjjAt4DCu4LMSP9c3ZEzj+U8APjTF/N8b4jDH3Ax7gzMBPBPA9Y8yUMeYXwIsncL15GWO2G2MePkabMcYkAgnARVjdQfO5ileDKMAWYPSIY0aBuHnO3TJn//GOVRtMKPo9lTqWB4HngSKO6DoC0oBYYI8VHwCrmyQcQERige9i9ZcnBfbHiUi4MWamG2NuH/ckr37AzaffGOOe87oA+ISIfH7Otkisb80G6DKHZ5C0ncD1TogxxikidwH9IrLNGNM3s09ELsIKvP9sjPEENk8A8UdcJh4Y52gTc/a7j3Os2mD0SUGtKGNMB9aA8zuAXxyxewCrS6jKGJMY+Ekwxsx8sF8MlANnGGPigX8JbBeW5sgUwTbgujn3TjTGxBpjHgF6gByZE62AvBO43nzHL1YYVhDNmdkgIp8ELgXebIyxzzm2FigWkbnf9nfwavfSq2/CmGGs97vjeMeqjUeDgloN5wNvMsY45240xvixBjS/KyLpACKSIyL/GjgkDitojIhIMnDlMrfrbuAzInKGWDaLyDsDH6R/xRpUvUhEIkTkHOD0E7geQC9QHGzjROStInKKiISLSDxwCzAM1Af2n4vV3fZWY0zr3HONMY3APuBKEYkWkX8HtgM/X+B2DwDfCAzuV2B1hf14TluiRCQ68DIycM2lBme1hmhQUCvOGNNijHl5gd2XAM3A30RkDPgd1tMBwK1YU1gHsAatn1nmdr2M9eF3O9aHbTNzZtwA/4EV0EawpmM+hTVGsOjrBXwb64N3RES+AiAitYEP9/kkYg1wjwItWAPxZ8/psvom1oD2S4EZTROBLqYZHwJ2BdpyPfA+Y0x/4L7nisjcJ4ErA/foAP4P+I4xZu6/dwNWgM4Bng38XbDQv4VaP0SL7Ci1NCLyd+AuY8x9xz1YqXVCnxSUCpKIvEFEMgPdR5/A6n5Z1qcVpVabzj5SKnjlWNNct2B1rbzPGNOzuk1Sanlp95FSSqlZ2n2klFJq1rruPkpNTTWFhYWr3QyllFpX9uzZM2CMmTcZ4roOCoWFhbz88kIzG5VSSs1HRDoW2qfdR0oppWZpUFBKKTVLg4JSSqlZGhSUUkrN0qCglFJqlgYFpZRSszQoKKWUmhWyoBDIr/6iiOwPpAO+OrD9xyLSFihmvk9Edga2i4h8T0SaA3VqTw1V25RSar2anp6mtbWViYmJ4x+8BKFcvObBKqQyISKbgD+JyK8D+75qjHn8iOPfDpQGfs4A7gz8Vkqpk54xhs7OTtrb25nJWbdly7GqzS5NyIJCoJbtTCjbFPg5Vva9c4AHAuf9TUQSRSRLs1AqpU5mPp+PgYEBbDYbExMTxMTEUFJSQkpKSkjuF9IxhUDZwH1AH/BbY8zfA7uuC3QRfVdEogLbcji8ELqdObVn51zzAhF5WURe7u/vD2XzlVJq1RhjGBwc5C9/+Qv19fV4PB5KS0s5/fTTSU1NJVTVT0Oa+8gY4wN2ikgi8ISIVAOXAQ4gEtiNVX7xGuYvvn7Uk4UxZnfgPHbt2qV5v5VSG8r4+DgOh4PBwUHcbjfR0dGUl5eTkpJCeHh4yO+/IgnxjDEjIvJHrHqyNwU2e0TkPuArgdd2IG/OablA90q0TymlVtv4+Dg2m42+vj4AYmNjKSkpISsri4iIlctdGrI7iUgaMBUICDHAW4AbZsYJxHr2eQ9wMHDKk8BFIvIo1gDzqI4nKKU2uv7+fjo6OmZnE+Xm5pKbm0t0dPSqtCeU4ScLuF9EwrHGLh4zxjwlIr8PBAwB9gGfCRz/NPAOoBmYBP4zhG1TSqlV19nZSWtrK5GRkRQXF5ORkUFUVNTxTwyhUM4+egU4ZZ7tb1rgeANcGKr2KKXUWuHz+WhqasLhcJCYmEhNTc2KjBcEY10X2VFKqfXE7/djs9no7u7G4/FQUFBAYWFhyGYSLYUGBaWUCiGPx0NXVxeTk5OMjIwwPT1NXFwcFRUVJCUlrXbzjqJBQSmlQmBmBXJHRwd+v5/Y2FiSk5NJS0sL6TqDE6VBQSmlltn09DQHDhxgdHSUuLg4tm3bRmxs7Go3KygaFJRSahm53W5eeeUVXC4XJSUl5ObmrtmngvloUFBKqWUyPDxMbW0txhiqq6tDlp8olDQoKKXUCZqenqatrY2uri4iIyPZuXPnuukuOpIGBaWUOgFTU1Ps3buXyclJcnJyKCoqWtG0FMtt/bZcKaVW0cTEBD09PfT29uL3+9mxY8eanGK6WBoUlFJqEWammra1tQGQnp5OXl4ecXFxK9YGux1iYiAUQxYaFJRSKggul4vOzk4GBwfxer0kJSVRXl6+oonrBgfh29+G22+Hz3wGbr11+e+hQUEppY7BGENrays2m1UDLCkpicLCQrKyslZsqunEBHz3u3DTTdbfH/84fOlLobmXBgWllFqA1+ulq6sLm81GRkYG+fn5bN68ecXu7/HAD38I110HfX3wnvfAN78JVVWhu6cGBaWUOoLP56OjowObzYYxhoyMDCoqKlbsycDjgYcegmuvhY4OOOss+OUv4cwzQ39vDQpKKTXH9PQ0e/bsweVykZ6eTlZWFomJiSsSEFwuuOsuuOEG6O2FU0+F3bvhrW+FlVoUrUFBKaUCJiYmaGlpweVysW3bNjIyMlbkvn4/PPooXHop2Gzw5jfDgw/CW96ycsFghgYFpZTCKotZV1eHMYatW7euSECYnoaHH7ZmFB06BDt3wgMPWN1Fq0WDglLqpDcwMEBtbS2xsbHU1NQQExMT8ns++yxcfDHU1sL27fDTn8L73gdhYSG/9TGt8u2VUmp1jYyMUF9fT1xcHKeddlrIA8LevfCv/wpnnw1uNzz+OOzbBx/4wOoHBAhhUBCRaBF5UUT2i0itiFwd2F4kIn8XkSYR+amIRAa2RwVeNwf2F4aqbUopBTA0NMSBAweIiooKeZ3k1lY491xr8Pjll+GWW6CuDt773sWPG0xPT2OVtV9+oYxLHuBNxpgdwE7gbBE5E7gB+K4xphQYBs4PHH8+MGyM2Qp8N3CcUkqFhMPh4JVXXiE6OpqdO3cSGRkZkvv09cF//RdUVMATT8DXv24FiC99CZZyS5fLxZ49e+jo6Fj+xhLCMQVjhbGJwMtNgR8DvAn4SGD7/cBVwJ3AOYG/AR4HbhcRMaEKh0qpk9bQ0BANDQ0kJSVRXV0dkieEiQnraeA737Gmmv6//wdXXAHZ2Uu7ntvtxm6343A4EBGSk5OXt8EBIR1oFpFwYA+wFbgDaAFGjDHTgUPsQE7g7xzABmCMmRaRUSAFGDjimhcAFwDk5+eHsvlKqQ3G7/fT0tJCV1cXmzdvpqqqatkDgtcLd98N11xjPSW8973WiuTy8qVdz+Vy0drayuDgIMYY4uPjKS8vD1m9hpAGBWOMD9gpIonAE8C2+Q4L/J6vV+2opwRjzG5gN8CuXbv0KUIpFRSPx0NtbS1jY2OkpqZSVla2rHUP/H742c/g8suhpQXe8IYTW4Xs9/vp6Oigo6OD8PBwMjIyKCgoCHkCvhWZkmqMGRGRPwJnAokiEhF4WsgFugOH2YE8wC4iEUACMLQS7VNKbVx+v3+2KpqIUFVVRVpa2rLe48UX4cILrQHkmhp4+mlrdtFiB5B9Ph/9/f0MDQ0xMjKC1+slIyOD4uJioqKilrXNCwlZUBCRNGAqEBBigLdgDR7/AXgf8CjwCeCXgVOeDLz+a2D/73U8QSl1IjweDy0tLfT19ZGSkkJJScmydrt0d8NVV8E990BmJtx/vzXDaCk9UqOjozQ0NDA5OUl4eDiJiYlkZGSQlpa2YjmXILRPClnA/YFxhTDgMWPMUyJSBzwqIt8E9gL3Bo6/F3hQRJqxnhA+FMK2KaU2KGPMbDDo7+8HoKCggKKiomW7x/g4XH+9lc56etqaXXT11ZCQsPhrud1uOjo66OnpISIigqqqKlJTU1c0EMwVytlHrwCnzLO9FTh9nu1u4P2hao9SauMyxjAyMsLIyAi9vb243W5EhNzcXFJTU0lMTFym+8BPfgJf+xr09MCHP2ylsi4uXvy1fD4f7e3t2O12AHJycigoKAjZ1NhgaZoLpdS65vf7aWhooLe3F4C4uDiys7NJS0tb1tXJf/sbfPnL8Ne/wmteY605OOOMpV1rZGSEQ4cO4Xa7ZweQQzWbaLE0KCil1qXp6WkcDgc2mw2Px0NhYSG5ubnLOqMIoL0dLrvMymKamQn33gvnnbe0lBQzg942m43IyEhqampICUWh5ROgQUEptW74/X4GBgbo6upidHQUgISEBCoqKkhKSlrWe42OWtlLb73VmkX03/9tdRtt2bL4a01PT8+OcUxPT5OVlcXWrVtDmlZjqTQoKKXWhbGxMerr63G5XERHR1NQUEBycjIJSxndPYbpaWvx2ZVXQn+/VQ/5uusgN3fx13I6ndjtdoaGhvB4PKSkpJCdnU1ycvKqDSQfjwYFpdSa5ff7GRkZoaenh4GBASIjI6msrCQ1NZWwZU4pagz8+tfwla9Afb21+Ozmm+G00xZ/renpaXp7e2lubgYgOTmZ8vLykKWmWE4aFJRSa9Lw8DCNjY24XC5EhJycHAoLC5d9zABg/34rGPzud1BaCv/zP/Dudy9+8Znf76e7u5u2tjZ8Ph+JiYlUVFSEfBXyctKgoJRaU4wxtLW10dnZSUxMDJWVlSQnJ4ckGNjt1ljB/fdDUhLcdht85jNLy146d/HZ5s2bKSwsXNX1BkulQUEptWYMDQ3R2trKxMQE2dnZbN26ddm7iQAmJ63spTfcAD6f9ZTw9a/DUpYzTE9P09raSnd3N1FRUVRXV5OSkrLugsEMDQpKqVU1NTVFW1sbAwMDeL1eoqOjKS8vJzMzc9k/WP1+qwbyN74BXV1WtbMbboDCwsVfyxhDT08PHR0deDwecnNzKSoqWpMzihZDg4JSasX5fD7Gx8dxuVzYbDZcLhfJyckkJSWRnZ0dkqeDPXvgc5+zktedcQY88gj88z8v7VojIyM0NjbOdhVVVVURHx+/vA1eJRoUlFIrxhhDR0cHdrud6WmrrEpERAQ7duxYtlQURxoasp4M7roL0tPhwQetpHVLeQiZ21UUHR1NRUUFGRkZ67araD4aFJRSITc9PU1fXx+9vb2Mjo6SlJREbm4usbGxREVFheTJwOOxBpAvv9wKDCeStA5gcHCQxsbGDdVVNB8NCkqpkHI6ndTW1jI5OUlERARlZWVkL7UmZRD8fnj4YSsYdHbC614Hd9wBO3Ys/lrGGIaGhmhra2NiYoLY2FhOPfXUDdNVNB8NCkqpkBkZGaG2thaAmpoakpKSQvJUMOP3v4evfhX+8Q849VTYvRve9ralrTcYGRnBZrMxPDxMTEwMpaWlZGVlhbT9a4EGBaXUsjPGYLfbaW1tJSYmhurq6pBmAa2rs/IS/e//Qn4+PPSQldZ6KZ/fExMTHDp0iImJCTZt2sTWrVtDNvi9FmlQUEotK2MMTU1NdHd3k5qaSkVFRUgWngE4HFaOonvusRLV3XCDNXaw1AXEAwMD1NfXA1BWVkZGRsaGHDc4Fg0KSqll4/P5qKurY3BwkPz8fIqKikIyM8fphJtushageTxw0UXWyuTU1MVfa6Ywz0zSus2bN7N9+/YVq4m81mhQUEqdsJnKZ62trYyPj1NaWkpOTs6y38fng/vugyuusCqfvfe9Vnrr0tLFXsdHf38//f39DA0NAVbSuoKCAjIzM0+arqL5aFBQSp2QyclJGhsbGRkZISwsjOrqalKX8pX9GIyBZ56xxg0OHoQzz4THH4d/+qfFXcfv98+uM/D7/URHR5OVlUVxcXHIurjWm5D9K4hIHvAAkAn4gd3GmNtE5CrgU0B/4NCvG2OeDpxzGXA+4AP+yxjzbKjap5Q6cb29vTQ2NmKMoaysjLS0NDZt2rSs99i3z8pN9NxzUFICP/uZ9YSw2F6pyclJ6uvrGR8fJz09nczMTJKSkjbUwrPlEMrQOA1cbIz5h4jEAXtE5LeBfd81xtw092ARqQQ+BFQB2cDvRKTMGOMLYRuVUkvg9/tpaWmhq6uLhIQEKisrl70P3mazViI/+KCVwfTWW+Gzn118BlOXy0VdXR3j4+NERERQWVlJenr6srZ1IwlZUDDG9AA9gb/HRaQeOFYn4znAo8YYD9AmIs3A6cBfQ9VGpdTiud1uamtrGR8fJzc3l+Li4mXtgx8bg+uvh+9+1+o2OpEMpi6Xi71792KMmR0viImJWba2bkQr0okmIoXAKcDfgdcBF4nIx4GXsZ4mhrECxt/mnGZnniAiIhcAFwDk5+eHtN1KqcMNDg5y6NAh/H4/VVVVpKWlLdu1p6asxWZXX22VwTz3XKsMZkHB0q43OjpKXV0dxhh27tzJ5s2bl62tG1nIh9hFZAvwc+CLxpgx4E6gBNiJ9SRx88yh85xujtpgzG5jzC5jzK7l/A9SKbWwmcVoBw4cIDIyktNOO23ZAoIx8MQTUF1tTS2trISXXrIWoC0lIMwk3Zt5QqipqdGAsAghfVIQkU1YAeEnxphfABhjeufsvxt4KvDSDuTNOT0X6A5l+5RSx+f3+2lqaqKnp4eUlBQqKyuXbUFXe7s1TvDMM7BtG/zqV/DOdy4tLcXw8DB9fX2Mjo7idrtJS0ujrKxs2Qe+N7pQzj4S4F6g3hhzy5ztWYHxBoB/Bw4G/n4SeFhEbsEaaC4FXgxV+5RSx+f1eqmtrWV0dJSCggIKCwuXZbbO5KS1+vjGG61UFLfdZtU6WOysUGMMDoeD9vZ2PB4PIkJKSgp5eXlkZ2frzKIlCOWTwuuAjwEHRGRfYNvXgQ+LyE6srqF24NMAxphaEXkMqMOauXShzjxSavX09/fT3NzM1NQU27ZtIyMj44Sv6ffDY49Z6w1sNis/0Y03Qm7u4q/l9XppbW3F4XAQFxdHaWkpiYmJut7gBIVy9tGfmH+c4OljnHMdcF2o2qSUOj5jDC0tLdjtdqKjoznllFOIi4s74ev+8Y9WMHjpJdi5E37yk8VXPjPG0NvbS1dXFxMTExhjQppO42SkIVUpNcvv91NfX09/fz85OTmUlJSc8HTTjg740pesweTcXPjxj+GjH4XFDkt4vV7q6uoYGRlhy5YtZGZmkp2dvSwBS71Kg4JSCrA+dF955RUmJiYoKSkhNzf3hL59u91W0rpvfct6/c1vwpe/DItdJjA1NUVfXx/t7e34fL6TLpX1StOgoJSip6eHlpYW/H7/sqz4/fWv4fOfh5YWKyXFLbdYdQ4Ww+l04nA46Orqwu/3ExcXR3l5OVu2bDmhtqlj06Cg1EnM4/HQ0dFBd3c3iYmJlJaWntCc/gMH4LLLrGI3ZWXw7LNW5bPFGBkZoa2tjdHRUQDi4uIoLi4mMTFRxw1WgAYFpU5CPp+P5uZmHA4HwAmPH3R0WPUMHnoIEhKs6aZf+AIEmw5pJvW2zWZjaGiIqKgoioqKSElJ0SeDFaZBQamTjNPppL6+nomJCTIzMykoKFhyPqDxcStP0c03WwvOvvpVuPRSK4FdMKampmhsbGR0dBSv10tkZCRFRUXk5OTo1NJVov/qSp0k/H4/7e3t2Gw2wsPDT6jugd9vPRVccolVEvPcc61iN3l5xz93xvT09OzAdnJyMunp6aSmpp505S/XGg0KSm1wPp+Prq4uHA4Hk5OTZGZmUlJSsuT0D3/5C3zxi9Z6g9NPh//5HzjjjODPd7lcOBwOent78Xg8VFVVLXtRHrV0GhSU2qCMMQwODtLa2srk5CSxsbHU1NSQkpKypOv19lpPBvffDzk51nqDj33MSlNxPF6vF4fDwfj4OIODg/j9/tlayEnB9jWpFaFBQakNyOv10tDQwODgIJs2bWL79u0kJycv6VrT03DnndZA8uSkNWZw+eUQ7Pjv2NgYBw8exOv1smnTJtLS0igsLNS6BmuUBgWlNpDp6WmampoYGBjA7/dTUlJCTk7OkmcV/fGPVlfR/v3w1rfC978P5eXBnTs2NkZTUxPj4+NERkaya9cunUm0DmhQUGoDmMkW2tHRgcfjITMzk9zc3CWvOWhttWYS/eIX1qKzYOsi+3w+BgcHGR0dpaenh8jISLZu3UpmZqbOJlon9H8lpdYxl8uFzWZjYGAAr9dLXFwcFRUVJC6ldiVWaoprr7XSU2zaFFxqCr/fT29vL0NDQwwNDeHz+RAREhIS2LZt27LXblahpUFBqXVqZGSEAwcO4Pf7SUlJIS0tjfT09CWv+n3uObjwQmhosAaQr78esrMXPt4Yg9vt5sCBA0xOThIdHU1aWhqZmZnExcXp1NJ1SoOCUuuMy+Wis7OT3t5eoqOjqaqqOqHUFD09cPHF8MgjUFISXGqKsbEx6urqcLvds2seUlJSNA3FBqBBQal1ZHR0lIMHD+Lz+cjIyKCwsHDJ3TM+nzWr6PLLrW6jK6+0ZhZFRy98jjGG9vZ2Ojo6iIqKoqSkhJSUFGJjY5f4jtRao0FBqXVicHCQ2tpaoqKiOPXUU09oSudLL1m1kffssWYV3XEHlJYe+xyXy0VjYyPDw8NkZGRQUlJCZGTkktug1iYNCkqtcX6/n56eHpqbm9myZQvbt29f8mrkkRHryeDOOyEzEx59FD7wgflnFbndbvr6+hgbG2NychKXy4WIUF5eTlZW1gm+K7VWaVBQag2bGch1Op3Ex8dTU1OzpIBgjFX+8uKLYWDAqnVwzTVWRtP5TExMsH//fqampoiJiWHz5s2kpqaSk5Ojs4k2uJAFBRHJAx4AMgE/sNsYc5uIJAM/BQqBduADxphhsUaobgPeAUwC5xlj/hGq9im1lvn9fvr7+2ltbcXn853QQG5trRUE/vAHK1fRr38Np546/7ETExPY7XYcDgdRUVGcfvrpOl5wkgnlk8I0cLEx5h8iEgfsEZHfAucBzxljrheRS4FLgUuAtwOlgZ8zgDsDv5U6aRhj6OzsxG63z35Lr66uXlId4qYmuOoqa1ZRQoLVZfSpT81fG9kYQ0dHBx0dHQBkZmZSVFSkTwUnoZAFBWNMD9AT+HtcROqBHOAc4KzAYfcDf8QKCucADxhjDPA3EUkUkazAdZTa8MbGxmhoaMDpdJKcnExmZiapqamLTlExMABXXw133QWRkfC1r8FXvgILJSKdmpri0KFDDA4Okp6eTmlp6ZLHLNT6F1RQEJEvGGNuO962Y5xfCJwC/B3ImPmgN8b0iMhMMdgcwDbnNHtg22FBQUQuAC4AyF9s0Vel1iCPx0NnZyfd3d1ERkYuuUay3w/33mtNKx0dtZ4KrroKMjIWPsftdrN//37cbjdbt24lJydH1xqc5IL9CvKJebadF8yJIrIF+DnwRWPM2LEOnWebOWqDMbuNMbuMMbvS0tKCaYJSa5Lf76evr489e/bQ1dVFSkoKp5122pICwv798PrXwwUXQFUV7NtndRcdKyAMDw+zd+9epqamOOWUU8jNzdWAoI79pCAiHwY+AhSJyJNzdsUBg8e7uIhswgoIPzHG/CKwuXemW0hEsoC+wHY7MLduUy7QHdzbUGp9cblcHDx4EKfTSWxsLNu3b19SBtHJSbjiCrj1VqsE5o9/DB//+LET1xljsNvttLS0EBMTQ01NjWYvVbOO1330F6zum1Tg5jnbx4FXjnViYDbRvUC9MeaWObuexHryuD7w+5dztl8kIo9iDTCP6niC2kh8Ph/Dw8MMDAzQ19dHWFgYlZWVSxo3AGsW0Re+YA0oX3CBVQ7zeCUTPB7PbGrttLQ0KioqNEeROswxg4IxpgPoAF4rIgVAqTHmdyISA8RgBYeFvA74GHBARPYFtn0dKxg8JiLnA53A+wP7nsaajtqMNSX1P5f2lpRaezweD3v37sXtdhMREUFGRgYFBQVEHyunxAIaGqzMpU8/ba1C/t3v4M1vPv55TqeTgwcP4iJxsLYAACAASURBVHa7KSoqIj8/X7uL1FGCHWj+FNbgbjJQgtW1cxew4H+Kxpg/Mf84AfOdF5h1dGEw7VFqPfH7/Rw8eJCpqSmqq6tJTk5e0pPByIiV1vp734PYWCu99ec/b80wOp6hoSEOHjyIiLBz504SFlq1pk56wU5JvRA4HWv2EMaYpjmzhpRSC3A6nTQ2NjI+Pk51dfWSCtT7fPCjH1npKQYG4PzzrToHxxpEnjE5OYndbqe7u3u2JrKuPVDHEmxQ8BhjvDOPmiISwTwzg5RSFqfTSVtbGwMDA2zatIny8vIlBYTnn7fGDfbts2YXPfPMwquR5/L5fLS0tNDd3Y2IkJGRwdatW3X9gTquYIPC/4nI14EYEXkr8DngV6FrllLrkzGG1tZWurq6CAsLIzc3l7y8vEV/O+/uthad/eQnkJd37MR1R5qcnKS2than00lubi75+fmazVQFLdigcClwPnAA+DTWoPA9oWqUUuuRMYampia6u7tJSkqivLx80QPJTid861twyy3WYrT//m9rMVow6Yempqaw2+10dnYSERFBTU0NKSkpS3w36mR13KAgIuHA/caYjwJ3h75JSq0/4+Pj2Gw2+vr6yMvLo6SkZFHnGwOPP27NKrLb4dxzrSymxcXHP9fj8dDS0sLg4CA+n4/k5GTKy8t17EAtyXGDgjHGJyJpIhJpjPGuRKOUWi+MMXR1ddHS0oIxhtzcXIqD+SSfY24W0x07rAR2r3/98c/z+/3Y7Xba29sxxpCRkUFOTg5btmzRqaZqyYLtPmoH/hxY1eyc2XjEojSlTirj4+M0NzczOjpKSkoKFRUVixrIHR21chN9//sQH29VP/v0p+fPYnokj8fD/v37mZycJDk5mZKSkhOq06zUjGCDQnfgJwwrxYVSJ7X29nba29sJCwujpKRkUXmD/H548EFrILm/30pcd911C2cxPfxcPzabDbvdjt/vp7KykrS0NH0yUMsmqKBgjLk61A1Raj0YHh7GZrMxNDREWloaxcXFi6qVvHcvXHgh/PWvcOaZ1qrk0047/nl+vx+Hw4HNZsPlcpGYmEhJScmS6iwodSzBrmj+FUevSxgFXgZ+aIxxL3fDlFpL/H4/TU1N9PT0ICJkZ2dTWloa9Df04WH4xjesGgcpKdZitE98Ao63sHlqaore3l46OjqYmppi8+bNOqtIhVSw3UetQBrwSOD1B4FeoAxrRtLHlr9pSq0NTqeThoYGxsbGyMnJoaioiIiI4P6v4/fD/fdbXUVDQ9ZTwjXXQGLi8c/t7++nsbGRqakpEhISyM3NJTU1VbuKVEgFGxROMcb8y5zXvxKR540x/yIitaFomFKrze/309HRMTvvf9u2bWQEk1si4O9/h4svhj//Gf7pn+AHP7BmFx3PxMQEHR0d9Pf3ExcXR1VVFQkJCRoM1IoINiikiUi+MaYTQETysdJpA+g0VbWhGGNwOBy0t7fj8XjIyMigpKQk6FXB3d1wySXw0EOQnh58V9HY2Bh2u52+vj5EhIKCAgoKCpaUPE+ppQo2KFwM/ElEWrAynxYBnxORzVh1lpXaEKanp6mvr2dwcJDo6Gi2b99O8vGKFAR4vVaxm2uugakpK4HdpZfC8erXGGNoa2ujs7NzdryisLBQU1OoVRHs7KOnRaQUqMAKCofmDC7fGqrGKbVSfD4fTU1NOBwOgEXXK37hBWuNQX09vPvdVpqKYBY1u91uamtrGR8fJzMzk5KSEk1ap1ZVsLOPYoEvAwXGmE+JSKmIlBtjngpt85QKLZfLxfDwMA6HY3YgOT09Peh6A7291qyie+6BwkL41a/gXe86/nnGGHp7e2lubsYYQ0VFBZmZmSf2ZpRaBsF2H90H7AFeG3htB34GaFBQ65bD4aChoQFjDOHh4ZSVlZGdnR3UuX4//PCH1tiBy2XlLLr66uC6isbGxmhvb2d4eJiEhATKy8uJDSbjnVIrINigUGKM+aCIfBjAGOMSnQqh1qm5XUXx8fGUlZURGxsb9IBuQ4O1CvmFF6wymD/4AZSVHfucmcFrm83G5OQk4eHhlJaWkp2drbOK1JoSbFDwBuoyGwARKQE8IWuVUiHS3d1Ne3s7Xq+XnJwciouLgy5cP1MO8/vfh82brVlF55137BoHPp+P7u5uHA4HTqeTLVu2UF5eTlpaWtBrHZRaScGkzhaseszPAHki8hPgdcB5xznvR8C7gD5jTHVg21XAp4D+wGFfN8Y8Hdh3GVbNBh/wX8aYZ5fwfpSa19wVyQkJCVRWVpIYzAoyrLTWDz1krTmYKYd57bVwrCEAYwz9/f20t7czOTnJ5s2bNU+RWheCSZ1tROQLwNuAM7FmH33BGDNwnFN/DNwOPHDE9u8aY26au0FEKoEPAVVANvA7ESkzxviCehdKHcPcgJCenk5FRUXQXUWtrdYq5GeesXIVPfssnHLKsc+ZO6MoNjZ2UdNalVptwT6//g0oNsb8b7AXNsY8LyKFQR5+DvCoMcYDtIlIM3A68Ndg76fUfHw+H7W1tQwNDZGbm8vWrVuDOs/jgRtvtKqgRUTAbbdZwWGhniZjDOPj4wwMDNDT04Pf76esrIysrCx9MlDrSrBB4Y3Ap0WkA6uegmA9RGxfwj0vEpGPYyXTu9gYMwzkYAWeGfbAtqOIyAXABQD5+flLuL06GcwM7La1teH1emc/oIPx3HPwuc9BY6NVF/mWWyBn3v8arfuMjIzQ1NTE5OQkIkJCQgJbt25ly/GmIim1BgUbFN6+TPe7E7gWa8D6WuBm4JNYQeZIR2ZltTYasxvYDbBr1655j1EnN7fbzYEDB3A6ncTExLBjxw6SkpKOe57DYU0tfeQR2LrV6ip629sWPt4YQ0NDAw6Hg6ioKCoqKkhJSdHFZ2pdC3ZFc8dy3MwY0zvzt4jczavrHOxA3pxDc7GK+igVNGMMg4ODNDU14fP5qKioICMj47jdNz6fldL68sutNQdXXmmlp4iOnv/46elp+vr66O7uZmJigry8PAoKCnQ2kdoQVvS/YhHJMsb0BF7+O3Aw8PeTwMMicgvWQHMp8OJKtk2tb319fbS1teFyudi0aRM7duwIqgDNyy/DZz9r/X7rW62SmKWlCx8/PDxMQ0MDbreb2NhYysvLyczM1HEDtWGELCiIyCPAWUCqiNiBK4GzRGQnVtdQO/BpAGNMrYg8BtQB08CFOvNIBctut9Pc3ExkZCRVVVUkJycfd+3B6Kj1ZPCDH0BGhtVl9MEPLrzmwOl00trayuDgIDExMezcuVPTWasNSYxZv93yu3btMi+//PJqN0OtEmMM7e3tdHR0kJqaSlVV1XE/pI2BRx+1xg76+qwZRddeCwulOhoYGMButzMyMkJ4eDgFBQXk5uZqOmu1ronIHmPMrvn2aSeoWneMMQwMDNDd3c3w8DCZmZlBlcZsbLRmFT33HLzmNfDUUwvXRzbG0NXVRXNzM9HR0RQVFZGVlaXprNWGp0FBrSuTk5O0tbXR399PREREUCmuXS749rfhhhsgJsYaN/j0pxdeczA3N1JqaiqVlZX6ZKBOGhoU1Lrg9/tpbm6mt7cXYwxFRUXk5+cf9+ngmWfgoougpQXOPRduumnh9BQzaw5aWlqYmJigsLCQgoICHTdQJxUNCmrNm5qaoq6ujuHhYTIyMigqKiJ6ofmiAV1d8KUvwc9+ZmUw/d3vrIymCzHG0NjYSE9PD5s2baK6uprU1NSFT1Bqg9KgoNY0t9vN3r178Xg8QdU7mJ6G22+HK66wSmJeey189asQFbXwOR6Ph0OHDjE8PEx+fj4FBQVBZ05VaqPRoKDWJL/fT1dXFzabDb/fH1RSueeftwaSa2vh7W+3gkNx8cLHG2Po7u6mtbUVv99PeXl50KkwlNqoNCioNWdiYoL6+nqcTieJiYnHzSPU3289Ddx/PxQUwBNPwDnnLLzmwOVy0dvbS19fH5OTkyQlJVFaWqrVz5RCg4JaQzweD21tbTgcjqD69f1+uPtuuOwyGB+3UlN84xtWAZwjzZTBnFl3YIwhPj5eaxwodQQNCmpNGBkZ4eDBg/h8PnJzcykoKDhmYrl9++Azn4G//x3e8AZrZXJl5dHHzQSDrq4u+vr6AEhJSWHr1q3ExMSE6u0otW5pUFCrzuFw0NDQQExMDNXV1cfsxhkbswaRv/99SEmBBx6Aj3706K4in8+H3W6nu7sbj8eDiFBQUEBOTo4uQFPqGDQoqFUzN01FYmIi1dXVC2YaNcaaXvqlL0FPj7X47FvfgiMzYvv9fnp6emhvb2dqaorExEQKCwtJSUnRYKBUEDQoqFXh9Xqpq6tjZGSErKwsSktLF1w13Nxs5Sj6zW/g1FOtgeTTTz/8GL/fT39/P62trXg8HhITE8nLyyM5OVnHC5RaBA0KasX19vbS2trK1NTUMVNPu91w/fXWT1QUfO971pTTI5cQzFQ+czqdbNmyha1bt5KamqrBQKkl0KCgVpTNZqOlpYVNmzaxc+dO4uPj5z3uN7+xng6am+HDH4abb4YjlxDMrGVobW0lPDycbdu2kZ6ersFAqROgQUGtCJ/PR2NjI729vaSlpVFZWTnvh3dXl5XW+rHHrPQUv/0tvOUthx/j8Xjo6OhgYGAAr9dLcnIy27Zt0zKYSi0DDQoqpIwx9Pf309LSgsfjIT8/n8LCwqMCwtz0FF4vXHMNfO1rh6enGBkZob+/H4fDgc/nIykpiW3btgVVf1kpFRwNCiokjDEMDQ3R2dnJ6OgosbGx1NTUkJKSctSxf/ubVRJz3z44+2wrOJSUvLrf5/PR0tJCd3c3IkJycrKuM1AqRDQoqGU3PDxMU1MTk5OTREZGUlZWRlZW1lFPB0ND1mrku++G7Gx4/HH4j/94dc3BTKGbtra22UVthYWFC05bVUqdOP1/l1o2Pp+Pjo4OOjs7iY6Opry8nIyMjKOmmhpj5Sn66ldheNhae3DVVRAX9+oxY2NjtLW1MTw8THJyMoWFhQsOSiullk/IgoKI/Ah4F9BnjKkObEsGfgoUAu3AB4wxw2J9hbwNeAcwCZxnjPlHqNqmlt/Y2BgNDQ04nc7Z8pjzpZ+urbW6il54AV77WrjrLti+/dX9Pp+P5uZmenp6CA8PD6qymlJq+YSyxuCPgbOP2HYp8JwxphR4LvAa4O1AaeDnAuDOELZLLSNjDJ2dnezbtw+Px0NNTQ0VFRVHBQSnEy65BHbutALDPffAn/50eEBwOp28+OKL9PT0kJOTw2tf+1pyc3M1ICi1gkL2pGCMeV5ECo/YfA5wVuDv+4E/ApcEtj9gjDHA30QkUUSyjDE9oWqfOnETExM0NTUxOjpKSkoK5eXlR6WS8PngwQetWUU2G3zyk1at5LnJT10uF93d3XR3dxMeHs7OnTtJTExc4XejlIKVH1PImPmgN8b0iEh6YHsOYJtznD2w7aigICIXYD1NkJ+fH9rWqgX19/dTV1dHWFgYFRUVZGRkHPWN/sUXrUyme/fCa14DDz8Mr3/9q/snJiaw2+04HA4AEhIS2LZt23FLbSqlQmetDDTP1z9g5jvQGLMb2A2wa9eueY9RoTUwMEBdXR1xcXFUVlYe9SE+PGzNKtq921qF/Mgj8MEPvjqryOl00t7eTn9/P2FhYeTm5pKTk6NTTJVaA1Y6KPTOdAuJSBbQF9huB/LmHJcLdK9w21QQuru7aWpqYsuWLWzfvv2o6aH/+79w/vlWNbQvfAGuvhpmJg1NTk5is9lmB5FzcnIoLCzUlchKrSErHRSeBD4BXB/4/cs52y8SkUeBM4BRHU9YW6anp2lsbKSvr4/4+HhqamoOCwh2uzWQ/PDDUFMDv/41nHKKtc/lctHW1kZfXx8iElQRHaXU6gjllNRHsAaVU0XEDlyJFQweE5HzgU7g/YHDn8aajtqMNSX1P0PVLrV4Xq+XV155BafTSV5eHkVFRbNrDzwe+M534NvftgaVv/EN6ycqyppearPZ6OjomA0GeXl5RM3NXaGUWlNCOfvowwvsevM8xxrgwlC1RS2eMYbu7m76+/sZHR1FRKipqSE5OXn2mOeft9Yc1NXB+94HN94IRUXWPpfLxYEDB5icnCQtLY3S0lItcqPUOrBWBprVGuH3+xkcHKSzs5Px8XFiYmJIS0ujoKCAzZs3AzAwAF/5irUqOS8Pnn4a3v5263xjDDabjc7OTgB27NihCeuUWkc0KKhZExMT1NfX43Q6CQ8Pp7KykrS0tNmppsZYNZEvvhhGR+HrX7e6imYmDbndbhoaGhgeHiYuLo5t27Yds96yUmrt0aCgAOjq6qK5uZlNmzZRVVVFcnLyYauSm5qsNQe//72VnmL3bqiufvX80dFRDhw4gDGG0tJSsrOzdSWyUuuQBoWT3MjICHa7nYGBAVJSUqioqDhsVpDXa40VfPObEB0Nd94JF1wAYWFWV1NPTw92ux2Xy0V0dDQ1NTWz3UxKqfVHg8JJamRkhPb2dkZGRhARMjMzKSsrOyyj6R/+YJXErK+H978fbrvt1ZKYbreb2tpaxsfH2bx5M/n5+WRnZ+tqZKXWOQ0KJxmv10t3dzft7e1ERkZSXFxMVlbWYU8HTU3WmoMnnrBmEz31FLzzna9eY3BwkPr6egCqqqpITU3VriKlNggNCicJn89HfX09AwMDACQlJVFdXX3YuMHEhJWs7sYbITISrr3WGlSeGUienJykvb2dvr4+tmzZQlVVlaamUGqD0aCwwfn9fmw2G93d3Xg8HrKzs8nIyCA+Pv6wWUUPP2wVvenpgXPPhZtugsxMAvutCmgtLS0YY8jJyaG4uHjeeglKqfVNg8IGNj09TW1tLcPDwyQkJFBRUXHUmoEXX7TGDV5+2cpk+vOfW7OLwAooQ0NDtLS04HK5NIupUicBDQobkN/vp7+/n46ODlwuF+Xl5WRmZh7W7z88bK0z+OEPrSeC++6Dj3/cmlUE1kDygQMHcDqdREdHL5geWym1sWhQ2GBGRkY4dOgQbrebiIiIo1JTGAMPPWStSB4YODqTKVipsRsbG/H7/VRUVJCWlqZdRUqdJDQobBA+n4+uri5aW1uJjIyksrKS1NTUw6aY7tkDX/yiVQbzzDPh2Wet8pgz/H4/7e3tdHZ2smXLFioqKtiyZcsqvBul1GrRoLDOGWOw2+20t7fj8/lIS0s7qkbywABcfjncfTekpVm/P/nJV7uK/H4/DoeDzs5O3G43WVlZlJaWHhZQlFInBw0K65jf76epqYmenh4SExPJzc0lJSVltt/f57MCwOWXW7mKvvhFuPJKSEggsN9Hd3c3NpsNr9dLXFwcZWVlh3U3KaVOLhoU1qmpqSn27duH0+kkPz+foqKiwwaB//EP+NSnrN9nnQW33w5VVa+ePzw8TH19PV6vl6SkJLZt20ZiYqIOJCt1ktOgsM643W66urpwOBxMTU1RXl5O1kzuCcDphGuugZtvtrqKjqyPPDU1RXNzM729vWzevJmqqioSZh4dlFInPQ0K68jo6CgHDx5kenqauLg4qqurZz/QjYFf/tKaTdTZadVJ/s53YGZZwvj4OD09PfT39+Pz+cjLyyM/P19LYiqlDqNBYZ3o7++nvr6eqKgoTjnllMPqFLS0wOc/b9VFrq6GF16A17/e2ud0OmlsbGR0dJSwsDBSUlLIz88nLi5uld6JUmot06Cwxhlj6OzspK2tjbi4OLZv3z777d7rtZ4Grr3WylV0yy1w0UWwaZM1iGy322lrayMsLIzi4mKys7OJiND/yZVSC1uVTwgRaQfGAR8wbYzZJSLJwE+BQqAd+IAxZng12rdW+Hw+mpub6enpIT09nfLy8tmpps8/bxW9mUlrfeutkJ1tpbbo6Oiiq6sLr9dLSkoKJSUlWgFNKRWU1fza+EZjzMCc15cCzxljrheRSwOvL1mdpq0+r9fLwYMHGRsbIycnh61btyIiOBxW4rqHHoKCglfTWhtjcDh6aW1tnZ1RVFlZSWJi4mq/FaXUOrKW+hLOAc4K/H0/8EdO0qAwMTHBwYMH8Xq9VFVVkZaWxvQ03HEHXHEFuN1WbeTLLoOYGMPIyCgdHR0MDw8THx9PdXU18XPzViilVJBWKygY4DciYoAfGmN2AxnGmB4AY0yPiKTPd6KIXABcAJCfn79S7V0Rxhh6enpoamoiIiKCnTt3Eh8fzwsvWJlMDxyAs8+G730PioqmGRoaornZwdDQEJs2bdLayEqpE7ZaQeF1xpjuwAf/b0XkULAnBgLIboBdu3aZUDVwJfl8vtnymOPj4yQmJlJZWcnoaCTnnQf33w/5+VYltHe8YwqHo4e//KUdv99PZGQkRUVF5ObmatI6pdQJW5WgYIzpDvzuE5EngNOBXhHJCjwlZAF9q9G2lTY6OkptbS1er5fIyMhAVtIM7rtP+NrXrGpol10Gl19ucLkGefnlRrxeL8nJyeTn55OQkKBPBkqpZbPiQUFENgNhxpjxwN9vA64BngQ+AVwf+P3LlW7bSjLG0NLSgt1uJyoqiqqqKpKTkzl0KJz3vQ/+/Gf4l3+BO++E7OwR6uqacDqdxMTEcOqpp+qYgVIqJFbjSSEDeCLw7TYCeNgY84yIvAQ8JiLnA53A+1ehbSvC5/NRV1fH4OAgOTk5FBUVMTUVwRVXWPWR4+PhRz+a5h3vGMLh6GHfvmGioqKoqKggPT1ds5cqpUJmxYOCMaYV2DHP9kHgzSvdnpU2MTFBXV0dk5OTlJWVkZ2dzW9+A5/9LLS2wic+AZdc0svgYBP19dOzYwY5OTm68EwpFXL6KbNCZtJUt7W1ER4ezvbt25maSubcc+Hhh6GsDH77Wy+5ua04HA7i4+PJy8sjOTlZB5CVUitGg8IKmJ6eZv/+/YyPjwcGiMu5444obrgBPB6rxsFFF03Q3HwQh8M9bypspZRaCRoUQmx4eJiGhgY8Hg/btlXywgtp/Nu/CZ2d8J73wDXXuElJGaKurnl2bYKuQlZKrRYNCiEydyFaZGQkMTE7+MhHEvn972H7dsM990xSUtKLzWZjcNDMrkSOjIxc7aYrpU5iGhRCwOPx0NzcTH9/P+HhW3j00Z3ccUcESUlT3HrrAGecYcPtnqSzE9LT08nNzSUuLk67i5RSq06DwjKamJigra2NwcFBjIG6ugKuuqqQwUHhs58d5T3vOcimTVOEhcVSUlJCWloa0dHRq91spZSapUFhmfT19XHo0CFEBKczi29/O4c//3kLr3+94aqr7Gza1BpYa2Alq9OnAqXUWqRB4QQNDw/T0dHByMgIERHxPPJINXfeGUlmpo977+3nlFPsjI6OkpiYzLZt27T8pVJqTdOgsEQ+n4+2tjbsdjvh4RHU1pZwzTU5DAwIX/yinXe9q5OwMC8uVyRbt24lJydHnw6UUmueBoVFMsZgt9ux2+14PB4GBnL45jdL2L8/jDe/eZQLL2wiKWmC+Ph4CgrKSU5O1mCglFo3NCgsgt/vp7m5me7ubkZG4rnvvgqefDKJsrJJ7rmnk+JiB9HRUZSUVJKWlqbBQCm17mhQCNLQ0BAtLS309Dh58slc7r23hJQUP9/+dhO7dnWzaRPk5uZRWFioaSmUUuuWBoUgtLa20tbWyYsvRrJ79za83jAuv7yFN72pn7AwD1lZWeTn5xMTE7PaTVVKqROiQeEYjDG0t7fz/POdPPhgJi+9lM1//Ecj7373BCkpQnx8PMXFlSQkJKx2U5VSalloUFjA+Pg4e/c28MtfTvDMM2mkpRluvvkfVFSEU1JSRmZmptY1UEptOBoUjuD3+6mvP8T//V8fTz0VjsORwHveM8gb32goLMyloKBA1xoopTYsDQpzjI+P8+KLjTz++Cj79sVSUODmYx8bpaYmlYKCAuLi4la7iUopFVIaFLDGDjo77fzsZ6389reGqalw3vUuN+98ZzLFxYWarE4pddI46YPC1NQUv//9IX760x7sdsjLi+Df/i2C173OWmuglFInkzUXFETkbOA2IBy4xxhzfajuNTg4xu23H2T//n7Cw4V3vCOBd74zh/z8PKKiokJ1W6WUWrPWVFAQkXDgDuCtgB14SUSeNMbULed9jDH8+ted/PSn+5mamiAvL4UPfjCP17ymVAeRlVIntTUVFIDTgWZjTCuAiDwKnAMsa1DYvfsQf/7zS4SFRfO2t1Xy3veW6CCyUkqx9oJCDmCb89oOnDH3ABG5ALgAID8/f0k3efvb8+jsHORzn6smJ0frISul1Iy1tvpqvik+5rAXxuw2xuwyxuxa6kBwfv4Wrrvu9RoQlFLqCGstKNiBvDmvc4HuVWqLUkqddNZaUHgJKBWRIhGJBD4EPLnKbVJKqZPGmhpTMMZMi8hFwLNYU1J/ZIypXeVmKaXUSWNNBQUAY8zTwNOr3Q6llDoZrbXuI6WUUqtIg4JSSqlZGhSUUkrN0qCglFJqlpj/3979h95V13Ecf75w9pWtH25JMVOcy5VJMl3DtjTIWnOZ2D9GjsCpo0iCtIJwKI7+CjF0RSFGP4SKFZqoLMzk60AQ+5rWprM59xV/LVfbymbUP4rv/vi879np9p37/rj7nu45rwcc7jmf87mXz/u8L3zu55xzPyfiyLX+T0naD7wwzbefABwYYHOGgWPuBsfcDTOJ+ZSImPDfv0PdKcyEpMciYnnT7ZhNjrkbHHM3HK2YffrIzMwq7hTMzKzS5U7hB003oAGOuRscczcclZg7e03BzMz+V5dHCmZm1sedgpmZVTrZKUhaI2mXpHFJ1zbdnkGRdLKkrZJ2SnpK0tVZvkDSA5J25+v8LJek7+ZxeELSsmYjmB5Jx0j6o6QtuX2qpLGM95c5DTuSRnJ7PPcvarLdMyHpeEl3Sno6872yzXmW9NX8Tu+QtFnScW3Ms6QfS9onaUetbMp5lbQu6++WtG4qbehcpyDpGOD7wKeAM4C1ks5otlUD8zrw9Yj4ALACYwC4vgAABLFJREFU+HLGdi0wGhFLgNHchnIMluTyReDW2W/yQFwN7Kxt3wjckvG+AqzP8vXAKxFxGnBL1htW3wF+ExGnA0sp8bcyz5LeA3wFWB4RH6RMq38p7czz7cCavrIp5VXSAmAj5VHG5wAbex3JpEREpxZgJXB/bXsDsKHpdh2lWO8BPgnsAhZm2UJgV67fBqyt1a/qDctCeTrfKPBxYAvlka4HgDn9+aY8p2Nlrs/Jemo6hmnE/Hbguf62tzXPHHp2+4LM2xbggrbmGVgE7JhuXoG1wG218v+qd6SlcyMFDn3BevZkWavkkPlsYAx4d0TsBcjXd2W1NhyLTcA3gDdy+53APyLi9dyux1TFm/sPZv1hsxjYD/wkT5v9UNI8WprniPgz8G3gRWAvJW+P0/4890w1rzPKdxc7BU1Q1qr7ciW9FfgVcE1EvPpmVScoG5pjIekiYF9EPF4vnqBqTGLfMJkDLANujYizgX9x6JTCRIY67jz18RngVOBEYB7l1Em/tuX5SA4X54zi72KnsAc4ubZ9EvByQ20ZOEnHUjqEn0fEXVn8V0kLc/9CYF+WD/uxOBe4WNLzwC8op5A2AcdL6j1VsB5TFW/ufwfw99ls8IDsAfZExFhu30npJNqa51XAcxGxPyJeA+4CPkL789wz1bzOKN9d7BR+DyzJOxfeQrlgdW/DbRoISQJ+BOyMiJtru+4FencgrKNca+iVX5Z3MawADvaGqcMgIjZExEkRsYiSxwcj4vPAVuCSrNYfb+84XJL1h+4XZET8BXhJ0vuz6BPAn2hpnimnjVZImpvf8V68rc5zzVTzej+wWtL8HGWtzrLJafqiSkMXci4EngGeBa5ruj0DjOs8yjDxCWBbLhdSzqeOArvzdUHWF+VOrGeBJyl3dzQexzRj/xiwJdcXA48C48AdwEiWH5fb47l/cdPtnkG8ZwGPZa7vBua3Oc/AN4GngR3AT4GRNuYZ2Ey5bvIa5Rf/+unkFbgy4x8HrphKGzzNhZmZVbp4+sjMzA7DnYKZmVXcKZiZWcWdgpmZVdwpmJlZxZ2C2TRJukbS3KbbYTZIviXVbJryn9TLI+JA020xGxSPFMwmQdI8Sb+WtD3n9N9ImYdnq6StWWe1pEck/UHSHTkHFZKel3SjpEdzOS3LP5uftV3SQ81FZ3aIOwWzyVkDvBwRS6PM6b+JMp/M+RFxvqQTgOuBVRGxjPJv46/V3v9qRJwDfC/fC3ADcEFELAUunq1AzN6MOwWzyXkSWJW/+D8aEQf79q+gPLTpYUnbKHPUnFLbv7n2ujLXHwZul/QFyoNjzBo358hVzCwinpH0IcpcUt+S9Nu+KgIeiIi1h/uI/vWI+JKkDwOfBrZJOisi/jbotptNhUcKZpMg6UTg3xHxM8oDX5YB/wTellV+B5xbu14wV9L7ah/xudrrI1nnvRExFhE3UJ4OVp/u2KwRHimYTc6ZwE2S3qDMYHkV5TTQfZL25nWFy4HNkkbyPddTZuMFGJE0Rvkh1htN3CRpCWWUMQpsn51QzA7Pt6SaHWW+ddWGiU8fmZlZxSMFMzOreKRgZmYVdwpmZlZxp2BmZhV3CmZmVnGnYGZmlf8AdH7UuFkP6nIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "layers = [64]\n",
    "regret, regrets, _, _ = run_several_experiments_hist_DL_online(layers, evolutive_env = True, nb_exp = 20, nb_steps_history=1000)\n",
    "plot_regret(regret, regrets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation 0 started, time elapsed: 0.000 seconds.\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 89us/step - loss: 0.1388 - val_loss: 0.0421\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0340 - val_loss: 0.0313\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0299 - val_loss: 0.0316\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0298 - val_loss: 0.0332\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0300 - val_loss: 0.0316\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0297 - val_loss: 0.0343\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 52us/step - loss: 0.0299 - val_loss: 0.0310\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0302 - val_loss: 0.0312\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0298 - val_loss: 0.0313\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0299 - val_loss: 0.0309\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0300 - val_loss: 0.0303\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0304 - val_loss: 0.0304\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0300 - val_loss: 0.0334\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0298 - val_loss: 0.0330\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0307 - val_loss: 0.0328\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0301 - val_loss: 0.0330\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0302 - val_loss: 0.0314\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0302 - val_loss: 0.0298\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0302 - val_loss: 0.0317\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0299 - val_loss: 0.0306\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0302 - val_loss: 0.0310\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0301 - val_loss: 0.0331\n",
      "Epoch 23/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0303 - val_loss: 0.0327\n",
      "Epoch 24/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0306 - val_loss: 0.0338\n",
      "Epoch 25/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0305 - val_loss: 0.0319\n",
      "Epoch 26/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0300 - val_loss: 0.0308\n",
      "Epoch 27/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0302 - val_loss: 0.0300\n",
      "Epoch 28/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0302 - val_loss: 0.0323\n",
      "best reward is :  [0.5014751  0.46754328 0.45169845 0.43900041 0.42986183]\n",
      "reward is :  [0.35873219 0.45169845 0.30953366 0.15809602 0.07877678]\n",
      "regrets is :  [0.14274291 0.01584483 0.14216479 0.28090439 0.35108505] \n",
      "\n",
      "best reward is :  [0.5605916  0.52684564 0.52284297 0.49949255 0.49423729]\n",
      "reward is :  [0.49423729 0.52684564 0.41151367 0.23664457 0.22942824]\n",
      "regrets is :  [0.06635431 0.         0.1113293  0.26284798 0.26480905] \n",
      "\n",
      "best reward is :  [0.71606834 0.67396288 0.65603432 0.45985944 0.44731059]\n",
      "reward is :  [0.07104065 0.25612767 0.67396288 0.31381175 0.43187745]\n",
      "regrets is :  [ 0.64502769  0.41783521 -0.01792856  0.14604768  0.01543314] \n",
      "\n",
      "best reward is :  [0.61377392 0.60546821 0.57384258 0.48574806 0.41883596]\n",
      "reward is :  [0.24522115 0.39583543 0.61377392 0.60546821 0.35012531]\n",
      "regrets is :  [ 0.36855277  0.20963278 -0.03993134 -0.11972016  0.06871065] \n",
      "\n",
      "best reward is :  [0.76070314 0.72093201 0.70095223 0.58684564 0.50468085]\n",
      "reward is :  [0.47959302 0.58684564 0.50468085 0.17223816 0.23587743]\n",
      "regrets is :  [0.28111011 0.13408638 0.19627138 0.41460748 0.26880342] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 87us/step - loss: 0.1017 - val_loss: 0.0366\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0303 - val_loss: 0.0318\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0279 - val_loss: 0.0299\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0274 - val_loss: 0.0297\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0272 - val_loss: 0.0289\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0274 - val_loss: 0.0294\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0272 - val_loss: 0.0298\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0273 - val_loss: 0.0289\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0276 - val_loss: 0.0285\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0274 - val_loss: 0.0315\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 50us/step - loss: 0.0275 - val_loss: 0.0304\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0272 - val_loss: 0.0301\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0275 - val_loss: 0.0299\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0275 - val_loss: 0.0302\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0278 - val_loss: 0.0291\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0281 - val_loss: 0.0302\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0274 - val_loss: 0.0306\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0278 - val_loss: 0.0286\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0276 - val_loss: 0.0289\n",
      "best reward is :  [0.81418231 0.51932114 0.48580645 0.45112114 0.44047568]\n",
      "reward is :  [0.15457968 0.48580645 0.37194198 0.17375224 0.34706455]\n",
      "regrets is :  [0.65960263 0.03351468 0.11386447 0.27736889 0.09341112] \n",
      "\n",
      "best reward is :  [0.64988421 0.56741788 0.53952475 0.49115637 0.46590374]\n",
      "reward is :  [0.4149633  0.21030135 0.12560761 0.56741788 0.17913828]\n",
      "regrets is :  [ 0.23492091  0.35711653  0.41391714 -0.07626151  0.28676546] \n",
      "\n",
      "best reward is :  [0.77732593 0.72530202 0.61655598 0.56261306 0.47150932]\n",
      "reward is :  [0.319245   0.77732593 0.61655598 0.31169958 0.72530202]\n",
      "regrets is :  [ 0.45808093 -0.05202391  0.          0.25091348 -0.25379271] \n",
      "\n",
      "best reward is :  [0.56711588 0.48580645 0.37194198 0.35754247 0.35527314]\n",
      "reward is :  [0.34129767 0.48580645 0.37194198 0.33375224 0.56711588]\n",
      "regrets is :  [ 0.22581821  0.          0.          0.02379022 -0.21184274] \n",
      "\n",
      "best reward is :  [0.68287562 0.58580645 0.45436839 0.45418231 0.45120787]\n",
      "reward is :  [0.34129767 0.58580645 0.45436839 0.33375224 0.68287562]\n",
      "regrets is :  [ 0.34157795  0.          0.          0.12043007 -0.23166775] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 84us/step - loss: 0.1180 - val_loss: 0.0394\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 19us/step - loss: 0.0368 - val_loss: 0.0297\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0321 - val_loss: 0.0286\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0314 - val_loss: 0.0289\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0313 - val_loss: 0.0330\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0319 - val_loss: 0.0287\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0313 - val_loss: 0.0296\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0316 - val_loss: 0.0291\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0316 - val_loss: 0.0299\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0316 - val_loss: 0.0292\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0316 - val_loss: 0.0295\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0319 - val_loss: 0.0309\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0316 - val_loss: 0.0291\n",
      "best reward is :  [0.68764554 0.67021041 0.60788545 0.59202694 0.58829888]\n",
      "reward is :  [0.51501866 0.48284836 0.60788545 0.67021041 0.68764554]\n",
      "regrets is :  [ 0.17262688  0.18736205  0.         -0.07818347 -0.09934666] \n",
      "\n",
      "best reward is :  [0.74105263 0.56895647 0.54820734 0.47373665 0.47065221]\n",
      "reward is :  [0.46966292 0.54820734 0.74105263 0.46485467 0.56895647]\n",
      "regrets is :  [ 0.27138971  0.02074913 -0.19284529  0.00888198 -0.09830426] \n",
      "\n",
      "best reward is :  [0.74105263 0.60820734 0.5626221  0.4828078  0.47183516]\n",
      "reward is :  [0.38064679 0.60820734 0.74105263 0.37813669 0.5626221 ]\n",
      "regrets is :  [ 0.36040584  0.         -0.17843053  0.10467112 -0.09078694] \n",
      "\n",
      "best reward is :  [0.65504794 0.61827035 0.56866321 0.51725773 0.49784249]\n",
      "reward is :  [0.0987672  0.10820734 0.2120365  0.25583854 0.3822898 ]\n",
      "regrets is :  [0.55628075 0.51006301 0.35662671 0.26141919 0.11555268] \n",
      "\n",
      "best reward is :  [0.65033466 0.57457563 0.56373665 0.55007415 0.51413671]\n",
      "reward is :  [0.33366292 0.47088521 0.65033466 0.51413671 0.51157184]\n",
      "regrets is :  [ 0.31667174  0.10369042 -0.08659801  0.03593744  0.00256487] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 88us/step - loss: 0.0625 - val_loss: 0.0309\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0309 - val_loss: 0.0302\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0304 - val_loss: 0.0296\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0304 - val_loss: 0.0307\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0309 - val_loss: 0.0301\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0306 - val_loss: 0.0300\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0311 - val_loss: 0.0286\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0308 - val_loss: 0.0294\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0310 - val_loss: 0.0343\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0309 - val_loss: 0.0325\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0308 - val_loss: 0.0296\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0306 - val_loss: 0.0306\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0303 - val_loss: 0.0300\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0312 - val_loss: 0.0314\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0307 - val_loss: 0.0298\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0311 - val_loss: 0.0330\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0307 - val_loss: 0.0298\n",
      "best reward is :  [0.69681053 0.60547859 0.51488412 0.48321168 0.48142283]\n",
      "reward is :  [0.47692308 0.2197341  0.26148953 0.48321168 0.25312513]\n",
      "regrets is :  [0.21988745 0.38574449 0.25339459 0.         0.2282977 ] \n",
      "\n",
      "best reward is :  [0.69756688 0.6043332  0.51484809 0.47003293 0.41877047]\n",
      "reward is :  [0.39934948 0.24132838 0.23030235 0.40563809 0.23395554]\n",
      "regrets is :  [0.2982174  0.36300482 0.28454575 0.06439485 0.18481494] \n",
      "\n",
      "best reward is :  [0.59220147 0.49510701 0.44143502 0.43694863 0.4231029 ]\n",
      "reward is :  [0.23310444 0.02766275 0.01663671 0.59220147 0.44143502]\n",
      "regrets is :  [ 0.35909704  0.46744426  0.42479831 -0.15525284 -0.01833212] \n",
      "\n",
      "best reward is :  [0.58563809 0.54378442 0.43966275 0.41984074 0.38798825]\n",
      "reward is :  [0.23934948 0.04003981 0.01663671 0.58563809 0.41984074]\n",
      "regrets is :  [ 0.3462886   0.50374461  0.42302604 -0.16579735 -0.03185249] \n",
      "\n",
      "best reward is :  [0.67993036 0.49658921 0.48321168 0.47692308 0.4359237 ]\n",
      "reward is :  [0.47692308 0.25694479 0.21663671 0.48321168 0.32776939]\n",
      "regrets is :  [ 0.20300729  0.23964442  0.26657497 -0.0062886   0.10815431] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 87us/step - loss: 0.1727 - val_loss: 0.0411\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0309 - val_loss: 0.0311\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0275 - val_loss: 0.0304\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0270 - val_loss: 0.0305\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0267 - val_loss: 0.0284\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0266 - val_loss: 0.0307\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0268 - val_loss: 0.0299\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 76us/step - loss: 0.0268 - val_loss: 0.0296\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0269 - val_loss: 0.0299\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 66us/step - loss: 0.0265 - val_loss: 0.0308\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0269 - val_loss: 0.0292\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0268 - val_loss: 0.0308\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0272 - val_loss: 0.0306\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0272 - val_loss: 0.0289\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0269 - val_loss: 0.0285\n",
      "best reward is :  [0.59622912 0.46997029 0.44008261 0.44       0.43627377]\n",
      "reward is :  [0.59622912 0.15755187 0.0645108  0.44       0.25721854]\n",
      "regrets is :  [0.         0.31241842 0.3755718  0.         0.17905523] \n",
      "\n",
      "best reward is :  [0.62484369 0.61759087 0.60995277 0.5851775  0.51307602]\n",
      "reward is :  [0.11813802 0.08315827 0.46587302 0.45366563 0.27088417]\n",
      "regrets is :  [0.50670568 0.53443259 0.14407975 0.13151186 0.24219185] \n",
      "\n",
      "best reward is :  [0.66108193 0.60485281 0.56415603 0.55484011 0.5297057 ]\n",
      "reward is :  [0.66108193 0.56415603 0.28515505 0.60485281 0.42207136]\n",
      "regrets is :  [ 0.          0.04069678  0.27900099 -0.0500127   0.10763434] \n",
      "\n",
      "best reward is :  [0.67703242 0.64552206 0.58647712 0.5484823  0.47213986]\n",
      "reward is :  [0.12951113 0.07276255 0.38953865 0.27328201 0.05721854]\n",
      "regrets is :  [0.54752129 0.57275952 0.19693848 0.27520028 0.41492132] \n",
      "\n",
      "best reward is :  [0.51622912 0.46898979 0.43501498 0.38264178 0.34921244]\n",
      "reward is :  [0.51622912 0.2593689  0.08089475 0.46898979 0.25668511]\n",
      "regrets is :  [ 0.          0.2096209   0.35412024 -0.08634801  0.09252733] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 1s 125us/step - loss: 0.0972 - val_loss: 0.0333\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0328 - val_loss: 0.0295\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0312 - val_loss: 0.0285\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0307 - val_loss: 0.0282\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0305 - val_loss: 0.0276\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0307 - val_loss: 0.0281\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 55us/step - loss: 0.0304 - val_loss: 0.0290\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0306 - val_loss: 0.0282\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0306 - val_loss: 0.0294\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0307 - val_loss: 0.0289\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0311 - val_loss: 0.0291\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0310 - val_loss: 0.0283\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 66us/step - loss: 0.0311 - val_loss: 0.0287\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0309 - val_loss: 0.0292\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 82us/step - loss: 0.0310 - val_loss: 0.0289\n",
      "best reward is :  [0.65994715 0.62567097 0.61900022 0.61517457 0.59954887]\n",
      "reward is :  [0.59954887 0.49643915 0.65994715 0.43051411 0.43932042]\n",
      "regrets is :  [ 0.06039828  0.12923182 -0.04094693  0.18466046  0.16022845] \n",
      "\n",
      "best reward is :  [0.61806162 0.59418496 0.59033174 0.58075898 0.56598579]\n",
      "reward is :  [0.05954887 0.06772442 0.20067843 0.06515837 0.09898642]\n",
      "regrets is :  [0.55851275 0.52646054 0.38965331 0.51560061 0.46699937] \n",
      "\n",
      "best reward is :  [0.50524344 0.49947199 0.49752075 0.49427189 0.43413468]\n",
      "reward is :  [0.32783314 0.38474904 0.49752075 0.26965327 0.29014605]\n",
      "regrets is :  [0.1774103  0.11472295 0.         0.22461862 0.14398863] \n",
      "\n",
      "best reward is :  [0.58928272 0.52153232 0.50448893 0.49837812 0.45429338]\n",
      "reward is :  [0.24783314 0.27108341 0.20337861 0.15001118 0.27396469]\n",
      "regrets is :  [0.34144958 0.25044891 0.30111032 0.34836693 0.1803287 ] \n",
      "\n",
      "best reward is :  [0.67509434 0.54280165 0.54063135 0.52515837 0.51776809]\n",
      "reward is :  [0.35954887 0.39108341 0.67509434 0.52515837 0.54063135]\n",
      "regrets is :  [ 0.31554547  0.15171824 -0.13446299  0.         -0.02286327] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 92us/step - loss: 0.0809 - val_loss: 0.0401\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0300 - val_loss: 0.0311\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0264 - val_loss: 0.0293\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0258 - val_loss: 0.0283\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0254 - val_loss: 0.0279\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 54us/step - loss: 0.0255 - val_loss: 0.0282\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0261 - val_loss: 0.0284\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.025 - 0s 103us/step - loss: 0.0254 - val_loss: 0.0276\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 69us/step - loss: 0.0260 - val_loss: 0.0277\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0254 - val_loss: 0.0278\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0262 - val_loss: 0.0285\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0256 - val_loss: 0.0287\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 67us/step - loss: 0.0256 - val_loss: 0.0279\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 82us/step - loss: 0.0255 - val_loss: 0.0278\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 58us/step - loss: 0.0256 - val_loss: 0.0278\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 50us/step - loss: 0.0253 - val_loss: 0.0272\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 53us/step - loss: 0.0256 - val_loss: 0.0284\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0256 - val_loss: 0.0282\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0256 - val_loss: 0.0278\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 51us/step - loss: 0.0255 - val_loss: 0.0298\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0260 - val_loss: 0.0290\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.0254 - val_loss: 0.0283\n",
      "Epoch 23/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0256 - val_loss: 0.0287\n",
      "Epoch 24/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0259 - val_loss: 0.0278\n",
      "Epoch 25/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0255 - val_loss: 0.0274\n",
      "Epoch 26/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0260 - val_loss: 0.0288\n",
      "best reward is :  [0.85361702 0.71318656 0.6201301  0.58065574 0.53985895]\n",
      "reward is :  [0.46018415 0.85361702 0.58065574 0.71318656 0.47442623]\n",
      "regrets is :  [ 0.39343287 -0.14043046  0.03947436 -0.13253082  0.06543272] \n",
      "\n",
      "best reward is :  [0.85361702 0.64065574 0.55318656 0.5481128  0.53442623]\n",
      "reward is :  [0.5481128  0.85361702 0.64065574 0.55318656 0.53442623]\n",
      "regrets is :  [ 0.30550422 -0.21296128 -0.08746918 -0.00507376  0.        ] \n",
      "\n",
      "best reward is :  [0.77361702 0.70065574 0.57597747 0.48984043 0.4588133 ]\n",
      "reward is :  [0.3726077  0.77361702 0.70065574 0.39113389 0.40370826]\n",
      "regrets is :  [ 0.40100933 -0.07296128 -0.12467827  0.09870654  0.05510504] \n",
      "\n",
      "best reward is :  [0.77318656 0.72860067 0.5986326  0.55361702 0.55026616]\n",
      "reward is :  [0.4681128  0.55361702 0.34065574 0.77318656 0.53442623]\n",
      "regrets is :  [ 0.30507376  0.17498365  0.25797686 -0.21956954  0.01583993] \n",
      "\n",
      "best reward is :  [0.77888359 0.60008859 0.56685219 0.53361702 0.47432137]\n",
      "reward is :  [0.37313453 0.53361702 0.47432137 0.56685219 0.38809186]\n",
      "regrets is :  [ 0.40574906  0.06647157  0.09253082 -0.03323517  0.08622951] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 91us/step - loss: 0.0978 - val_loss: 0.0443\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0353 - val_loss: 0.0377\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0322 - val_loss: 0.0353\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0323 - val_loss: 0.0376\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0321 - val_loss: 0.0344\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0319 - val_loss: 0.0337\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 51us/step - loss: 0.0317 - val_loss: 0.0359\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0320 - val_loss: 0.0352\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 53us/step - loss: 0.0324 - val_loss: 0.0344\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0320 - val_loss: 0.0339\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0322 - val_loss: 0.0335\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0326 - val_loss: 0.0343\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 53us/step - loss: 0.0325 - val_loss: 0.0353\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.0323 - val_loss: 0.0340\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 53us/step - loss: 0.0329 - val_loss: 0.0344\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 52us/step - loss: 0.0322 - val_loss: 0.0348\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 54us/step - loss: 0.0320 - val_loss: 0.0372\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0326 - val_loss: 0.0376\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0318 - val_loss: 0.0377\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0318 - val_loss: 0.0380\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 54us/step - loss: 0.0325 - val_loss: 0.0378\n",
      "best reward is :  [0.57826087 0.53143627 0.53099189 0.52616216 0.46441795]\n",
      "reward is :  [0.53099189 0.52616216 0.57826087 0.43408682 0.43808301]\n",
      "regrets is :  [ 0.04726898  0.00527411 -0.04726898  0.09207534  0.02633494] \n",
      "\n",
      "best reward is :  [0.6135831  0.58765543 0.58183155 0.57320157 0.52562835]\n",
      "reward is :  [0.26574947 0.09234831 0.38736514 0.08642412 0.58183155]\n",
      "regrets is :  [ 0.34783364  0.49530712  0.1944664   0.48677745 -0.05620319] \n",
      "\n",
      "best reward is :  [0.65826087 0.53610967 0.47541097 0.47348955 0.38234352]\n",
      "reward is :  [0.25884535 0.38234352 0.65826087 0.36873108 0.26272727]\n",
      "regrets is :  [ 0.39941552  0.15376614 -0.1828499   0.10475847  0.11961625] \n",
      "\n",
      "best reward is :  [0.85826087 0.55319296 0.53414965 0.5335839  0.47720957]\n",
      "reward is :  [0.33870185 0.43101498 0.85826087 0.5335839  0.35272727]\n",
      "regrets is :  [ 0.51955902  0.12217799 -0.32411122  0.          0.1244823 ] \n",
      "\n",
      "best reward is :  [0.79826087 0.55319296 0.53414965 0.50873108 0.47720957]\n",
      "reward is :  [0.33870185 0.43101498 0.79826087 0.50873108 0.29272727]\n",
      "regrets is :  [ 0.45955902  0.12217799 -0.26411122  0.          0.1844823 ] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 88us/step - loss: 0.1013 - val_loss: 0.0349\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0332 - val_loss: 0.0314\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0312 - val_loss: 0.0307\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0310 - val_loss: 0.0302\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0308 - val_loss: 0.0309\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0309 - val_loss: 0.0316\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0313 - val_loss: 0.0317\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0311 - val_loss: 0.0308\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0311 - val_loss: 0.0304\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0309 - val_loss: 0.0307\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0313 - val_loss: 0.0310\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0311 - val_loss: 0.0333\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0316 - val_loss: 0.0302\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0309 - val_loss: 0.0312\n",
      "best reward is :  [0.59543788 0.55133893 0.45962617 0.45202186 0.43321235]\n",
      "reward is :  [0.0973323  0.45962617 0.37157895 0.59543788 0.09624718]\n",
      "regrets is :  [ 0.49810558  0.09171277  0.08804722 -0.14341602  0.33696517] \n",
      "\n",
      "best reward is :  [0.70985732 0.6629608  0.57084995 0.56917663 0.55513376]\n",
      "reward is :  [0.24872413 0.54521025 0.46776031 0.38929612 0.23284147]\n",
      "regrets is :  [0.46113319 0.11775055 0.10308964 0.17988051 0.32229229] \n",
      "\n",
      "best reward is :  [0.64432924 0.52447898 0.51257236 0.50210455 0.48996546]\n",
      "reward is :  [0.10188168 0.52447898 0.40056874 0.50210455 0.07824125]\n",
      "regrets is :  [0.54244756 0.         0.11200362 0.         0.41172421] \n",
      "\n",
      "best reward is :  [0.71835064 0.52176458 0.45306706 0.40254014 0.39710998]\n",
      "reward is :  [0.27904886 0.20447898 0.04634993 0.37847049 0.32520472]\n",
      "regrets is :  [0.43930178 0.3172856  0.40671713 0.02406965 0.07190526] \n",
      "\n",
      "best reward is :  [0.56245146 0.55684444 0.50152819 0.47254901 0.46725738]\n",
      "reward is :  [0.4508198  0.14581232 0.07157895 0.19233013 0.46725738]\n",
      "regrets is :  [0.11163166 0.41103213 0.42994925 0.28021888 0.        ] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 70us/step - loss: 0.0812 - val_loss: 0.0341\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0309 - val_loss: 0.0285\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 19us/step - loss: 0.0290 - val_loss: 0.0274\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0285 - val_loss: 0.0274\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0282 - val_loss: 0.0281\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0286 - val_loss: 0.0274\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0283 - val_loss: 0.0273\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0288 - val_loss: 0.0282\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0286 - val_loss: 0.0291\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0282 - val_loss: 0.0284\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0285 - val_loss: 0.0288\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0286 - val_loss: 0.0281\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0287 - val_loss: 0.0277\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0286 - val_loss: 0.0286\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0288 - val_loss: 0.0276\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0285 - val_loss: 0.0274\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0290 - val_loss: 0.0282\n",
      "best reward is :  [0.76445445 0.68608203 0.66667076 0.62368203 0.52451866]\n",
      "reward is :  [0.62368203 0.76445445 0.68608203 0.66667076 0.49992026]\n",
      "regrets is :  [ 0.14077241 -0.07837241 -0.01941128 -0.04298872  0.02459839] \n",
      "\n",
      "best reward is :  [0.56215574 0.53517241 0.41938121 0.3944     0.38816211]\n",
      "reward is :  [0.3944     0.53517241 0.56215574 0.25607779 0.19311653]\n",
      "regrets is :  [ 0.16775574  0.         -0.14277453  0.13832221  0.19504558] \n",
      "\n",
      "best reward is :  [0.60017582 0.54883805 0.44590428 0.4332648  0.38350428]\n",
      "reward is :  [0.38350428 0.54883805 0.44590428 0.306493   0.4332648 ]\n",
      "regrets is :  [ 0.21667154  0.          0.          0.1267718  -0.04976052] \n",
      "\n",
      "best reward is :  [0.81517241 0.6744     0.65105436 0.52332157 0.51922641]\n",
      "reward is :  [0.6744     0.81517241 0.51922641 0.65105436 0.47249386]\n",
      "regrets is :  [ 0.14077241 -0.14077241  0.13182795 -0.12773278  0.04673255] \n",
      "\n",
      "best reward is :  [0.61105879 0.57559235 0.50477405 0.43867394 0.43553291]\n",
      "reward is :  [0.27234733 0.41311975 0.25989401 0.22092266 0.23807369]\n",
      "regrets is :  [0.33871145 0.1624726  0.24488004 0.21775128 0.19745922] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 84us/step - loss: 0.0704 - val_loss: 0.0358\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0309 - val_loss: 0.0359\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0293 - val_loss: 0.0338\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0289 - val_loss: 0.0310\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0290 - val_loss: 0.0320\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0288 - val_loss: 0.0305\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0290 - val_loss: 0.0327\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0289 - val_loss: 0.0298\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0290 - val_loss: 0.0315\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0288 - val_loss: 0.0287\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0294 - val_loss: 0.0298\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0288 - val_loss: 0.0297\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0291 - val_loss: 0.0336\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0284 - val_loss: 0.0313\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0286 - val_loss: 0.0293\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0289 - val_loss: 0.0314\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0295 - val_loss: 0.0323\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0289 - val_loss: 0.0332\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0288 - val_loss: 0.0311\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0288 - val_loss: 0.0310\n",
      "best reward is :  [0.66634208 0.65807426 0.51155425 0.48735857 0.48212624]\n",
      "reward is :  [0.38994733 0.35929187 0.65807426 0.66634208 0.27912678]\n",
      "regrets is :  [ 0.27639474  0.29878239 -0.14652001 -0.17898351  0.20299946] \n",
      "\n",
      "best reward is :  [0.67297338 0.67013699 0.53598555 0.53333039 0.51540444]\n",
      "reward is :  [0.22664102 0.53598555 0.36012693 0.39735228 0.67013699]\n",
      "regrets is :  [ 0.44633236  0.13415143  0.17585863  0.13597811 -0.15473255] \n",
      "\n",
      "best reward is :  [0.66792207 0.66176961 0.495042   0.48262295 0.43721303]\n",
      "reward is :  [0.42128203 0.26008539 0.20940896 0.19609313 0.37941902]\n",
      "regrets is :  [0.24664003 0.40168422 0.28563304 0.28652982 0.05779401] \n",
      "\n",
      "best reward is :  [0.66129393 0.53968898 0.53889662 0.50159501 0.4956938 ]\n",
      "reward is :  [0.38528201 0.35710131 0.16280479 0.21529961 0.4769698 ]\n",
      "regrets is :  [0.27601192 0.18258768 0.37609183 0.28629539 0.018724  ] \n",
      "\n",
      "best reward is :  [0.60226315 0.59530036 0.58013699 0.5733134  0.52678813]\n",
      "reward is :  [0.40098979 0.49033433 0.1692312  0.20735228 0.58013699]\n",
      "regrets is :  [ 0.20127335  0.10496602  0.41090578  0.36596112 -0.05334885] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 69us/step - loss: 0.0837 - val_loss: 0.0356\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0323 - val_loss: 0.0353\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0309 - val_loss: 0.0353\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0309 - val_loss: 0.0344\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0310 - val_loss: 0.0363\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0308 - val_loss: 0.0342\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0307 - val_loss: 0.0352\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0318 - val_loss: 0.0365\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0320 - val_loss: 0.0349\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0308 - val_loss: 0.0361\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0314 - val_loss: 0.0349\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0308 - val_loss: 0.0350\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0317 - val_loss: 0.0352\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0314 - val_loss: 0.0348\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0306 - val_loss: 0.0334\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0319 - val_loss: 0.0351\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0315 - val_loss: 0.0343\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0312 - val_loss: 0.0348\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0311 - val_loss: 0.0357\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0310 - val_loss: 0.0372\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0309 - val_loss: 0.0344\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0312 - val_loss: 0.0346\n",
      "Epoch 23/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0310 - val_loss: 0.0353\n",
      "Epoch 24/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0310 - val_loss: 0.0346\n",
      "Epoch 25/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0311 - val_loss: 0.0352\n",
      "best reward is :  [0.7258341  0.6531923  0.54754885 0.54676822 0.51720074]\n",
      "reward is :  [0.6531923  0.08892443 0.10193012 0.08671712 0.20696305]\n",
      "regrets is :  [0.07264181 0.56426787 0.44561873 0.4600511  0.31023769] \n",
      "\n",
      "best reward is :  [0.58773348 0.57762152 0.49081252 0.48882998 0.45597918]\n",
      "reward is :  [0.57762152 0.24633843 0.27121215 0.34222222 0.45597918]\n",
      "regrets is :  [0.01011196 0.33128308 0.21960037 0.14660776 0.        ] \n",
      "\n",
      "best reward is :  [0.67597918 0.58442953 0.56340501 0.56193012 0.53086279]\n",
      "reward is :  [0.20833948 0.58442953 0.56193012 0.34222222 0.67597918]\n",
      "regrets is :  [ 0.4676397   0.          0.00147489  0.21970789 -0.14511639] \n",
      "\n",
      "best reward is :  [0.7258341  0.62833948 0.54754885 0.54676822 0.51720074]\n",
      "reward is :  [0.62833948 0.08892443 0.10193012 0.08671712 0.23597918]\n",
      "regrets is :  [0.09749462 0.53941506 0.44561873 0.4600511  0.28122156] \n",
      "\n",
      "best reward is :  [0.55036642 0.52888889 0.52526121 0.48193012 0.48162483]\n",
      "reward is :  [0.20603252 0.40945126 0.48193012 0.52888889 0.52526121]\n",
      "regrets is :  [ 0.3443339   0.11943763  0.0433311  -0.04695877 -0.04363638] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 87us/step - loss: 0.1120 - val_loss: 0.0411\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0333 - val_loss: 0.0349\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0314 - val_loss: 0.0349\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0311 - val_loss: 0.0346\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0312 - val_loss: 0.0352\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0310 - val_loss: 0.0346\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0312 - val_loss: 0.0324\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0311 - val_loss: 0.0337\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0317 - val_loss: 0.0358\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0317 - val_loss: 0.0334\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0314 - val_loss: 0.0360\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0316 - val_loss: 0.0347\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0313 - val_loss: 0.0340\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0311 - val_loss: 0.0341\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0314 - val_loss: 0.0333\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0316 - val_loss: 0.0348\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0317 - val_loss: 0.0390\n",
      "best reward is :  [0.62750638 0.57689858 0.57096818 0.53632961 0.53411991]\n",
      "reward is :  [0.36       0.1215196  0.14658265 0.05156165 0.45693918]\n",
      "regrets is :  [0.26750638 0.45537898 0.42438553 0.48476796 0.07718073] \n",
      "\n",
      "best reward is :  [0.70681769 0.53697762 0.52756121 0.52166452 0.51521368]\n",
      "reward is :  [0.26155264 0.12455583 0.08994972 0.03386861 0.47250996]\n",
      "regrets is :  [0.44526505 0.41242179 0.43761148 0.4877959  0.04270372] \n",
      "\n",
      "best reward is :  [0.53711737 0.44794193 0.43297716 0.41745703 0.41152663]\n",
      "reward is :  [0.29366563 0.33228523 0.30658265 0.24753424 0.28132277]\n",
      "regrets is :  [0.24345174 0.11565671 0.12639452 0.16992278 0.13020385] \n",
      "\n",
      "best reward is :  [0.7482229  0.66906427 0.5738379  0.56863128 0.56137248]\n",
      "reward is :  [0.28242641 0.30835893 0.26937196 0.21035188 0.27301288]\n",
      "regrets is :  [0.46579649 0.36070533 0.30446594 0.35827939 0.2883596 ] \n",
      "\n",
      "best reward is :  [0.59509511 0.57739747 0.57146707 0.5340167  0.46      ]\n",
      "reward is :  [0.46       0.12568106 0.09581702 0.05654648 0.28132277]\n",
      "regrets is :  [0.13509511 0.45171641 0.47565006 0.47747022 0.17867723] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 84us/step - loss: 0.0538 - val_loss: 0.0308\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0283 - val_loss: 0.0298\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0276 - val_loss: 0.0298\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0277 - val_loss: 0.0315\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0280 - val_loss: 0.0288\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0282 - val_loss: 0.0323\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0278 - val_loss: 0.0290\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0277 - val_loss: 0.0286\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0277 - val_loss: 0.0288\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0281 - val_loss: 0.0302\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0277 - val_loss: 0.0295\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0279 - val_loss: 0.0313\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0279 - val_loss: 0.0297\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0278 - val_loss: 0.0293\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0283 - val_loss: 0.0331\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0281 - val_loss: 0.0334\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0281 - val_loss: 0.0306\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0283 - val_loss: 0.0286\n",
      "best reward is :  [0.72027585 0.68973785 0.61362096 0.61215909 0.52782302]\n",
      "reward is :  [0.52782302 0.72027585 0.68973785 0.45146032 0.51618136]\n",
      "regrets is :  [ 0.19245283 -0.030538   -0.07611689  0.16069877  0.01164166] \n",
      "\n",
      "best reward is :  [0.55516704 0.54063751 0.52809216 0.47266932 0.43325697]\n",
      "reward is :  [0.10192724 0.40204182 0.20184076 0.10805461 0.19794733]\n",
      "regrets is :  [0.4532398  0.13859569 0.3262514  0.36461471 0.23530964] \n",
      "\n",
      "best reward is :  [0.76       0.75883323 0.68247052 0.65861111 0.64409449]\n",
      "reward is :  [0.75883323 0.64409449 0.61355649 0.68247052 0.76      ]\n",
      "regrets is :  [ 0.00116677  0.11473874  0.06891404 -0.02385941 -0.11590551] \n",
      "\n",
      "best reward is :  [0.83883323 0.74247052 0.70409449 0.68       0.57776467]\n",
      "reward is :  [0.83883323 0.70409449 0.53355649 0.74247052 0.68      ]\n",
      "regrets is :  [ 0.          0.03837603  0.170538   -0.06247052 -0.10223533] \n",
      "\n",
      "best reward is :  [0.68811526 0.62683282 0.54930334 0.51616584 0.49821767]\n",
      "reward is :  [0.68811526 0.51616584 0.40283852 0.54930334 0.62683282]\n",
      "regrets is :  [ 0.          0.11066698  0.14646482 -0.0331375  -0.12861514] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 81us/step - loss: 0.0509 - val_loss: 0.0326\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0328 - val_loss: 0.0311\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0322 - val_loss: 0.0327\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0320 - val_loss: 0.0323\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0323 - val_loss: 0.0330\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0323 - val_loss: 0.0319\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0332 - val_loss: 0.0322\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0317 - val_loss: 0.0321\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0325 - val_loss: 0.0329\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0324 - val_loss: 0.0358\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0325 - val_loss: 0.0323\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0321 - val_loss: 0.0340\n",
      "best reward is :  [0.64468986 0.61396311 0.61066355 0.60429611 0.53890951]\n",
      "reward is :  [0.53890951 0.47622198 0.49286365 0.47622198 0.49845018]\n",
      "regrets is :  [0.10578035 0.13774114 0.1177999  0.12807413 0.04045932] \n",
      "\n",
      "best reward is :  [0.41204363 0.39654138 0.38753769 0.36991971 0.33845018]\n",
      "reward is :  [0.36991971 0.30060557 0.09286365 0.11522421 0.33845018]\n",
      "regrets is :  [0.04212391 0.0959358  0.29467404 0.2546955  0.        ] \n",
      "\n",
      "best reward is :  [0.59939611 0.55790411 0.48937776 0.48872551 0.47253707]\n",
      "reward is :  [0.28320173 0.30060557 0.10843443 0.11047388 0.33845018]\n",
      "regrets is :  [0.31619438 0.25729854 0.38094333 0.37825163 0.13408688] \n",
      "\n",
      "best reward is :  [0.65286365 0.64472733 0.63622198 0.62693994 0.61412691]\n",
      "reward is :  [0.54991971 0.62693994 0.65286365 0.63622198 0.48087659]\n",
      "regrets is :  [ 0.10294393  0.01778739 -0.01664167 -0.00928203  0.13325032] \n",
      "\n",
      "best reward is :  [0.71803085 0.67418308 0.57179276 0.55508271 0.54245676]\n",
      "reward is :  [0.49477253 0.35196167 0.53976298 0.57179276 0.36463633]\n",
      "regrets is :  [ 0.22325832  0.3222214   0.03202978 -0.01671004  0.17782043] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 86us/step - loss: 0.1014 - val_loss: 0.0312\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0300 - val_loss: 0.0330\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0297 - val_loss: 0.0323\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0301 - val_loss: 0.0304\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0305 - val_loss: 0.0324\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0300 - val_loss: 0.0314\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0308 - val_loss: 0.0316\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0300 - val_loss: 0.0349\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0298 - val_loss: 0.0305\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0299 - val_loss: 0.0304\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0307 - val_loss: 0.0313\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0301 - val_loss: 0.0298\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0300 - val_loss: 0.0294\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0300 - val_loss: 0.0305\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0297 - val_loss: 0.0295\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0301 - val_loss: 0.0310\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0300 - val_loss: 0.0305\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0299 - val_loss: 0.0304\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0314 - val_loss: 0.0313\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0305 - val_loss: 0.0321\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0305 - val_loss: 0.0326\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0307 - val_loss: 0.0315\n",
      "Epoch 23/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0300 - val_loss: 0.0301\n",
      "best reward is :  [0.67055756 0.58409166 0.51263255 0.50529881 0.49547818]\n",
      "reward is :  [0.50529881 0.45148936 0.49547818 0.3039711  0.48438407]\n",
      "regrets is :  [0.16525875 0.1326023  0.01715437 0.20132771 0.01109411] \n",
      "\n",
      "best reward is :  [0.63927741 0.54752344 0.53333333 0.49141905 0.48080171]\n",
      "reward is :  [0.42529881 0.28047916 0.26619615 0.30933009 0.45510204]\n",
      "regrets is :  [0.2139786  0.26704429 0.26713718 0.18208897 0.02569967] \n",
      "\n",
      "best reward is :  [0.67906052 0.62528784 0.5199552  0.51101809 0.50194359]\n",
      "reward is :  [0.49630901 0.29148936 0.32619615 0.32299572 0.44045778]\n",
      "regrets is :  [0.18275151 0.33379848 0.19375905 0.18802237 0.06148582] \n",
      "\n",
      "best reward is :  [0.82662152 0.70116183 0.67104896 0.63634218 0.61861212]\n",
      "reward is :  [0.70116183 0.63634218 0.67104896 0.61861212 0.82662152]\n",
      "regrets is :  [ 0.12545969  0.06481965  0.          0.01773006 -0.2080094 ] \n",
      "\n",
      "best reward is :  [0.78982178 0.70371565 0.64529881 0.58480542 0.5298846 ]\n",
      "reward is :  [0.64529881 0.43391577 0.31947816 0.43831988 0.46409184]\n",
      "regrets is :  [0.14452297 0.26979988 0.32582065 0.14648554 0.06579276] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 71us/step - loss: 0.1599 - val_loss: 0.0423\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0361 - val_loss: 0.0309\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0327 - val_loss: 0.0286\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0316 - val_loss: 0.0290\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 19us/step - loss: 0.0314 - val_loss: 0.0295\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0315 - val_loss: 0.0280\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0315 - val_loss: 0.0285\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0318 - val_loss: 0.0293\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0317 - val_loss: 0.0291\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0315 - val_loss: 0.0294\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0314 - val_loss: 0.0290\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0318 - val_loss: 0.0287\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0316 - val_loss: 0.0307\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0313 - val_loss: 0.0286\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0315 - val_loss: 0.0292\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0317 - val_loss: 0.0299\n",
      "best reward is :  [0.65894737 0.58914827 0.57557395 0.55555556 0.55307395]\n",
      "reward is :  [0.52655172 0.65894737 0.55555556 0.4359487  0.42848485]\n",
      "regrets is :  [ 0.13239564 -0.0697991   0.0200184   0.11960686  0.1245891 ] \n",
      "\n",
      "best reward is :  [0.77452632 0.71512873 0.58785547 0.57463655 0.54125   ]\n",
      "reward is :  [0.43157345 0.71512873 0.47173692 0.40130768 0.34312586]\n",
      "regrets is :  [0.34295286 0.         0.11611856 0.17332887 0.19812414] \n",
      "\n",
      "best reward is :  [0.84848485 0.75377054 0.58901754 0.53474617 0.49715784]\n",
      "reward is :  [0.20897813 0.35894737 0.24922119 0.07495094 0.84848485]\n",
      "regrets is :  [ 0.63950672  0.39482317  0.33979636  0.45979523 -0.35132701] \n",
      "\n",
      "best reward is :  [0.73894737 0.67317809 0.65325    0.63555556 0.55429869]\n",
      "reward is :  [0.54655172 0.73894737 0.63555556 0.50666667 0.3405562 ]\n",
      "regrets is :  [ 0.19239564 -0.06576928  0.01769444  0.12888889  0.2137425 ] \n",
      "\n",
      "best reward is :  [0.63852459 0.6288448  0.59352613 0.57410582 0.53981394]\n",
      "reward is :  [0.20897813 0.25894737 0.41555556 0.26666667 0.45039375]\n",
      "regrets is :  [0.42954646 0.36989743 0.17797057 0.30743916 0.08942019] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 71us/step - loss: 0.1338 - val_loss: 0.0385\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 19us/step - loss: 0.0330 - val_loss: 0.0289\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 19us/step - loss: 0.0290 - val_loss: 0.0276\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0284 - val_loss: 0.0274\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0285 - val_loss: 0.0273\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0287 - val_loss: 0.0274\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0285 - val_loss: 0.0268\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0285 - val_loss: 0.0270\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 19us/step - loss: 0.0286 - val_loss: 0.0266\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0285 - val_loss: 0.0271\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0287 - val_loss: 0.0277\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0285 - val_loss: 0.0272\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0286 - val_loss: 0.0275\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0286 - val_loss: 0.0274\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0289 - val_loss: 0.0271\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0289 - val_loss: 0.0276\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0287 - val_loss: 0.0292\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0291 - val_loss: 0.0280\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0285 - val_loss: 0.0274\n",
      "best reward is :  [0.61194846 0.60249617 0.54630791 0.50043127 0.42162969]\n",
      "reward is :  [0.26267787 0.06669891 0.04221284 0.28018737 0.05014612]\n",
      "regrets is :  [0.34927059 0.53579727 0.50409507 0.2202439  0.37148357] \n",
      "\n",
      "best reward is :  [0.76485281 0.57878139 0.54769667 0.5266925  0.51377632]\n",
      "reward is :  [0.76485281 0.54769667 0.57878139 0.37580377 0.5266925 ]\n",
      "regrets is :  [ 0.          0.03108472 -0.03108472  0.15088873 -0.01291618] \n",
      "\n",
      "best reward is :  [0.48659617 0.42828427 0.41334569 0.4105247  0.40326745]\n",
      "reward is :  [0.42828427 0.40326745 0.37928431 0.39137455 0.40255552]\n",
      "regrets is :  [0.0583119  0.02501682 0.03406138 0.01915014 0.00071193] \n",
      "\n",
      "best reward is :  [0.66485281 0.54117471 0.53392857 0.47937846 0.46255552]\n",
      "reward is :  [0.66485281 0.42740443 0.53392857 0.39551153 0.46255552]\n",
      "regrets is :  [0.         0.11377028 0.         0.08386693 0.        ] \n",
      "\n",
      "best reward is :  [0.61194846 0.60249617 0.54630791 0.50043127 0.42162969]\n",
      "reward is :  [0.26267787 0.09841463 0.04221284 0.28018737 0.05014612]\n",
      "regrets is :  [0.34927059 0.50408154 0.50409507 0.2202439  0.37148357] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 87us/step - loss: 0.0684 - val_loss: 0.0313\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0332 - val_loss: 0.0306\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0324 - val_loss: 0.0307\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0327 - val_loss: 0.0304\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0322 - val_loss: 0.0309\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0329 - val_loss: 0.0318\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0325 - val_loss: 0.0351\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0328 - val_loss: 0.0325\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0324 - val_loss: 0.0303\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0332 - val_loss: 0.0356\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0330 - val_loss: 0.0334\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0325 - val_loss: 0.0322\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0329 - val_loss: 0.0310\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0329 - val_loss: 0.0312\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0326 - val_loss: 0.0317\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0325 - val_loss: 0.0311\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0324 - val_loss: 0.0304\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0331 - val_loss: 0.0323\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0324 - val_loss: 0.0311\n",
      "best reward is :  [0.45410962 0.41815488 0.4159487  0.36737481 0.35315436]\n",
      "reward is :  [0.4159487  0.14966568 0.20108459 0.45410962 0.20752759]\n",
      "regrets is :  [ 0.03816092  0.26848921  0.21486411 -0.08673481  0.14562678] \n",
      "\n",
      "best reward is :  [0.55913998 0.48725252 0.43899438 0.40130734 0.39819881]\n",
      "reward is :  [0.26502173 0.01389474 0.27647059 0.02482759 0.31919755]\n",
      "regrets is :  [0.29411825 0.47335779 0.16252379 0.37647975 0.07900126] \n",
      "\n",
      "best reward is :  [0.74       0.5580694  0.52317677 0.51352227 0.48529673]\n",
      "reward is :  [0.74       0.52317677 0.40575262 0.20072197 0.22795832]\n",
      "regrets is :  [0.         0.03489263 0.11742415 0.31280029 0.25733841] \n",
      "\n",
      "best reward is :  [0.62553191 0.58555526 0.52       0.49706425 0.48094118]\n",
      "reward is :  [0.52       0.24317677 0.08096549 0.09410962 0.62553191]\n",
      "regrets is :  [ 0.10553191  0.34237849  0.43903451  0.40295463 -0.14459074] \n",
      "\n",
      "best reward is :  [0.68506816 0.64553191 0.58070814 0.52       0.48725252]\n",
      "reward is :  [0.52       0.19389474 0.09265195 0.03937972 0.64553191]\n",
      "regrets is :  [ 0.16506816  0.45163718  0.48805619  0.48062028 -0.15827939] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 88us/step - loss: 0.0964 - val_loss: 0.0317\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0282 - val_loss: 0.0274\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0280 - val_loss: 0.0288\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0279 - val_loss: 0.0264\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0276 - val_loss: 0.0266\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0281 - val_loss: 0.0314\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0280 - val_loss: 0.0279\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0275 - val_loss: 0.0274\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0273 - val_loss: 0.0261\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0273 - val_loss: 0.0273\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0277 - val_loss: 0.0284\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0287 - val_loss: 0.0277\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0274 - val_loss: 0.0261\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0279 - val_loss: 0.0270\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0288 - val_loss: 0.0265\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0278 - val_loss: 0.0272\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0280 - val_loss: 0.0264\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0278 - val_loss: 0.0275\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0283 - val_loss: 0.0259\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0277 - val_loss: 0.0286\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0278 - val_loss: 0.0272\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0276 - val_loss: 0.0257\n",
      "Epoch 23/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0280 - val_loss: 0.0266\n",
      "Epoch 24/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0279 - val_loss: 0.0275\n",
      "Epoch 25/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0279 - val_loss: 0.0279\n",
      "Epoch 26/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0276 - val_loss: 0.0267\n",
      "Epoch 27/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0275 - val_loss: 0.0265\n",
      "Epoch 28/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0283 - val_loss: 0.0278\n",
      "Epoch 29/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0283 - val_loss: 0.0275\n",
      "Epoch 30/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0276 - val_loss: 0.0274\n",
      "Epoch 31/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0282 - val_loss: 0.0274\n",
      "Epoch 32/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0278 - val_loss: 0.0278\n",
      "best reward is :  [0.55303493 0.44857374 0.39331155 0.38105676 0.36710532]\n",
      "reward is :  [0.29122641 0.30250802 0.0969579  0.44857374 0.15358732]\n",
      "regrets is :  [ 0.26180853  0.14606573  0.29635365 -0.06751698  0.21351799] \n",
      "\n",
      "best reward is :  [0.6467073  0.64313177 0.62318846 0.57182395 0.54812903]\n",
      "reward is :  [0.3688     0.38922601 0.47575168 0.11836195 0.25464102]\n",
      "regrets is :  [0.2779073  0.25390576 0.14743677 0.453462   0.29348801] \n",
      "\n",
      "best reward is :  [0.62372093 0.5329599  0.48922601 0.4688     0.44306284]\n",
      "reward is :  [0.4688     0.48922601 0.19860883 0.62372093 0.36      ]\n",
      "regrets is :  [ 0.15492093  0.0437339   0.29061718 -0.15492093  0.08306284] \n",
      "\n",
      "best reward is :  [0.50345399 0.48727628 0.44130768 0.4382158  0.4288    ]\n",
      "reward is :  [0.4288     0.4382158  0.34146597 0.42372093 0.44130768]\n",
      "regrets is :  [ 0.07465399  0.04906048  0.09984171  0.01449487 -0.01250768] \n",
      "\n",
      "best reward is :  [0.6208983  0.60823305 0.56604194 0.56290543 0.54298719]\n",
      "reward is :  [0.33365281 0.30922601 0.45965212 0.11990229 0.30485281]\n",
      "regrets is :  [0.28724549 0.29900704 0.10638982 0.44300314 0.23813438] \n",
      "\n",
      "End of the simulations, time elapsed: 145.441 seconds.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "layers = [64]\n",
    "regret, regrets, _, _ = run_several_experiments_hist_DL(layers, evolutive_env = False, nb_exp = 20, nb_steps_history=1000)\n",
    "plot_regret(regret, regrets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation 0 started, time elapsed: 0.000 seconds.\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 95us/step - loss: 0.1009 - val_loss: 0.0360\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0317 - val_loss: 0.0304\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0297 - val_loss: 0.0303\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0295 - val_loss: 0.0306\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0295 - val_loss: 0.0294\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0296 - val_loss: 0.0290\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0297 - val_loss: 0.0294\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0293 - val_loss: 0.0302\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0296 - val_loss: 0.0303\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0296 - val_loss: 0.0323\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 52us/step - loss: 0.0296 - val_loss: 0.0294\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0294 - val_loss: 0.0313\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0294 - val_loss: 0.0292\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0295 - val_loss: 0.0303\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0294 - val_loss: 0.0291\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0297 - val_loss: 0.0306\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 35us/step - loss: 0.0298 - val_loss: 0.0450\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 43us/step - loss: 0.0313 - val_loss: 0.0415\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 39us/step - loss: 0.0294 - val_loss: 0.0430\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 46us/step - loss: 0.0298 - val_loss: 0.0407\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 45us/step - loss: 0.0294 - val_loss: 0.0398\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 29us/step - loss: 0.0304 - val_loss: 0.0377\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 37us/step - loss: 0.0307 - val_loss: 0.0425\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.0309 - val_loss: 0.0482\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 36us/step - loss: 0.0306 - val_loss: 0.0412\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.0311 - val_loss: 0.0438\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 34us/step - loss: 0.0317 - val_loss: 0.0309\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 37us/step - loss: 0.0318 - val_loss: 0.0307\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 45us/step - loss: 0.0313 - val_loss: 0.0340\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 40us/step - loss: 0.0312 - val_loss: 0.0388\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 43us/step - loss: 0.0315 - val_loss: 0.0347\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 32us/step - loss: 0.0316 - val_loss: 0.0421\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 38us/step - loss: 0.0313 - val_loss: 0.0422\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 35us/step - loss: 0.0312 - val_loss: 0.0411\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 29us/step - loss: 0.0312 - val_loss: 0.0470\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 27us/step - loss: 0.0309 - val_loss: 0.0407\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.0322 - val_loss: 0.0383\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.0322 - val_loss: 0.0438\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 42us/step - loss: 0.0321 - val_loss: 0.0386\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 45us/step - loss: 0.0321 - val_loss: 0.0388\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 46us/step - loss: 0.0324 - val_loss: 0.0375\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 35us/step - loss: 0.0325 - val_loss: 0.0369\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 41us/step - loss: 0.0326 - val_loss: 0.0357\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 55us/step - loss: 0.0325 - val_loss: 0.0329\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 45us/step - loss: 0.0326 - val_loss: 0.0346\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 43us/step - loss: 0.0323 - val_loss: 0.0395\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 44us/step - loss: 0.0323 - val_loss: 0.0281\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 46us/step - loss: 0.0327 - val_loss: 0.0292\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 51us/step - loss: 0.0326 - val_loss: 0.0228\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 46us/step - loss: 0.0327 - val_loss: 0.0270\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 43us/step - loss: 0.0325 - val_loss: 0.0324\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 38us/step - loss: 0.0328 - val_loss: 0.0320\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 40us/step - loss: 0.0325 - val_loss: 0.0284\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 56us/step - loss: 0.0325 - val_loss: 0.0297\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 40us/step - loss: 0.0323 - val_loss: 0.0315\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 31us/step - loss: 0.0325 - val_loss: 0.0325\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 24us/step - loss: 0.0320 - val_loss: 0.0382\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 30us/step - loss: 0.0320 - val_loss: 0.0378\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 35us/step - loss: 0.0321 - val_loss: 0.0363\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 46us/step - loss: 0.0319 - val_loss: 0.0354\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 44us/step - loss: 0.0321 - val_loss: 0.0373\n",
      "best reward is :  [0.70157734 0.63197077 0.60048918 0.41956926 0.36333361]\n",
      "reward is :  [0.41956926 0.63197077 0.70157734 0.60048918 0.36193025]\n",
      "regrets is :  [ 0.28200807  0.         -0.10108816 -0.18091991  0.00140336] \n",
      "\n",
      "best reward is :  [0.4933899  0.49040112 0.42354701 0.39405268 0.39376332]\n",
      "reward is :  [0.15099926 0.10076624 0.19248426 0.09322045 0.25839631]\n",
      "regrets is :  [0.34239063 0.38963488 0.23106274 0.30083223 0.135367  ] \n",
      "\n",
      "best reward is :  [0.65678604 0.62299761 0.55666177 0.52875779 0.46795975]\n",
      "reward is :  [0.15772269 0.26789943 0.33750599 0.24736424 0.11206194]\n",
      "regrets is :  [0.49906335 0.35509818 0.21915578 0.28139355 0.35589781] \n",
      "\n",
      "best reward is :  [0.72349392 0.59063071 0.51993034 0.5065638  0.49347973]\n",
      "reward is :  [0.15687074 0.10906384 0.23733708 0.12763636 0.24458246]\n",
      "regrets is :  [0.56662318 0.48156686 0.28259327 0.37892743 0.24889727] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.0318 - val_loss: 0.0319\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 53us/step - loss: 0.0319 - val_loss: 0.0347\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 47us/step - loss: 0.0320 - val_loss: 0.0330\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 44us/step - loss: 0.0319 - val_loss: 0.0344\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.0319 - val_loss: 0.0352\n",
      "best reward is :  [0.69117663 0.54795975 0.53004999 0.48183078 0.47957375]\n",
      "reward is :  [0.17714286 0.1428777  0.21248426 0.09382251 0.30324913]\n",
      "regrets is :  [0.51403377 0.40508206 0.31756572 0.38800827 0.17632462] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 89us/step - loss: 0.0752 - val_loss: 0.0299\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0273 - val_loss: 0.0276\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0266 - val_loss: 0.0263\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0270 - val_loss: 0.0262\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0268 - val_loss: 0.0267\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0271 - val_loss: 0.0277\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0274 - val_loss: 0.0311\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0279 - val_loss: 0.0288\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0272 - val_loss: 0.0283\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0276 - val_loss: 0.0282\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0271 - val_loss: 0.0272\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0273 - val_loss: 0.0277\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0270 - val_loss: 0.0286\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0271 - val_loss: 0.0284\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 24us/step - loss: 0.0270 - val_loss: 0.0385\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 39us/step - loss: 0.0274 - val_loss: 0.0398\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 41us/step - loss: 0.0272 - val_loss: 0.0362\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 38us/step - loss: 0.0275 - val_loss: 0.0378\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 37us/step - loss: 0.0274 - val_loss: 0.0424\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 35us/step - loss: 0.0284 - val_loss: 0.0329\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 36us/step - loss: 0.0279 - val_loss: 0.0339\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 42us/step - loss: 0.0277 - val_loss: 0.0328\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.0280 - val_loss: 0.0333\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.0280 - val_loss: 0.0340\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 33us/step - loss: 0.0291 - val_loss: 0.0323\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 33us/step - loss: 0.0282 - val_loss: 0.0336\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 43us/step - loss: 0.0285 - val_loss: 0.0307\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 36us/step - loss: 0.0283 - val_loss: 0.0348\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 44us/step - loss: 0.0284 - val_loss: 0.0340\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 34us/step - loss: 0.0284 - val_loss: 0.0287\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 35us/step - loss: 0.0286 - val_loss: 0.0289\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 36us/step - loss: 0.0289 - val_loss: 0.0288\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 37us/step - loss: 0.0287 - val_loss: 0.0281\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 45us/step - loss: 0.0287 - val_loss: 0.0297\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 20us/step - loss: 0.0292 - val_loss: 0.0332\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 24us/step - loss: 0.0288 - val_loss: 0.0331\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 24us/step - loss: 0.0284 - val_loss: 0.0316\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.0286 - val_loss: 0.0300\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 28us/step - loss: 0.0289 - val_loss: 0.0358\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 31us/step - loss: 0.0293 - val_loss: 0.0349\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 27us/step - loss: 0.0289 - val_loss: 0.0381\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 24us/step - loss: 0.0294 - val_loss: 0.0369\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 26us/step - loss: 0.0289 - val_loss: 0.0365\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 25us/step - loss: 0.0289 - val_loss: 0.0374\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 36us/step - loss: 0.0293 - val_loss: 0.0342\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 38us/step - loss: 0.0297 - val_loss: 0.0320\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 37us/step - loss: 0.0294 - val_loss: 0.0326\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 38us/step - loss: 0.0292 - val_loss: 0.0335\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 37us/step - loss: 0.0296 - val_loss: 0.0313\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 32us/step - loss: 0.0297 - val_loss: 0.0328\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 36us/step - loss: 0.0296 - val_loss: 0.0332\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 39us/step - loss: 0.0298 - val_loss: 0.0329\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 37us/step - loss: 0.0296 - val_loss: 0.0291\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 37us/step - loss: 0.0296 - val_loss: 0.0302\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 25us/step - loss: 0.0295 - val_loss: 0.0282\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 25us/step - loss: 0.0295 - val_loss: 0.0306\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 24us/step - loss: 0.0292 - val_loss: 0.0321\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 23us/step - loss: 0.0294 - val_loss: 0.0299\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 29us/step - loss: 0.0293 - val_loss: 0.0293\n",
      "best reward is :  [0.59811577 0.54595115 0.51834084 0.4825327  0.47194607]\n",
      "reward is :  [0.14233944 0.2559487  0.41311182 0.02800467 0.41744653]\n",
      "regrets is :  [0.45577633 0.29000245 0.10522902 0.45452803 0.05449954] \n",
      "\n",
      "best reward is :  [0.49701741 0.48382979 0.47565646 0.3620472  0.35876971]\n",
      "reward is :  [0.3620472  0.47565646 0.48382979 0.32800467 0.32309775]\n",
      "regrets is :  [ 0.13497021  0.00817333 -0.00817333  0.03404254  0.03567196] \n",
      "\n",
      "best reward is :  [0.85590114 0.52550847 0.47226384 0.44839888 0.4134705 ]\n",
      "reward is :  [0.28512876 0.39873802 0.85590114 0.52550847 0.15464288]\n",
      "regrets is :  [ 0.57077238  0.12677045 -0.38363729 -0.07710959  0.25882762] \n",
      "\n",
      "best reward is :  [0.71293106 0.62258042 0.5189429  0.49756101 0.43597724]\n",
      "reward is :  [0.26216168 0.37577094 0.20782979 0.02800467 0.49756101]\n",
      "regrets is :  [ 0.45076937  0.24680947  0.31111312  0.46955634 -0.06158377] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.0296 - val_loss: 0.0290\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.0293 - val_loss: 0.0278\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.0295 - val_loss: 0.0329\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.0298 - val_loss: 0.0332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.0300 - val_loss: 0.0293\n",
      "best reward is :  [0.70440543 0.51214329 0.50308471 0.4820453  0.43586748]\n",
      "reward is :  [0.27548382 0.4159487  0.25311182 0.02800467 0.70440543]\n",
      "regrets is :  [ 0.42892162  0.09619459  0.24997289  0.45404063 -0.26853796] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 71us/step - loss: 0.0747 - val_loss: 0.0332\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0347 - val_loss: 0.0329\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0331 - val_loss: 0.0302\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0327 - val_loss: 0.0293\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0326 - val_loss: 0.0304\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0325 - val_loss: 0.0293\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0328 - val_loss: 0.0302\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0328 - val_loss: 0.0300\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0336 - val_loss: 0.0306\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0333 - val_loss: 0.0331\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0331 - val_loss: 0.0309\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0328 - val_loss: 0.0312\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0334 - val_loss: 0.0299\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0337 - val_loss: 0.0312\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 35us/step - loss: 0.0328 - val_loss: 0.0358\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 35us/step - loss: 0.0326 - val_loss: 0.0344\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 40us/step - loss: 0.0326 - val_loss: 0.0342\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 42us/step - loss: 0.0328 - val_loss: 0.0352\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 39us/step - loss: 0.0330 - val_loss: 0.0378\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 32us/step - loss: 0.0328 - val_loss: 0.0423\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.0331 - val_loss: 0.0408\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 37us/step - loss: 0.0336 - val_loss: 0.0392\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 44us/step - loss: 0.0326 - val_loss: 0.0419\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 44us/step - loss: 0.0327 - val_loss: 0.0438\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 35us/step - loss: 0.0336 - val_loss: 0.0337\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 40us/step - loss: 0.0333 - val_loss: 0.0242\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 41us/step - loss: 0.0334 - val_loss: 0.0353\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 37us/step - loss: 0.0336 - val_loss: 0.0298\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 40us/step - loss: 0.0330 - val_loss: 0.0308\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 36us/step - loss: 0.0329 - val_loss: 0.0252\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 40us/step - loss: 0.0332 - val_loss: 0.0262\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 24us/step - loss: 0.0330 - val_loss: 0.0268\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 24us/step - loss: 0.0336 - val_loss: 0.0232\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 25us/step - loss: 0.0331 - val_loss: 0.0264\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.0325 - val_loss: 0.0264\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.0323 - val_loss: 0.0255\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.0324 - val_loss: 0.0251\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.0333 - val_loss: 0.0268\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.0326 - val_loss: 0.0223\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 35us/step - loss: 0.0313 - val_loss: 0.0261\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 34us/step - loss: 0.0317 - val_loss: 0.0296\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 38us/step - loss: 0.0318 - val_loss: 0.0266\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 37us/step - loss: 0.0316 - val_loss: 0.0277\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 38us/step - loss: 0.0317 - val_loss: 0.0245\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 39us/step - loss: 0.0310 - val_loss: 0.0246\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 42us/step - loss: 0.0313 - val_loss: 0.0229\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 39us/step - loss: 0.0312 - val_loss: 0.0239\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 38us/step - loss: 0.0316 - val_loss: 0.0294\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 36us/step - loss: 0.0312 - val_loss: 0.0261\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 20us/step - loss: 0.0307 - val_loss: 0.0245\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 21us/step - loss: 0.0309 - val_loss: 0.0225\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 25us/step - loss: 0.0310 - val_loss: 0.0234\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 26us/step - loss: 0.0310 - val_loss: 0.0251\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 26us/step - loss: 0.0311 - val_loss: 0.0252\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 29us/step - loss: 0.0303 - val_loss: 0.0280\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 24us/step - loss: 0.0302 - val_loss: 0.0285\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 28us/step - loss: 0.0304 - val_loss: 0.0293\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 28us/step - loss: 0.0303 - val_loss: 0.0300\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 27us/step - loss: 0.0300 - val_loss: 0.0294\n",
      "best reward is :  [0.70799751 0.55461947 0.48127184 0.46571558 0.44519691]\n",
      "reward is :  [0.26640511 0.55461947 0.37344538 0.26665922 0.34577295]\n",
      "regrets is :  [0.4415924  0.         0.10782646 0.19905636 0.09942396] \n",
      "\n",
      "best reward is :  [0.60950129 0.58267854 0.45532224 0.43733333 0.43137255]\n",
      "reward is :  [0.27557949 0.18560334 0.21587179 0.04665922 0.30838533]\n",
      "regrets is :  [0.3339218  0.39707521 0.23945046 0.39067412 0.12298722] \n",
      "\n",
      "best reward is :  [0.66817108 0.65043827 0.59547003 0.59266076 0.58689841]\n",
      "reward is :  [0.66817108 0.5125668  0.59266076 0.46215115 0.65043827]\n",
      "regrets is :  [ 0.          0.13787147  0.00280927  0.13050961 -0.06353986] \n",
      "\n",
      "best reward is :  [0.74950129 0.5817005  0.45354004 0.44256858 0.44016615]\n",
      "reward is :  [0.28388938 0.18290374 0.25829819 0.04665922 0.34615657]\n",
      "regrets is :  [0.46561191 0.39879676 0.19524184 0.39590936 0.09400958] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.0304 - val_loss: 0.0245\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.0302 - val_loss: 0.0255\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.0298 - val_loss: 0.0251\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.0302 - val_loss: 0.0256\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.0303 - val_loss: 0.0279\n",
      "best reward is :  [0.55492205 0.49714762 0.48865927 0.47642734 0.39344538]\n",
      "reward is :  [0.19022375 0.2239015  0.39344538 0.27594125 0.14528298]\n",
      "regrets is :  [0.3646983  0.27324612 0.09521389 0.20048609 0.2481624 ] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 87us/step - loss: 0.1047 - val_loss: 0.0368\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0335 - val_loss: 0.0303\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0318 - val_loss: 0.0302\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0318 - val_loss: 0.0304\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0314 - val_loss: 0.0301\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0315 - val_loss: 0.0301\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0318 - val_loss: 0.0298\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0318 - val_loss: 0.0309\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0318 - val_loss: 0.0297\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0318 - val_loss: 0.0305\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0314 - val_loss: 0.0294\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0316 - val_loss: 0.0297\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0324 - val_loss: 0.0307\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0316 - val_loss: 0.0295\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0319 - val_loss: 0.0306\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0318 - val_loss: 0.0307\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0323 - val_loss: 0.0297\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0318 - val_loss: 0.0297\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0320 - val_loss: 0.0314\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0320 - val_loss: 0.0298\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0318 - val_loss: 0.0296\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 26us/step - loss: 0.0322 - val_loss: 0.0386\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 41us/step - loss: 0.0317 - val_loss: 0.0509\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 39us/step - loss: 0.0317 - val_loss: 0.0636\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 37us/step - loss: 0.0315 - val_loss: 0.0549\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 39us/step - loss: 0.0320 - val_loss: 0.0465\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 23us/step - loss: 0.0324 - val_loss: 0.0358\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.0327 - val_loss: 0.0369\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 42us/step - loss: 0.0329 - val_loss: 0.0353\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 42us/step - loss: 0.0326 - val_loss: 0.0318\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.0332 - val_loss: 0.0394\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 33us/step - loss: 0.0331 - val_loss: 0.0309\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 43us/step - loss: 0.0327 - val_loss: 0.0349\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 41us/step - loss: 0.0325 - val_loss: 0.0311\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 41us/step - loss: 0.0327 - val_loss: 0.0323\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 45us/step - loss: 0.0325 - val_loss: 0.0339\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 34us/step - loss: 0.0324 - val_loss: 0.0273\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 34us/step - loss: 0.0324 - val_loss: 0.0290\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 40us/step - loss: 0.0326 - val_loss: 0.0327\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 42us/step - loss: 0.0324 - val_loss: 0.0325\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 33us/step - loss: 0.0327 - val_loss: 0.0314\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.0323 - val_loss: 0.0308\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.0319 - val_loss: 0.0266\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 26us/step - loss: 0.0323 - val_loss: 0.0310\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 27us/step - loss: 0.0323 - val_loss: 0.0271\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 27us/step - loss: 0.0322 - val_loss: 0.0297\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 27us/step - loss: 0.0320 - val_loss: 0.0285\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 38us/step - loss: 0.0320 - val_loss: 0.0292\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 29us/step - loss: 0.0322 - val_loss: 0.0283\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 26us/step - loss: 0.0324 - val_loss: 0.0274\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 36us/step - loss: 0.0323 - val_loss: 0.0287\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 34us/step - loss: 0.0318 - val_loss: 0.0264\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 37us/step - loss: 0.0316 - val_loss: 0.0221\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 52us/step - loss: 0.0317 - val_loss: 0.0267\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 48us/step - loss: 0.0318 - val_loss: 0.0274\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 36us/step - loss: 0.0318 - val_loss: 0.0269\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 21us/step - loss: 0.0317 - val_loss: 0.0257\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 25us/step - loss: 0.0321 - val_loss: 0.0227\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 24us/step - loss: 0.0318 - val_loss: 0.0243\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 28us/step - loss: 0.0315 - val_loss: 0.0241\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 26us/step - loss: 0.0319 - val_loss: 0.0223\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 37us/step - loss: 0.0310 - val_loss: 0.0258\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 37us/step - loss: 0.0312 - val_loss: 0.0254\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 37us/step - loss: 0.0312 - val_loss: 0.0270\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 37us/step - loss: 0.0312 - val_loss: 0.0228\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 44us/step - loss: 0.0308 - val_loss: 0.0247\n",
      "best reward is :  [0.59928494 0.56362718 0.54056943 0.43265101 0.42275744]\n",
      "reward is :  [0.26502173 0.08843129 0.34736829 0.0595217  0.26070979]\n",
      "regrets is :  [0.33426321 0.47519589 0.19320114 0.37312931 0.16204765] \n",
      "\n",
      "best reward is :  [0.73515368 0.66242641 0.65489861 0.55695005 0.52151175]\n",
      "reward is :  [0.66242641 0.48817983 0.73515368 0.34194811 0.55695005]\n",
      "regrets is :  [ 0.07272727  0.17424658 -0.08025507  0.21500194 -0.03543829] \n",
      "\n",
      "best reward is :  [0.7225073  0.56001288 0.53499365 0.43928494 0.4325346 ]\n",
      "reward is :  [0.43098387 0.31060624 0.17582128 0.25746903 0.09761765]\n",
      "regrets is :  [0.29152343 0.24940664 0.35917236 0.18181591 0.33491695] \n",
      "\n",
      "best reward is :  [0.68046621 0.67366563 0.6063929  0.51391261 0.50460053]\n",
      "reward is :  [0.67366563 0.48039444 0.6063929  0.49318733 0.42070979]\n",
      "regrets is :  [0.00680057 0.19327119 0.         0.02072528 0.08389074] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 0s 33us/step - loss: 0.0305 - val_loss: 0.0226\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.0304 - val_loss: 0.0184\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.0305 - val_loss: 0.0203\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.0306 - val_loss: 0.0213\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 43us/step - loss: 0.0308 - val_loss: 0.0200\n",
      "best reward is :  [0.55085989 0.46150983 0.39974182 0.39083195 0.38897959]\n",
      "reward is :  [0.26828427 0.11941906 0.34101154 0.08780597 0.25805758]\n",
      "regrets is :  [0.28257562 0.34209077 0.05873028 0.30302597 0.13092201] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 80us/step - loss: 0.0786 - val_loss: 0.0324\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0291 - val_loss: 0.0311\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0287 - val_loss: 0.0306\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0285 - val_loss: 0.0314\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0282 - val_loss: 0.0311\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0284 - val_loss: 0.0301\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0284 - val_loss: 0.0292\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0285 - val_loss: 0.0294\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0295 - val_loss: 0.0313\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0285 - val_loss: 0.0290\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0289 - val_loss: 0.0317\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0286 - val_loss: 0.0318\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0286 - val_loss: 0.0344\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0293 - val_loss: 0.0330\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0286 - val_loss: 0.0302\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0286 - val_loss: 0.0327\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0285 - val_loss: 0.0301\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0286 - val_loss: 0.0305\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0289 - val_loss: 0.0347\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0296 - val_loss: 0.0354\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 36us/step - loss: 0.0289 - val_loss: 0.0390\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 40us/step - loss: 0.0289 - val_loss: 0.0347\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 40us/step - loss: 0.0293 - val_loss: 0.0379\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 40us/step - loss: 0.0289 - val_loss: 0.0352\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 38us/step - loss: 0.0286 - val_loss: 0.0368\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 22us/step - loss: 0.0293 - val_loss: 0.0490\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.0299 - val_loss: 0.0494\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 36us/step - loss: 0.0293 - val_loss: 0.0482\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.0296 - val_loss: 0.0410\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.0293 - val_loss: 0.0460\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 37us/step - loss: 0.0305 - val_loss: 0.0507\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 34us/step - loss: 0.0307 - val_loss: 0.0409\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 37us/step - loss: 0.0307 - val_loss: 0.0555\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 42us/step - loss: 0.0310 - val_loss: 0.0471\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 35us/step - loss: 0.0303 - val_loss: 0.0368\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 38us/step - loss: 0.0314 - val_loss: 0.0316\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 39us/step - loss: 0.0315 - val_loss: 0.0322\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 38us/step - loss: 0.0318 - val_loss: 0.0333\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 37us/step - loss: 0.0320 - val_loss: 0.0345\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 42us/step - loss: 0.0318 - val_loss: 0.0358\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.0315 - val_loss: 0.0339\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.0314 - val_loss: 0.0322\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 44us/step - loss: 0.0317 - val_loss: 0.0353\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.0319 - val_loss: 0.0313\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 43us/step - loss: 0.0320 - val_loss: 0.0335\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 32us/step - loss: 0.0322 - val_loss: 0.0313\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 37us/step - loss: 0.0317 - val_loss: 0.0328\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 38us/step - loss: 0.0320 - val_loss: 0.0294\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 45us/step - loss: 0.0322 - val_loss: 0.0333\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 39us/step - loss: 0.0318 - val_loss: 0.0311\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 25us/step - loss: 0.0319 - val_loss: 0.0309\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 34us/step - loss: 0.0322 - val_loss: 0.0293\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 36us/step - loss: 0.0320 - val_loss: 0.0274\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 35us/step - loss: 0.0315 - val_loss: 0.0345\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 35us/step - loss: 0.0320 - val_loss: 0.0337\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 33us/step - loss: 0.0318 - val_loss: 0.0283\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 27us/step - loss: 0.0321 - val_loss: 0.0329\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 26us/step - loss: 0.0314 - val_loss: 0.0341\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 26us/step - loss: 0.0317 - val_loss: 0.0347\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 27us/step - loss: 0.0316 - val_loss: 0.0303\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 34us/step - loss: 0.0315 - val_loss: 0.0289\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 40us/step - loss: 0.0315 - val_loss: 0.0285\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 36us/step - loss: 0.0316 - val_loss: 0.0326\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 39us/step - loss: 0.0315 - val_loss: 0.0284\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 43us/step - loss: 0.0313 - val_loss: 0.0349\n",
      "best reward is :  [0.68907008 0.54733175 0.52849417 0.5104842  0.50469959]\n",
      "reward is :  [0.10957051 0.23053475 0.46928203 0.07299744 0.23041888]\n",
      "regrets is :  [0.57949956 0.316797   0.05921213 0.43748676 0.27428071] \n",
      "\n",
      "best reward is :  [0.60541966 0.58826837 0.58079954 0.56390232 0.5258856 ]\n",
      "reward is :  [0.10091904 0.26191694 0.45366563 0.07931412 0.13794877]\n",
      "regrets is :  [0.50450062 0.32635143 0.12713391 0.4845882  0.38793682] \n",
      "\n",
      "best reward is :  [0.56762422 0.47666642 0.46928203 0.42087664 0.38465308]\n",
      "reward is :  [0.08724556 0.2572411  0.46928203 0.10544986 0.17970092]\n",
      "regrets is :  [0.48037866 0.21942532 0.         0.31542678 0.20495216] \n",
      "\n",
      "best reward is :  [0.64951469 0.49009889 0.47057444 0.3883394  0.37494179]\n",
      "reward is :  [0.37494179 0.47057444 0.64951469 0.31410736 0.37274201]\n",
      "regrets is :  [ 0.27457291  0.01952445 -0.17894026  0.07423204  0.00219978] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 0s 31us/step - loss: 0.0313 - val_loss: 0.0232\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.0314 - val_loss: 0.0247\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.0311 - val_loss: 0.0344\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.0310 - val_loss: 0.0346\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.0312 - val_loss: 0.0283\n",
      "best reward is :  [0.56983571 0.5573988  0.3958499  0.38996543 0.38338636]\n",
      "reward is :  [0.27874489 0.06853501 0.27618136 0.27178423 0.33041888]\n",
      "regrets is :  [0.29109082 0.48886379 0.11966853 0.1181812  0.05296748] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 88us/step - loss: 0.0812 - val_loss: 0.0327\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0307 - val_loss: 0.0307\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0296 - val_loss: 0.0302\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0297 - val_loss: 0.0298\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0298 - val_loss: 0.0307\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0296 - val_loss: 0.0317\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0302 - val_loss: 0.0305\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0303 - val_loss: 0.0308\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0298 - val_loss: 0.0302\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0303 - val_loss: 0.0304\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0305 - val_loss: 0.0336\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0304 - val_loss: 0.0298\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0297 - val_loss: 0.0299\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0295 - val_loss: 0.0299\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0294 - val_loss: 0.0311\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0301 - val_loss: 0.0298\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0298 - val_loss: 0.0300\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0302 - val_loss: 0.0310\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0305 - val_loss: 0.0307\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0302 - val_loss: 0.0303\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 37us/step - loss: 0.0296 - val_loss: 0.0329\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 42us/step - loss: 0.0302 - val_loss: 0.0375\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 42us/step - loss: 0.0298 - val_loss: 0.0411\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 37us/step - loss: 0.0298 - val_loss: 0.0341\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 38us/step - loss: 0.0300 - val_loss: 0.0420\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 35us/step - loss: 0.0310 - val_loss: 0.0426\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 37us/step - loss: 0.0312 - val_loss: 0.0315\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 37us/step - loss: 0.0306 - val_loss: 0.0365\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 30us/step - loss: 0.0306 - val_loss: 0.0404\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 23us/step - loss: 0.0310 - val_loss: 0.0359\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 35us/step - loss: 0.0314 - val_loss: 0.0330\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 37us/step - loss: 0.0307 - val_loss: 0.0346\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 40us/step - loss: 0.0306 - val_loss: 0.0300\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 43us/step - loss: 0.0312 - val_loss: 0.0311\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 43us/step - loss: 0.0308 - val_loss: 0.0291\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 33us/step - loss: 0.0309 - val_loss: 0.0327\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 36us/step - loss: 0.0309 - val_loss: 0.0290\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 43us/step - loss: 0.0315 - val_loss: 0.0206\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 38us/step - loss: 0.0308 - val_loss: 0.0280\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 39us/step - loss: 0.0311 - val_loss: 0.0259\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 32us/step - loss: 0.0306 - val_loss: 0.0368\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.0306 - val_loss: 0.0351\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 44us/step - loss: 0.0303 - val_loss: 0.0370\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.0308 - val_loss: 0.0319\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.0305 - val_loss: 0.0333\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 32us/step - loss: 0.0308 - val_loss: 0.0316\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 42us/step - loss: 0.0304 - val_loss: 0.0342\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 40us/step - loss: 0.0304 - val_loss: 0.0314\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 37us/step - loss: 0.0305 - val_loss: 0.0304\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 42us/step - loss: 0.0306 - val_loss: 0.0304\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 33us/step - loss: 0.0306 - val_loss: 0.0246\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 30us/step - loss: 0.0307 - val_loss: 0.0239\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 41us/step - loss: 0.0308 - val_loss: 0.0264\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 37us/step - loss: 0.0309 - val_loss: 0.0245\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 42us/step - loss: 0.0306 - val_loss: 0.0240\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 35us/step - loss: 0.0303 - val_loss: 0.0196\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 46us/step - loss: 0.0303 - val_loss: 0.0253\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 39us/step - loss: 0.0303 - val_loss: 0.0290\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 37us/step - loss: 0.0304 - val_loss: 0.0262\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 27us/step - loss: 0.0305 - val_loss: 0.0232\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 33us/step - loss: 0.0302 - val_loss: 0.0268\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 34us/step - loss: 0.0300 - val_loss: 0.0198\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 37us/step - loss: 0.0299 - val_loss: 0.0203\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 43us/step - loss: 0.0299 - val_loss: 0.0245\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 38us/step - loss: 0.0300 - val_loss: 0.0221\n",
      "best reward is :  [0.57133615 0.56729453 0.52373431 0.50690165 0.50429403]\n",
      "reward is :  [0.28535574 0.08806872 0.02886414 0.03437666 0.13956972]\n",
      "regrets is :  [0.28598041 0.47922581 0.49487017 0.47252499 0.36472431] \n",
      "\n",
      "best reward is :  [0.80485281 0.62804229 0.57449513 0.48942308 0.47369159]\n",
      "reward is :  [0.80485281 0.57449513 0.40252977 0.62804229 0.28544887]\n",
      "regrets is :  [ 0.          0.05354716  0.17196535 -0.13861921  0.18824273] \n",
      "\n",
      "best reward is :  [0.78       0.69605654 0.68158893 0.62886414 0.58780237]\n",
      "reward is :  [0.78       0.44539085 0.62886414 0.33437666 0.04946671]\n",
      "regrets is :  [0.         0.25066569 0.05272479 0.29448748 0.53833566] \n",
      "\n",
      "best reward is :  [0.48614162 0.44647809 0.44341263 0.44059605 0.4148072 ]\n",
      "reward is :  [0.36       0.18539085 0.23421988 0.08804229 0.44059605]\n",
      "regrets is :  [ 0.12614162  0.26108724  0.20919275  0.35255376 -0.02578886] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.0294 - val_loss: 0.0228\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.0294 - val_loss: 0.0241\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 34us/step - loss: 0.0294 - val_loss: 0.0239\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.0297 - val_loss: 0.0211\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.0295 - val_loss: 0.0250\n",
      "best reward is :  [0.50459422 0.46       0.44987809 0.38299649 0.36259259]\n",
      "reward is :  [0.46       0.24460623 0.04374831 0.26365869 0.44987809]\n",
      "regrets is :  [ 0.04459422  0.21539377  0.40612977  0.1193378  -0.08728549] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 90us/step - loss: 0.0787 - val_loss: 0.0286\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0272 - val_loss: 0.0266\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0260 - val_loss: 0.0296\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0260 - val_loss: 0.0272\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0257 - val_loss: 0.0271\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0258 - val_loss: 0.0279\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0262 - val_loss: 0.0276\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0265 - val_loss: 0.0291\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0264 - val_loss: 0.0276\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0260 - val_loss: 0.0278\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0260 - val_loss: 0.0281\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0267 - val_loss: 0.0271\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 40us/step - loss: 0.0264 - val_loss: 0.0366\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 40us/step - loss: 0.0263 - val_loss: 0.0348\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 37us/step - loss: 0.0269 - val_loss: 0.0315\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 38us/step - loss: 0.0264 - val_loss: 0.0348\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 40us/step - loss: 0.0265 - val_loss: 0.0399\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 33us/step - loss: 0.0268 - val_loss: 0.0338\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.0267 - val_loss: 0.0311\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.0270 - val_loss: 0.0253\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 37us/step - loss: 0.0271 - val_loss: 0.0288\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.0271 - val_loss: 0.0398\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 32us/step - loss: 0.0276 - val_loss: 0.0169\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 34us/step - loss: 0.0275 - val_loss: 0.0224\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 44us/step - loss: 0.0271 - val_loss: 0.0223\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 41us/step - loss: 0.0271 - val_loss: 0.0221\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 43us/step - loss: 0.0275 - val_loss: 0.0284\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 34us/step - loss: 0.0266 - val_loss: 0.0216\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 37us/step - loss: 0.0262 - val_loss: 0.0187\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 45us/step - loss: 0.0265 - val_loss: 0.0210\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 44us/step - loss: 0.0267 - val_loss: 0.0255\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 34us/step - loss: 0.0266 - val_loss: 0.0239\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 31us/step - loss: 0.0260 - val_loss: 0.0184\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.0258 - val_loss: 0.0255\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 42us/step - loss: 0.0259 - val_loss: 0.0233\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0260 - val_loss: 0.0180\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 27us/step - loss: 0.0264 - val_loss: 0.0203\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 40us/step - loss: 0.0259 - val_loss: 0.0189\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 38us/step - loss: 0.0257 - val_loss: 0.0180\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 36us/step - loss: 0.0253 - val_loss: 0.0202\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 37us/step - loss: 0.0256 - val_loss: 0.0217\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 39us/step - loss: 0.0256 - val_loss: 0.0201\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 30us/step - loss: 0.0258 - val_loss: 0.0196\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 37us/step - loss: 0.0251 - val_loss: 0.0175\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 36us/step - loss: 0.0256 - val_loss: 0.0160\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 33us/step - loss: 0.0249 - val_loss: 0.0180\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 26us/step - loss: 0.0252 - val_loss: 0.0204\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 23us/step - loss: 0.0247 - val_loss: 0.0148\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 22us/step - loss: 0.0249 - val_loss: 0.0188\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 26us/step - loss: 0.0246 - val_loss: 0.0189\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 25us/step - loss: 0.0248 - val_loss: 0.0184\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 24us/step - loss: 0.0248 - val_loss: 0.0148\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 34us/step - loss: 0.0241 - val_loss: 0.0148\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 39us/step - loss: 0.0243 - val_loss: 0.0161\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 29us/step - loss: 0.0242 - val_loss: 0.0144\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 26us/step - loss: 0.0244 - val_loss: 0.0146\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 26us/step - loss: 0.0243 - val_loss: 0.0152\n",
      "best reward is :  [0.76178462 0.59435986 0.54931812 0.54       0.49797275]\n",
      "reward is :  [0.54       0.59435986 0.49797275 0.54931812 0.76178462]\n",
      "regrets is :  [ 0.22178462  0.          0.05134537 -0.00931812 -0.26381186] \n",
      "\n",
      "best reward is :  [0.50158943 0.48471233 0.4694382  0.4539645  0.45300613]\n",
      "reward is :  [0.43207135 0.37314919 0.30355684 0.06407168 0.15858798]\n",
      "regrets is :  [0.06951808 0.11156314 0.16588136 0.38989282 0.29441816] \n",
      "\n",
      "best reward is :  [0.4173124  0.40455314 0.39943305 0.38296434 0.36      ]\n",
      "reward is :  [0.36       0.26593066 0.14065062 0.32178824 0.32446248]\n",
      "regrets is :  [0.0573124  0.13862248 0.25878243 0.0611761  0.03553752] \n",
      "\n",
      "best reward is :  [0.6357108  0.58786552 0.58       0.56452438 0.54696255]\n",
      "reward is :  [0.58       0.40107784 0.54696255 0.33077803 0.51077441]\n",
      "regrets is :  [0.0557108  0.18678768 0.03303745 0.23374635 0.03618814] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.0240 - val_loss: 0.0160\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.0235 - val_loss: 0.0194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.0239 - val_loss: 0.0165\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.0238 - val_loss: 0.0143\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.0238 - val_loss: 0.0176\n",
      "best reward is :  [0.7350469  0.63686528 0.62315587 0.58714035 0.57632919]\n",
      "reward is :  [0.54928203 0.46350425 0.48039916 0.43107027 0.58714035]\n",
      "regrets is :  [ 0.18576486  0.17336103  0.14275671  0.15607008 -0.01081116] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 87us/step - loss: 0.1124 - val_loss: 0.0383\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0336 - val_loss: 0.0319\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0312 - val_loss: 0.0307\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0311 - val_loss: 0.0309\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0312 - val_loss: 0.0308\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0309 - val_loss: 0.0315\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0312 - val_loss: 0.0307\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0312 - val_loss: 0.0301\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0309 - val_loss: 0.0301\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0312 - val_loss: 0.0326\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0315 - val_loss: 0.0315\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0317 - val_loss: 0.0303\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0318 - val_loss: 0.0314\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0310 - val_loss: 0.0312\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0312 - val_loss: 0.0306\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0321 - val_loss: 0.0356\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0313 - val_loss: 0.0303\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0310 - val_loss: 0.0327\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0311 - val_loss: 0.0308\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 33us/step - loss: 0.0310 - val_loss: 0.0425\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 39us/step - loss: 0.0310 - val_loss: 0.0361\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 39us/step - loss: 0.0313 - val_loss: 0.0356\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 42us/step - loss: 0.0313 - val_loss: 0.0362\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 41us/step - loss: 0.0312 - val_loss: 0.0373\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 30us/step - loss: 0.0315 - val_loss: 0.0347\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 37us/step - loss: 0.0320 - val_loss: 0.0360\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 49us/step - loss: 0.0321 - val_loss: 0.0322\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 43us/step - loss: 0.0318 - val_loss: 0.0391\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.0315 - val_loss: 0.0330\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 33us/step - loss: 0.0320 - val_loss: 0.0318\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 40us/step - loss: 0.0321 - val_loss: 0.0334\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 45us/step - loss: 0.0319 - val_loss: 0.0283\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 39us/step - loss: 0.0318 - val_loss: 0.0305\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 39us/step - loss: 0.0318 - val_loss: 0.0301\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 22us/step - loss: 0.0329 - val_loss: 0.0448\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 20us/step - loss: 0.0321 - val_loss: 0.0372\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 23us/step - loss: 0.0316 - val_loss: 0.0351\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 24us/step - loss: 0.0318 - val_loss: 0.0395\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 25us/step - loss: 0.0319 - val_loss: 0.0370\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 33us/step - loss: 0.0318 - val_loss: 0.0300\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.0318 - val_loss: 0.0340\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.0319 - val_loss: 0.0319\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.0320 - val_loss: 0.0370\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 42us/step - loss: 0.0318 - val_loss: 0.0323\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 33us/step - loss: 0.0318 - val_loss: 0.0387\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 36us/step - loss: 0.0324 - val_loss: 0.0314\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 37us/step - loss: 0.0323 - val_loss: 0.0349\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 38us/step - loss: 0.0321 - val_loss: 0.0343\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 38us/step - loss: 0.0319 - val_loss: 0.0316\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 35us/step - loss: 0.0320 - val_loss: 0.0349\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 33us/step - loss: 0.0319 - val_loss: 0.0288\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 30us/step - loss: 0.0320 - val_loss: 0.0354\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 43us/step - loss: 0.0319 - val_loss: 0.0328\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 32us/step - loss: 0.0321 - val_loss: 0.0322\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 23us/step - loss: 0.0322 - val_loss: 0.0268\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 29us/step - loss: 0.0319 - val_loss: 0.0280\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 34us/step - loss: 0.0320 - val_loss: 0.0215\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 39us/step - loss: 0.0320 - val_loss: 0.0259\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 42us/step - loss: 0.0321 - val_loss: 0.0239\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 36us/step - loss: 0.0317 - val_loss: 0.0233\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 29us/step - loss: 0.0318 - val_loss: 0.0232\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 27us/step - loss: 0.0318 - val_loss: 0.0252\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 29us/step - loss: 0.0318 - val_loss: 0.0198\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 26us/step - loss: 0.0316 - val_loss: 0.0220\n",
      "best reward is :  [0.64100202 0.55194045 0.51119466 0.49989621 0.44708331]\n",
      "reward is :  [0.38766273 0.25227476 0.38534062 0.0696938  0.07504247]\n",
      "regrets is :  [0.25333929 0.29966568 0.12585404 0.43020242 0.37204084] \n",
      "\n",
      "best reward is :  [0.76708331 0.69124117 0.68572738 0.63189501 0.62295817]\n",
      "reward is :  [0.21209195 0.09145476 0.22534062 0.05445378 0.24380543]\n",
      "regrets is :  [0.55499136 0.59978642 0.46038676 0.57744123 0.37915274] \n",
      "\n",
      "best reward is :  [0.60280992 0.58291421 0.5055969  0.47105929 0.40027149]\n",
      "reward is :  [0.60280992 0.5055969  0.58291421 0.33240111 0.40027149]\n",
      "regrets is :  [ 0.          0.07731732 -0.07731732  0.13865818  0.        ] \n",
      "\n",
      "best reward is :  [0.59575677 0.56587639 0.53258883 0.52616216 0.4819922 ]\n",
      "reward is :  [0.34816565 0.25524184 0.34584354 0.09980952 0.06027149]\n",
      "regrets is :  [0.24759112 0.31063455 0.18674529 0.42635264 0.4217207 ] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 0s 34us/step - loss: 0.0310 - val_loss: 0.0270\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 1s 71us/step - loss: 0.0311 - val_loss: 0.0272\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.0313 - val_loss: 0.0237\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.0312 - val_loss: 0.0225\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.0312 - val_loss: 0.0261\n",
      "best reward is :  [0.44268501 0.4361808  0.4098957  0.39366972 0.3803492 ]\n",
      "reward is :  [0.17745093 0.10111782 0.15878763 0.25980952 0.0758511 ]\n",
      "regrets is :  [0.26523408 0.33506298 0.25110807 0.1338602  0.3044981 ] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 1s 187us/step - loss: 0.0892 - val_loss: 0.0367\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0314 - val_loss: 0.0344\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 77us/step - loss: 0.0305 - val_loss: 0.0339\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 71us/step - loss: 0.0308 - val_loss: 0.0351\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 50us/step - loss: 0.0309 - val_loss: 0.0345\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0302 - val_loss: 0.0362\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0306 - val_loss: 0.0337\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 54us/step - loss: 0.0307 - val_loss: 0.0351\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0305 - val_loss: 0.0367\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 58us/step - loss: 0.0307 - val_loss: 0.0344\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0306 - val_loss: 0.0338\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 54us/step - loss: 0.0305 - val_loss: 0.0343\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0304 - val_loss: 0.0331\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0308 - val_loss: 0.0341\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 67us/step - loss: 0.0311 - val_loss: 0.0346\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0307 - val_loss: 0.0336\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0306 - val_loss: 0.0343\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0308 - val_loss: 0.0332\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0307 - val_loss: 0.0332\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0308 - val_loss: 0.0332\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0307 - val_loss: 0.0341\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0312 - val_loss: 0.0352\n",
      "Epoch 23/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0306 - val_loss: 0.0343\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 32us/step - loss: 0.0310 - val_loss: 0.0455\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 40us/step - loss: 0.0310 - val_loss: 0.0440\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 42us/step - loss: 0.0309 - val_loss: 0.0473\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 36us/step - loss: 0.0314 - val_loss: 0.0418\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 43us/step - loss: 0.0310 - val_loss: 0.0410\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 49us/step - loss: 0.0324 - val_loss: 0.0306\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.0318 - val_loss: 0.0316\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 50us/step - loss: 0.0318 - val_loss: 0.0328\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 49us/step - loss: 0.0328 - val_loss: 0.0276\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 46us/step - loss: 0.0323 - val_loss: 0.0311\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 69us/step - loss: 0.0317 - val_loss: 0.0365\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 45us/step - loss: 0.0319 - val_loss: 0.0422\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 31us/step - loss: 0.0318 - val_loss: 0.0359\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 28us/step - loss: 0.0322 - val_loss: 0.0361\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 36us/step - loss: 0.0321 - val_loss: 0.0372\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 37us/step - loss: 0.0328 - val_loss: 0.0349\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 38us/step - loss: 0.0322 - val_loss: 0.0353\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 57us/step - loss: 0.0320 - val_loss: 0.0346\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 58us/step - loss: 0.0321 - val_loss: 0.0341\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 55us/step - loss: 0.0326 - val_loss: 0.0331\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 22us/step - loss: 0.0324 - val_loss: 0.0364\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.0322 - val_loss: 0.0401\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.0323 - val_loss: 0.0387\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 44us/step - loss: 0.0321 - val_loss: 0.0358\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 44us/step - loss: 0.0319 - val_loss: 0.0365\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 38us/step - loss: 0.0322 - val_loss: 0.0391\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 44us/step - loss: 0.0324 - val_loss: 0.0402\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 47us/step - loss: 0.0323 - val_loss: 0.0362\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 45us/step - loss: 0.0324 - val_loss: 0.0353\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 40us/step - loss: 0.0321 - val_loss: 0.0358\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 35us/step - loss: 0.0325 - val_loss: 0.0331\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 53us/step - loss: 0.0329 - val_loss: 0.0426\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 53us/step - loss: 0.0331 - val_loss: 0.0329\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 44us/step - loss: 0.0328 - val_loss: 0.0333\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 41us/step - loss: 0.0326 - val_loss: 0.0341\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 26us/step - loss: 0.0326 - val_loss: 0.0271\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 26us/step - loss: 0.0325 - val_loss: 0.0283\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 38us/step - loss: 0.0326 - val_loss: 0.0284\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 39us/step - loss: 0.0328 - val_loss: 0.0293\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 46us/step - loss: 0.0327 - val_loss: 0.0300\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 40us/step - loss: 0.0322 - val_loss: 0.0285\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 43us/step - loss: 0.0323 - val_loss: 0.0298\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 49us/step - loss: 0.0323 - val_loss: 0.0284\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 45us/step - loss: 0.0321 - val_loss: 0.0280\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8550/8550 [==============================] - 0s 41us/step - loss: 0.0322 - val_loss: 0.0274\n",
      "best reward is :  [0.58491849 0.54673581 0.52533641 0.41548387 0.40625532]\n",
      "reward is :  [0.06433898 0.0344086  0.06317377 0.21366563 0.09333303]\n",
      "regrets is :  [0.5205795  0.51232721 0.46216264 0.20181824 0.31292229] \n",
      "\n",
      "best reward is :  [0.64736842 0.64620321 0.63444995 0.6344086  0.47218658]\n",
      "reward is :  [0.64736842 0.6344086  0.64620321 0.46928203 0.63444995]\n",
      "regrets is :  [ 0.          0.01179461 -0.01175326  0.16512657 -0.16226337] \n",
      "\n",
      "best reward is :  [0.72435533 0.6873428  0.63965217 0.62373193 0.59546914]\n",
      "reward is :  [0.23565269 0.22269287 0.22517687 0.44642489 0.30339968]\n",
      "regrets is :  [0.48870264 0.46464993 0.4144753  0.17730704 0.29206946] \n",
      "\n",
      "best reward is :  [0.56206879 0.54723281 0.47272416 0.47153291 0.46620321]\n",
      "reward is :  [0.47272416 0.4544086  0.46620321 0.28535574 0.44199752]\n",
      "regrets is :  [0.08934463 0.09282421 0.00652095 0.18617717 0.02420569] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 18us/step - loss: 0.0323 - val_loss: 0.0305\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.0321 - val_loss: 0.0326\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.0322 - val_loss: 0.0361\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.0321 - val_loss: 0.0323\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.0321 - val_loss: 0.0349\n",
      "best reward is :  [0.72031112 0.6615765  0.5856888  0.56617764 0.55192304]\n",
      "reward is :  [0.24531575 0.22769061 0.22471961 0.35328201 0.25358422]\n",
      "regrets is :  [0.47499537 0.43388589 0.36096919 0.21289563 0.29833882] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 89us/step - loss: 0.0779 - val_loss: 0.0304\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0299 - val_loss: 0.0303\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0289 - val_loss: 0.0313\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0288 - val_loss: 0.0298\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0285 - val_loss: 0.0290\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0286 - val_loss: 0.0296\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0295 - val_loss: 0.0294\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0289 - val_loss: 0.0312\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0294 - val_loss: 0.0298\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0296 - val_loss: 0.0293\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0293 - val_loss: 0.0321\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0290 - val_loss: 0.0296\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0292 - val_loss: 0.0304\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0292 - val_loss: 0.0323\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0299 - val_loss: 0.0300\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 58us/step - loss: 0.0289 - val_loss: 0.0343\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 57us/step - loss: 0.0291 - val_loss: 0.0402\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 61us/step - loss: 0.0292 - val_loss: 0.0316\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 48us/step - loss: 0.0294 - val_loss: 0.0373\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 42us/step - loss: 0.0291 - val_loss: 0.0301\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 37us/step - loss: 0.0294 - val_loss: 0.0332\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 64us/step - loss: 0.0293 - val_loss: 0.0362\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.0296 - val_loss: 0.0411\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 65us/step - loss: 0.0294 - val_loss: 0.0378\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 60us/step - loss: 0.0296 - val_loss: 0.0375\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 21us/step - loss: 0.0303 - val_loss: 0.0333\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 27us/step - loss: 0.0299 - val_loss: 0.0262\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 24us/step - loss: 0.0298 - val_loss: 0.0322\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 27us/step - loss: 0.0299 - val_loss: 0.0310\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 57us/step - loss: 0.0309 - val_loss: 0.0388\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 38us/step - loss: 0.0306 - val_loss: 0.0310\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 48us/step - loss: 0.0302 - val_loss: 0.0369\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 31us/step - loss: 0.0299 - val_loss: 0.0340\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 50us/step - loss: 0.0299 - val_loss: 0.0314\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 50us/step - loss: 0.0301 - val_loss: 0.0333\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 1s 83us/step - loss: 0.0302 - val_loss: 0.0331\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 67us/step - loss: 0.0304 - val_loss: 0.0348\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 68us/step - loss: 0.0302 - val_loss: 0.0311\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 54us/step - loss: 0.0302 - val_loss: 0.0330\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 48us/step - loss: 0.0301 - val_loss: 0.0324\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 40us/step - loss: 0.0304 - val_loss: 0.0292\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 50us/step - loss: 0.0299 - val_loss: 0.0246\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 45us/step - loss: 0.0301 - val_loss: 0.0237\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 62us/step - loss: 0.0303 - val_loss: 0.0274\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 45us/step - loss: 0.0300 - val_loss: 0.0266\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 32us/step - loss: 0.0301 - val_loss: 0.0357\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 41us/step - loss: 0.0299 - val_loss: 0.0271\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 39us/step - loss: 0.0301 - val_loss: 0.0273\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 40us/step - loss: 0.0300 - val_loss: 0.0262\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 41us/step - loss: 0.0300 - val_loss: 0.0302\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 36us/step - loss: 0.0298 - val_loss: 0.0274\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 40us/step - loss: 0.0298 - val_loss: 0.0264\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 41us/step - loss: 0.0299 - val_loss: 0.0270\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 33us/step - loss: 0.0298 - val_loss: 0.0278\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 35us/step - loss: 0.0302 - val_loss: 0.0318\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 38us/step - loss: 0.0297 - val_loss: 0.0260\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 41us/step - loss: 0.0300 - val_loss: 0.0280\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 42us/step - loss: 0.0296 - val_loss: 0.0279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 41us/step - loss: 0.0299 - val_loss: 0.0265\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 36us/step - loss: 0.0298 - val_loss: 0.0274\n",
      "best reward is :  [0.71121244 0.61913419 0.60761332 0.58369533 0.49434041]\n",
      "reward is :  [0.46928203 0.07696793 0.21502421 0.03079555 0.03079555]\n",
      "regrets is :  [0.24193041 0.54216626 0.39258911 0.55289977 0.46354486] \n",
      "\n",
      "best reward is :  [0.58114522 0.48589641 0.44490164 0.42769068 0.40278494]\n",
      "reward is :  [0.27618136 0.26696793 0.37833053 0.22079555 0.23079555]\n",
      "regrets is :  [0.30496386 0.21892848 0.06657112 0.20689513 0.17198939] \n",
      "\n",
      "best reward is :  [0.60994951 0.58076815 0.49462513 0.46038319 0.42899616]\n",
      "reward is :  [0.3        0.28595772 0.46038319 0.22407756 0.20447082]\n",
      "regrets is :  [0.30994951 0.29481042 0.03424194 0.23630563 0.22452534] \n",
      "\n",
      "best reward is :  [0.58842708 0.56282761 0.5475553  0.46       0.45586375]\n",
      "reward is :  [0.46       0.09485647 0.2228096  0.0486841  0.03079555]\n",
      "regrets is :  [0.12842708 0.46797114 0.3247457  0.4113159  0.4250682 ] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.0295 - val_loss: 0.0247\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.0292 - val_loss: 0.0250\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.0293 - val_loss: 0.0285\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.0295 - val_loss: 0.0231\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.0293 - val_loss: 0.0261\n",
      "best reward is :  [0.74523601 0.67564837 0.65464102 0.59160895 0.55564837]\n",
      "reward is :  [0.65464102 0.59160895 0.74523601 0.67564837 0.55564837]\n",
      "regrets is :  [ 0.09059499  0.08403942 -0.09059499 -0.08403942  0.        ] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 69us/step - loss: 0.0636 - val_loss: 0.0303\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0307 - val_loss: 0.0306\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0304 - val_loss: 0.0301\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0297 - val_loss: 0.0290\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0294 - val_loss: 0.0280\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0297 - val_loss: 0.0291\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0300 - val_loss: 0.0305\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0303 - val_loss: 0.0280\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0303 - val_loss: 0.0301\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0301 - val_loss: 0.0279\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0307 - val_loss: 0.0291\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0301 - val_loss: 0.0281\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0298 - val_loss: 0.0289\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0299 - val_loss: 0.0279\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0296 - val_loss: 0.0287\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0299 - val_loss: 0.0285\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0301 - val_loss: 0.0285\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0306 - val_loss: 0.0278\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0300 - val_loss: 0.0301\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0303 - val_loss: 0.0283\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0300 - val_loss: 0.0282\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0296 - val_loss: 0.0274\n",
      "Epoch 23/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0301 - val_loss: 0.0290\n",
      "Epoch 24/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0296 - val_loss: 0.0270\n",
      "Epoch 25/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0302 - val_loss: 0.0302\n",
      "Epoch 26/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0301 - val_loss: 0.0278\n",
      "Epoch 27/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0300 - val_loss: 0.0299\n",
      "Epoch 28/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0303 - val_loss: 0.0279\n",
      "Epoch 29/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0298 - val_loss: 0.0282\n",
      "Epoch 30/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0302 - val_loss: 0.0299\n",
      "Epoch 31/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0300 - val_loss: 0.0282\n",
      "Epoch 32/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0299 - val_loss: 0.0275\n",
      "Epoch 33/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0300 - val_loss: 0.0291\n",
      "Epoch 34/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0301 - val_loss: 0.0274\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 20us/step - loss: 0.0299 - val_loss: 0.0298\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 25us/step - loss: 0.0304 - val_loss: 0.0379\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 23us/step - loss: 0.0296 - val_loss: 0.0373\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 25us/step - loss: 0.0302 - val_loss: 0.0383\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 24us/step - loss: 0.0297 - val_loss: 0.0305\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 30us/step - loss: 0.0300 - val_loss: 0.0354\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - ETA: 0s - loss: 0.029 - 0s 37us/step - loss: 0.0299 - val_loss: 0.0298\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.0298 - val_loss: 0.0384\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.0303 - val_loss: 0.0555\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.0297 - val_loss: 0.0496\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 20us/step - loss: 0.0300 - val_loss: 0.0345\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 24us/step - loss: 0.0303 - val_loss: 0.0364\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 24us/step - loss: 0.0301 - val_loss: 0.0363\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 27us/step - loss: 0.0305 - val_loss: 0.0368\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 26us/step - loss: 0.0302 - val_loss: 0.0325\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 33us/step - loss: 0.0304 - val_loss: 0.0296\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 37us/step - loss: 0.0304 - val_loss: 0.0297\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 41us/step - loss: 0.0305 - val_loss: 0.0307\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 42us/step - loss: 0.0302 - val_loss: 0.0302\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 41us/step - loss: 0.0306 - val_loss: 0.0329\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 34us/step - loss: 0.0301 - val_loss: 0.0262\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 43us/step - loss: 0.0301 - val_loss: 0.0196\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.0301 - val_loss: 0.0254\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 32us/step - loss: 0.0302 - val_loss: 0.0224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 23us/step - loss: 0.0303 - val_loss: 0.0258\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 33us/step - loss: 0.0297 - val_loss: 0.0199\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 38us/step - loss: 0.0302 - val_loss: 0.0228\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 37us/step - loss: 0.0298 - val_loss: 0.0278\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 38us/step - loss: 0.0296 - val_loss: 0.0256\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 38us/step - loss: 0.0299 - val_loss: 0.0254\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 33us/step - loss: 0.0293 - val_loss: 0.0277\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 36us/step - loss: 0.0296 - val_loss: 0.0211\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 38us/step - loss: 0.0292 - val_loss: 0.0231\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 38us/step - loss: 0.0295 - val_loss: 0.0190\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 37us/step - loss: 0.0296 - val_loss: 0.0259\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 29us/step - loss: 0.0291 - val_loss: 0.0242\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 38us/step - loss: 0.0291 - val_loss: 0.0171\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 38us/step - loss: 0.0293 - val_loss: 0.0193\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 39us/step - loss: 0.0289 - val_loss: 0.0217\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 41us/step - loss: 0.0292 - val_loss: 0.0206\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 32us/step - loss: 0.0284 - val_loss: 0.0236\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 34us/step - loss: 0.0284 - val_loss: 0.0229\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 23us/step - loss: 0.0284 - val_loss: 0.0224\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 23us/step - loss: 0.0285 - val_loss: 0.0272\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 22us/step - loss: 0.0286 - val_loss: 0.0216\n",
      "best reward is :  [0.68857615 0.65491525 0.57669903 0.47740646 0.45382159]\n",
      "reward is :  [0.65491525 0.45382159 0.57669903 0.68857615 0.27776688]\n",
      "regrets is :  [ 0.0336609   0.20109366  0.         -0.21116969  0.17605471] \n",
      "\n",
      "best reward is :  [0.62756868 0.62302142 0.53656242 0.51336586 0.50202512]\n",
      "reward is :  [0.11519896 0.23120623 0.15334004 0.17393513 0.06466565]\n",
      "regrets is :  [0.51236973 0.39181519 0.38322239 0.33943072 0.43735947] \n",
      "\n",
      "best reward is :  [0.60670754 0.58696597 0.5742641  0.54215048 0.47669903]\n",
      "reward is :  [0.30858089 0.58696597 0.47669903 0.43295975 0.54215048]\n",
      "regrets is :  [ 0.29812666  0.          0.09756507  0.10919073 -0.06545145] \n",
      "\n",
      "best reward is :  [0.62756868 0.62302142 0.53656242 0.51336586 0.50202512]\n",
      "reward is :  [0.11519896 0.23120623 0.15334004 0.17393513 0.06466565]\n",
      "regrets is :  [0.51236973 0.39181519 0.38322239 0.33943072 0.43735947] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 32us/step - loss: 0.0282 - val_loss: 0.0225\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.0279 - val_loss: 0.0233\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.0281 - val_loss: 0.0215\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.0281 - val_loss: 0.0201\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.0281 - val_loss: 0.0216\n",
      "best reward is :  [0.60804316 0.58848485 0.55803658 0.55374695 0.55120623]\n",
      "reward is :  [0.47491525 0.55120623 0.4858033  0.51929412 0.58848485]\n",
      "regrets is :  [ 0.1331279   0.03727862  0.07223327  0.03445283 -0.03727862] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 97us/step - loss: 0.0952 - val_loss: 0.0378\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0307 - val_loss: 0.0361\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0307 - val_loss: 0.0372\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0301 - val_loss: 0.0350\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0303 - val_loss: 0.0350\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0304 - val_loss: 0.0369\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0307 - val_loss: 0.0361\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0305 - val_loss: 0.0353\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0306 - val_loss: 0.0348\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0311 - val_loss: 0.0356\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0307 - val_loss: 0.0352\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0302 - val_loss: 0.0369\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0303 - val_loss: 0.0361\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0305 - val_loss: 0.0334\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0305 - val_loss: 0.0340\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0305 - val_loss: 0.0338\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0305 - val_loss: 0.0359\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0306 - val_loss: 0.0346\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0309 - val_loss: 0.0343\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0308 - val_loss: 0.0357\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0311 - val_loss: 0.0357\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0308 - val_loss: 0.0359\n",
      "Epoch 23/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0305 - val_loss: 0.0339\n",
      "Epoch 24/100\n",
      "4500/4500 [==============================] - 0s 51us/step - loss: 0.0302 - val_loss: 0.0347\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 36us/step - loss: 0.0319 - val_loss: 0.0373\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 32us/step - loss: 0.0309 - val_loss: 0.0378\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 38us/step - loss: 0.0311 - val_loss: 0.0374\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 37us/step - loss: 0.0312 - val_loss: 0.0364\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 41us/step - loss: 0.0310 - val_loss: 0.0363\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 36us/step - loss: 0.0314 - val_loss: 0.0421\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 37us/step - loss: 0.0314 - val_loss: 0.0301\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 42us/step - loss: 0.0311 - val_loss: 0.0372\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 44us/step - loss: 0.0322 - val_loss: 0.0326\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.0313 - val_loss: 0.0314\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 27us/step - loss: 0.0315 - val_loss: 0.0331\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 38us/step - loss: 0.0317 - val_loss: 0.0361\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 43us/step - loss: 0.0317 - val_loss: 0.0312\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 41us/step - loss: 0.0318 - val_loss: 0.0306\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5850/5850 [==============================] - 0s 39us/step - loss: 0.0312 - val_loss: 0.0304\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 33us/step - loss: 0.0319 - val_loss: 0.0308\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 35us/step - loss: 0.0319 - val_loss: 0.0288\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 40us/step - loss: 0.0317 - val_loss: 0.0277\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 38us/step - loss: 0.0318 - val_loss: 0.0333\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 41us/step - loss: 0.0316 - val_loss: 0.0352\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 32us/step - loss: 0.0315 - val_loss: 0.0332\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.0315 - val_loss: 0.0328\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.0313 - val_loss: 0.0338\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.0312 - val_loss: 0.0349\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.0313 - val_loss: 0.0330\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 37us/step - loss: 0.0308 - val_loss: 0.0352\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 34us/step - loss: 0.0315 - val_loss: 0.0350\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 23us/step - loss: 0.0317 - val_loss: 0.0350\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 23us/step - loss: 0.0311 - val_loss: 0.0352\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 25us/step - loss: 0.0314 - val_loss: 0.0356\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 35us/step - loss: 0.0312 - val_loss: 0.0302\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 38us/step - loss: 0.0314 - val_loss: 0.0318\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 37us/step - loss: 0.0317 - val_loss: 0.0317\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 41us/step - loss: 0.0314 - val_loss: 0.0312\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 36us/step - loss: 0.0315 - val_loss: 0.0317\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 36us/step - loss: 0.0315 - val_loss: 0.0335\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 37us/step - loss: 0.0316 - val_loss: 0.0303\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 38us/step - loss: 0.0317 - val_loss: 0.0327\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 43us/step - loss: 0.0316 - val_loss: 0.0291\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 32us/step - loss: 0.0314 - val_loss: 0.0308\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 33us/step - loss: 0.0312 - val_loss: 0.0352\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 38us/step - loss: 0.0312 - val_loss: 0.0370\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 35us/step - loss: 0.0312 - val_loss: 0.0373\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 43us/step - loss: 0.0315 - val_loss: 0.0355\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 36us/step - loss: 0.0311 - val_loss: 0.0381\n",
      "best reward is :  [0.70231207 0.55211631 0.54811175 0.53336969 0.51501737]\n",
      "reward is :  [0.25265195 0.54811175 0.07392861 0.42505771 0.38149284]\n",
      "regrets is :  [0.44966012 0.00400456 0.47418313 0.10831197 0.13352453] \n",
      "\n",
      "best reward is :  [0.61403549 0.5317757  0.49912195 0.48441613 0.43647059]\n",
      "reward is :  [0.43647059 0.49912195 0.27978648 0.5317757  0.61403549]\n",
      "regrets is :  [ 0.1775649   0.03265375  0.21933547 -0.04735957 -0.1775649 ] \n",
      "\n",
      "best reward is :  [0.84313725 0.49596784 0.48678544 0.46216808 0.40034901]\n",
      "reward is :  [0.84313725 0.39912195 0.48678544 0.28544133 0.28308712]\n",
      "regrets is :  [0.         0.09684589 0.         0.17672675 0.11726189] \n",
      "\n",
      "best reward is :  [0.63608815 0.5317757  0.49912195 0.48441613 0.43647059]\n",
      "reward is :  [0.43647059 0.49912195 0.27978648 0.5317757  0.63608815]\n",
      "regrets is :  [ 0.19961757  0.03265375  0.21933547 -0.04735957 -0.19961757] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 34us/step - loss: 0.0311 - val_loss: 0.0371\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.0312 - val_loss: 0.0436\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 45us/step - loss: 0.0311 - val_loss: 0.0420\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 1s 58us/step - loss: 0.0315 - val_loss: 0.0348\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 48us/step - loss: 0.0311 - val_loss: 0.0418\n",
      "best reward is :  [0.64537019 0.5630728  0.53287898 0.5207655  0.50840398]\n",
      "reward is :  [0.4613234  0.50840398 0.30463929 0.5207655  0.64537019]\n",
      "regrets is :  [ 0.18404678  0.05466882  0.22823969  0.         -0.1369662 ] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 96us/step - loss: 0.0749 - val_loss: 0.0367\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0338 - val_loss: 0.0306\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0324 - val_loss: 0.0306\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0327 - val_loss: 0.0298\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 52us/step - loss: 0.0325 - val_loss: 0.0322\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0324 - val_loss: 0.0300\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0325 - val_loss: 0.0305\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 56us/step - loss: 0.0325 - val_loss: 0.0306\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0323 - val_loss: 0.0312\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0323 - val_loss: 0.0305\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 53us/step - loss: 0.0325 - val_loss: 0.0336\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 53us/step - loss: 0.0327 - val_loss: 0.0297\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0331 - val_loss: 0.0303\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0330 - val_loss: 0.0325\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 51us/step - loss: 0.0324 - val_loss: 0.0299\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 52us/step - loss: 0.0329 - val_loss: 0.0301\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0321 - val_loss: 0.0296\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0321 - val_loss: 0.0300\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 51us/step - loss: 0.0322 - val_loss: 0.0321\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0323 - val_loss: 0.0307\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0322 - val_loss: 0.0293\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0322 - val_loss: 0.0300\n",
      "Epoch 23/100\n",
      "4500/4500 [==============================] - 0s 58us/step - loss: 0.0325 - val_loss: 0.0338\n",
      "Epoch 24/100\n",
      "4500/4500 [==============================] - 0s 56us/step - loss: 0.0325 - val_loss: 0.0312\n",
      "Epoch 25/100\n",
      "4500/4500 [==============================] - 0s 51us/step - loss: 0.0322 - val_loss: 0.0296\n",
      "Epoch 26/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0323 - val_loss: 0.0311\n",
      "Epoch 27/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0330 - val_loss: 0.0300\n",
      "Epoch 28/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0321 - val_loss: 0.0311\n",
      "Epoch 29/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0320 - val_loss: 0.0292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0321 - val_loss: 0.0355\n",
      "Epoch 31/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0323 - val_loss: 0.0300\n",
      "Epoch 32/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0321 - val_loss: 0.0326\n",
      "Epoch 33/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0323 - val_loss: 0.0299\n",
      "Epoch 34/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0321 - val_loss: 0.0295\n",
      "Epoch 35/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0330 - val_loss: 0.0305\n",
      "Epoch 36/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0322 - val_loss: 0.0309\n",
      "Epoch 37/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0319 - val_loss: 0.0297\n",
      "Epoch 38/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0324 - val_loss: 0.0312\n",
      "Epoch 39/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0325 - val_loss: 0.0303\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 32us/step - loss: 0.0319 - val_loss: 0.0325\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 39us/step - loss: 0.0324 - val_loss: 0.0306\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 37us/step - loss: 0.0323 - val_loss: 0.0391\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 43us/step - loss: 0.0324 - val_loss: 0.0351\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 41us/step - loss: 0.0319 - val_loss: 0.0401\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 33us/step - loss: 0.0323 - val_loss: 0.0393\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.0324 - val_loss: 0.0378\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 37us/step - loss: 0.0327 - val_loss: 0.0417\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.0325 - val_loss: 0.0382\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.0324 - val_loss: 0.0338\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 34us/step - loss: 0.0323 - val_loss: 0.0354\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 37us/step - loss: 0.0325 - val_loss: 0.0301\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 37us/step - loss: 0.0325 - val_loss: 0.0303\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 37us/step - loss: 0.0324 - val_loss: 0.0459\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 41us/step - loss: 0.0325 - val_loss: 0.0351\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 33us/step - loss: 0.0325 - val_loss: 0.0275\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 37us/step - loss: 0.0322 - val_loss: 0.0266\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 45us/step - loss: 0.0324 - val_loss: 0.0328\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 39us/step - loss: 0.0323 - val_loss: 0.0284\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 39us/step - loss: 0.0323 - val_loss: 0.0308\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.0319 - val_loss: 0.0267\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 42us/step - loss: 0.0321 - val_loss: 0.0239\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.0319 - val_loss: 0.0265\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 41us/step - loss: 0.0319 - val_loss: 0.0227\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 41us/step - loss: 0.0321 - val_loss: 0.0254\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 32us/step - loss: 0.0316 - val_loss: 0.0233\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 42us/step - loss: 0.0314 - val_loss: 0.0263\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 36us/step - loss: 0.0320 - val_loss: 0.0243\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 36us/step - loss: 0.0318 - val_loss: 0.0249\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 37us/step - loss: 0.0314 - val_loss: 0.0226\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 33us/step - loss: 0.0311 - val_loss: 0.0254\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 35us/step - loss: 0.0310 - val_loss: 0.0214\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 27us/step - loss: 0.0312 - val_loss: 0.0211\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 24us/step - loss: 0.0314 - val_loss: 0.0226\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 26us/step - loss: 0.0315 - val_loss: 0.0214\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 22us/step - loss: 0.0304 - val_loss: 0.0204\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 25us/step - loss: 0.0309 - val_loss: 0.0174\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 24us/step - loss: 0.0306 - val_loss: 0.0184\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 25us/step - loss: 0.0304 - val_loss: 0.0204\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 26us/step - loss: 0.0305 - val_loss: 0.0203\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 34us/step - loss: 0.0300 - val_loss: 0.0166\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 26us/step - loss: 0.0299 - val_loss: 0.0163\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 26us/step - loss: 0.0300 - val_loss: 0.0163\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 28us/step - loss: 0.0300 - val_loss: 0.0193\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 25us/step - loss: 0.0299 - val_loss: 0.0173\n",
      "best reward is :  [0.79333333 0.69238411 0.58       0.53555484 0.49226113]\n",
      "reward is :  [0.69238411 0.58       0.79333333 0.48718053 0.41602434]\n",
      "regrets is :  [ 0.10094923  0.11238411 -0.21333333  0.04837431  0.07623679] \n",
      "\n",
      "best reward is :  [0.64232772 0.59238411 0.54953313 0.52138008 0.49868907]\n",
      "reward is :  [0.59238411 0.49868907 0.41868907 0.64232772 0.52138008]\n",
      "regrets is :  [ 0.04994361  0.09369504  0.13084406 -0.12094764 -0.02269101] \n",
      "\n",
      "best reward is :  [0.64071393 0.61366563 0.53445169 0.50856547 0.48699896]\n",
      "reward is :  [0.50856547 0.61366563 0.48699896 0.43439907 0.3922057 ]\n",
      "regrets is :  [0.13214846 0.         0.04745272 0.0741664  0.09479326] \n",
      "\n",
      "best reward is :  [0.59280015 0.54646154 0.54146893 0.51518395 0.47333333]\n",
      "reward is :  [0.18702512 0.28       0.47333333 0.09850851 0.04613016]\n",
      "regrets is :  [0.40577502 0.26646154 0.06813559 0.41667544 0.42720317] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 21us/step - loss: 0.0293 - val_loss: 0.0168\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.0292 - val_loss: 0.0188\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.0293 - val_loss: 0.0212\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.0294 - val_loss: 0.0193\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.0294 - val_loss: 0.0161\n",
      "best reward is :  [0.68232772 0.64       0.63868907 0.63602434 0.59238411]\n",
      "reward is :  [0.59238411 0.64       0.63868907 0.68232772 0.63602434]\n",
      "regrets is :  [ 0.08994361  0.          0.         -0.04630338 -0.04364023] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 94us/step - loss: 0.0789 - val_loss: 0.0377\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0309 - val_loss: 0.0319\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0297 - val_loss: 0.0313\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0294 - val_loss: 0.0308\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0299 - val_loss: 0.0315\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0293 - val_loss: 0.0317\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0300 - val_loss: 0.0299\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0293 - val_loss: 0.0305\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0296 - val_loss: 0.0342\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0302 - val_loss: 0.0314\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0295 - val_loss: 0.0310\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0297 - val_loss: 0.0298\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0296 - val_loss: 0.0308\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0299 - val_loss: 0.0310\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0297 - val_loss: 0.0329\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0298 - val_loss: 0.0318\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0299 - val_loss: 0.0314\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0296 - val_loss: 0.0331\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0296 - val_loss: 0.0314\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0293 - val_loss: 0.0317\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0294 - val_loss: 0.0314\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0296 - val_loss: 0.0304\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 39us/step - loss: 0.0300 - val_loss: 0.0446\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 48us/step - loss: 0.0298 - val_loss: 0.0357\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 38us/step - loss: 0.0306 - val_loss: 0.0366\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 43us/step - loss: 0.0297 - val_loss: 0.0404\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 41us/step - loss: 0.0296 - val_loss: 0.0401\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 30us/step - loss: 0.0304 - val_loss: 0.0338\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 35us/step - loss: 0.0305 - val_loss: 0.0332\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.0308 - val_loss: 0.0381\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 43us/step - loss: 0.0305 - val_loss: 0.0397\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.0306 - val_loss: 0.0378\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 20us/step - loss: 0.0308 - val_loss: 0.0353\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 25us/step - loss: 0.0310 - val_loss: 0.0369\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 24us/step - loss: 0.0306 - val_loss: 0.0383\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 24us/step - loss: 0.0309 - val_loss: 0.0313\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 26us/step - loss: 0.0309 - val_loss: 0.0319\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 37us/step - loss: 0.0313 - val_loss: 0.0293\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 30us/step - loss: 0.0304 - val_loss: 0.0313\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 24us/step - loss: 0.0307 - val_loss: 0.0250\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 24us/step - loss: 0.0308 - val_loss: 0.0283\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 24us/step - loss: 0.0307 - val_loss: 0.0283\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.0302 - val_loss: 0.0276\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.0306 - val_loss: 0.0242\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.0306 - val_loss: 0.0255\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.0304 - val_loss: 0.0286\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.0305 - val_loss: 0.0234\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 22us/step - loss: 0.0299 - val_loss: 0.0265\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 23us/step - loss: 0.0302 - val_loss: 0.0212\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 26us/step - loss: 0.0300 - val_loss: 0.0260\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 29us/step - loss: 0.0299 - val_loss: 0.0229\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 32us/step - loss: 0.0302 - val_loss: 0.0277\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 37us/step - loss: 0.0299 - val_loss: 0.0240\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 39us/step - loss: 0.0298 - val_loss: 0.0183\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 42us/step - loss: 0.0296 - val_loss: 0.0218\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 39us/step - loss: 0.0296 - val_loss: 0.0244\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 42us/step - loss: 0.0299 - val_loss: 0.0182\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 34us/step - loss: 0.0290 - val_loss: 0.0193\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 37us/step - loss: 0.0292 - val_loss: 0.0235\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 39us/step - loss: 0.0293 - val_loss: 0.0185\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 43us/step - loss: 0.0291 - val_loss: 0.0175\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 30us/step - loss: 0.0289 - val_loss: 0.0196\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 36us/step - loss: 0.0285 - val_loss: 0.0186\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 35us/step - loss: 0.0286 - val_loss: 0.0219\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 43us/step - loss: 0.0286 - val_loss: 0.0170\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 42us/step - loss: 0.0286 - val_loss: 0.0214\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 40us/step - loss: 0.0286 - val_loss: 0.0193\n",
      "best reward is :  [0.60421335 0.51427457 0.46928203 0.45520913 0.43339913]\n",
      "reward is :  [0.15406162 0.46928203 0.24187013 0.15123929 0.26884501]\n",
      "regrets is :  [0.45015173 0.04499253 0.2274119  0.30396984 0.16455411] \n",
      "\n",
      "best reward is :  [0.82171269 0.69769568 0.67322871 0.56898979 0.56335491]\n",
      "reward is :  [0.69769568 0.56898979 0.39805149 0.82171269 0.46207507]\n",
      "regrets is :  [ 0.12401701  0.12870588  0.27517722 -0.25272289  0.10127984] \n",
      "\n",
      "best reward is :  [0.76       0.70920084 0.5879985  0.57148461 0.55130599]\n",
      "reward is :  [0.54870588 0.76       0.48429654 0.49272289 0.42884501]\n",
      "regrets is :  [ 0.21129412 -0.05079916  0.10370196  0.07876172  0.12246098] \n",
      "\n",
      "best reward is :  [0.5185767  0.48505538 0.47752634 0.38222981 0.37318213]\n",
      "reward is :  [0.1433469  0.27       0.31394148 0.15300659 0.0664186 ]\n",
      "regrets is :  [0.3752298  0.21505538 0.16358486 0.22922322 0.30676353] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.0281 - val_loss: 0.0187\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.0280 - val_loss: 0.0174\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 0s 44us/step - loss: 0.0279 - val_loss: 0.0199\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.0281 - val_loss: 0.0194\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.0280 - val_loss: 0.0179\n",
      "best reward is :  [0.56203922 0.46670521 0.45305519 0.43333333 0.42281847]\n",
      "reward is :  [0.56203922 0.4003323  0.34886909 0.45305519 0.1309135 ]\n",
      "regrets is :  [ 0.          0.06637291  0.1041861  -0.01972186  0.29190497] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 87us/step - loss: 0.0984 - val_loss: 0.0373\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0335 - val_loss: 0.0322\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0310 - val_loss: 0.0318\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0310 - val_loss: 0.0331\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0307 - val_loss: 0.0338\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0309 - val_loss: 0.0315\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0310 - val_loss: 0.0342\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0310 - val_loss: 0.0314\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0312 - val_loss: 0.0310\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0319 - val_loss: 0.0324\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0309 - val_loss: 0.0324\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0315 - val_loss: 0.0313\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0311 - val_loss: 0.0325\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0313 - val_loss: 0.0319\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0308 - val_loss: 0.0316\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0312 - val_loss: 0.0317\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0309 - val_loss: 0.0328\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0311 - val_loss: 0.0336\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0313 - val_loss: 0.0326\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 36us/step - loss: 0.0314 - val_loss: 0.0398\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 44us/step - loss: 0.0312 - val_loss: 0.0431\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 39us/step - loss: 0.0313 - val_loss: 0.0382\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 39us/step - loss: 0.0312 - val_loss: 0.0369\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 46us/step - loss: 0.0314 - val_loss: 0.0453\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 35us/step - loss: 0.0318 - val_loss: 0.0362\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 34us/step - loss: 0.0313 - val_loss: 0.0339\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.0315 - val_loss: 0.0322\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.0317 - val_loss: 0.0340\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 43us/step - loss: 0.0312 - val_loss: 0.0326\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 33us/step - loss: 0.0317 - val_loss: 0.0303\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 35us/step - loss: 0.0317 - val_loss: 0.0263\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 37us/step - loss: 0.0315 - val_loss: 0.0248\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 44us/step - loss: 0.0319 - val_loss: 0.0238\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 43us/step - loss: 0.0315 - val_loss: 0.0262\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 33us/step - loss: 0.0311 - val_loss: 0.0261\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 39us/step - loss: 0.0313 - val_loss: 0.0234\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 39us/step - loss: 0.0311 - val_loss: 0.0283\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 44us/step - loss: 0.0314 - val_loss: 0.0248\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 41us/step - loss: 0.0312 - val_loss: 0.0202\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.0305 - val_loss: 0.0237\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.0308 - val_loss: 0.0351\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 42us/step - loss: 0.0308 - val_loss: 0.0282\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 29us/step - loss: 0.0308 - val_loss: 0.0295\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 23us/step - loss: 0.0312 - val_loss: 0.0252\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 25us/step - loss: 0.0307 - val_loss: 0.0280\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 25us/step - loss: 0.0301 - val_loss: 0.0309\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 26us/step - loss: 0.0304 - val_loss: 0.0247\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 27us/step - loss: 0.0304 - val_loss: 0.0293\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 37us/step - loss: 0.0302 - val_loss: 0.0289\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 21us/step - loss: 0.0298 - val_loss: 0.0164\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 23us/step - loss: 0.0300 - val_loss: 0.0167\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 24us/step - loss: 0.0302 - val_loss: 0.0202\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 28us/step - loss: 0.0300 - val_loss: 0.0176\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 26us/step - loss: 0.0299 - val_loss: 0.0191\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 36us/step - loss: 0.0292 - val_loss: 0.0166\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 38us/step - loss: 0.0294 - val_loss: 0.0191\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 44us/step - loss: 0.0295 - val_loss: 0.0179\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 32us/step - loss: 0.0293 - val_loss: 0.0191\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 26us/step - loss: 0.0293 - val_loss: 0.0169\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 34us/step - loss: 0.0286 - val_loss: 0.0183\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 36us/step - loss: 0.0285 - val_loss: 0.0182\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 36us/step - loss: 0.0288 - val_loss: 0.0153\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 37us/step - loss: 0.0292 - val_loss: 0.0184\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 37us/step - loss: 0.0286 - val_loss: 0.0269\n",
      "best reward is :  [0.87105876 0.60585254 0.59325453 0.54749246 0.51787833]\n",
      "reward is :  [0.87105876 0.51787833 0.59325453 0.08363636 0.60585254]\n",
      "regrets is :  [ 0.          0.08797421  0.          0.4638561  -0.08797421] \n",
      "\n",
      "best reward is :  [0.80242891 0.66888515 0.66449537 0.65297763 0.62608555]\n",
      "reward is :  [0.66449537 0.65297763 0.80242891 0.0969697  0.66888515]\n",
      "regrets is :  [ 0.13793354  0.01590751 -0.13793354  0.55600794 -0.04279959] \n",
      "\n",
      "best reward is :  [0.49539038 0.47251921 0.44567307 0.4302439  0.42743096]\n",
      "reward is :  [0.3474247  0.37735343 0.31098633 0.36030303 0.47251921]\n",
      "regrets is :  [ 0.14796568  0.09516578  0.13468673  0.06994087 -0.04508825] \n",
      "\n",
      "best reward is :  [0.73116204 0.69949958 0.58369975 0.58300465 0.56595582]\n",
      "reward is :  [0.73116204 0.58300465 0.69949958 0.08363636 0.56595582]\n",
      "regrets is :  [ 0.          0.11649493 -0.11579982  0.49936829  0.        ] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.0280 - val_loss: 0.0288\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.0283 - val_loss: 0.0231\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.0281 - val_loss: 0.0233\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.0281 - val_loss: 0.0264\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.0282 - val_loss: 0.0230\n",
      "best reward is :  [0.74873563 0.69949958 0.58369975 0.58300465 0.56595582]\n",
      "reward is :  [0.74873563 0.58300465 0.69949958 0.08363636 0.56595582]\n",
      "regrets is :  [ 0.          0.11649493 -0.11579982  0.49936829  0.        ] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 92us/step - loss: 0.0828 - val_loss: 0.0311\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0310 - val_loss: 0.0270\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0302 - val_loss: 0.0291\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 72us/step - loss: 0.0303 - val_loss: 0.0281\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0306 - val_loss: 0.0283\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0302 - val_loss: 0.0297- ETA: 0s - loss: 0.030 - ETA: 0s - loss: 0.030\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0307 - val_loss: 0.0273\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0309 - val_loss: 0.0267\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0311 - val_loss: 0.0273\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0301 - val_loss: 0.0276\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0304 - val_loss: 0.0285\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0310 - val_loss: 0.0290\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0308 - val_loss: 0.0282\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0307 - val_loss: 0.0304\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0308 - val_loss: 0.0267\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0304 - val_loss: 0.0279\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0304 - val_loss: 0.0298\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0310 - val_loss: 0.0271\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0306 - val_loss: 0.0276\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.0311 - val_loss: 0.0277\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0313 - val_loss: 0.0303\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0308 - val_loss: 0.0289\n",
      "Epoch 23/100\n",
      "4500/4500 [==============================] - 0s 80us/step - loss: 0.0313 - val_loss: 0.0264\n",
      "Epoch 24/100\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.0307 - val_loss: 0.0279\n",
      "Epoch 25/100\n",
      "4500/4500 [==============================] - 0s 74us/step - loss: 0.0316 - val_loss: 0.0321\n",
      "Epoch 26/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0312 - val_loss: 0.0287\n",
      "Epoch 27/100\n",
      "4500/4500 [==============================] - 0s 56us/step - loss: 0.0307 - val_loss: 0.0300\n",
      "Epoch 28/100\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0308 - val_loss: 0.0268\n",
      "Epoch 29/100\n",
      "4500/4500 [==============================] - 0s 50us/step - loss: 0.0308 - val_loss: 0.0287\n",
      "Epoch 30/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0307 - val_loss: 0.0285\n",
      "Epoch 31/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0307 - val_loss: 0.0288\n",
      "Epoch 32/100\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.0310 - val_loss: 0.0322\n",
      "Epoch 33/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0311 - val_loss: 0.0278\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 23us/step - loss: 0.0300 - val_loss: 0.0324\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 25us/step - loss: 0.0300 - val_loss: 0.0309\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 25us/step - loss: 0.0304 - val_loss: 0.0296\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 28us/step - loss: 0.0306 - val_loss: 0.0305\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 27us/step - loss: 0.0305 - val_loss: 0.0298\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 37us/step - loss: 0.0301 - val_loss: 0.0329\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.0306 - val_loss: 0.0344\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 35us/step - loss: 0.0299 - val_loss: 0.0416\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.0305 - val_loss: 0.0440\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 65us/step - loss: 0.0303 - val_loss: 0.0387\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 35us/step - loss: 0.0303 - val_loss: 0.0366\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 39us/step - loss: 0.0302 - val_loss: 0.0339\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 35us/step - loss: 0.0310 - val_loss: 0.0270\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 40us/step - loss: 0.0304 - val_loss: 0.0333\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 59us/step - loss: 0.0308 - val_loss: 0.0389\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 21us/step - loss: 0.0306 - val_loss: 0.0331\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 23us/step - loss: 0.0304 - val_loss: 0.0339\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 25us/step - loss: 0.0305 - val_loss: 0.0337\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 23us/step - loss: 0.0305 - val_loss: 0.0345\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 27us/step - loss: 0.0308 - val_loss: 0.0330\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 47us/step - loss: 0.0307 - val_loss: 0.0341\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 42us/step - loss: 0.0306 - val_loss: 0.0324\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 62us/step - loss: 0.0305 - val_loss: 0.0324\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.0308 - val_loss: 0.0336\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 32us/step - loss: 0.0305 - val_loss: 0.0318\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 31us/step - loss: 0.0305 - val_loss: 0.0273\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 49us/step - loss: 0.0311 - val_loss: 0.0304\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 44us/step - loss: 0.0305 - val_loss: 0.0312\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 58us/step - loss: 0.0302 - val_loss: 0.0318\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 51us/step - loss: 0.0305 - val_loss: 0.0299\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 35us/step - loss: 0.0307 - val_loss: 0.0202\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 36us/step - loss: 0.0305 - val_loss: 0.0260\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 27us/step - loss: 0.0311 - val_loss: 0.0236\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 27us/step - loss: 0.0303 - val_loss: 0.0235\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 31us/step - loss: 0.0307 - val_loss: 0.0259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 31us/step - loss: 0.0303 - val_loss: 0.0211\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 22us/step - loss: 0.0303 - val_loss: 0.0248\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 23us/step - loss: 0.0302 - val_loss: 0.0194\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 20us/step - loss: 0.0302 - val_loss: 0.0247\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 23us/step - loss: 0.0300 - val_loss: 0.0209\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 37us/step - loss: 0.0300 - val_loss: 0.0204\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 37us/step - loss: 0.0298 - val_loss: 0.0195\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 35us/step - loss: 0.0298 - val_loss: 0.0181\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 38us/step - loss: 0.0296 - val_loss: 0.0213\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 27us/step - loss: 0.0296 - val_loss: 0.0186\n",
      "best reward is :  [0.63321125 0.58819262 0.56637744 0.49135545 0.48780538]\n",
      "reward is :  [0.48780538 0.14769231 0.56637744 0.41130851 0.43335761]\n",
      "regrets is :  [0.14540587 0.44050032 0.         0.08004694 0.05444777] \n",
      "\n",
      "best reward is :  [0.52735615 0.49457602 0.48104917 0.44667991 0.43154269]\n",
      "reward is :  [0.25436877 0.34417558 0.25918587 0.09307449 0.06436782]\n",
      "regrets is :  [0.27298738 0.15040044 0.2218633  0.35360543 0.36717487] \n",
      "\n",
      "best reward is :  [0.63276728 0.62800794 0.54702751 0.53170198 0.50355335]\n",
      "reward is :  [0.32537897 0.42769231 0.33019608 0.06907687 0.18436782]\n",
      "regrets is :  [0.30738831 0.20031564 0.21683143 0.46262511 0.31918553] \n",
      "\n",
      "best reward is :  [0.93504889 0.77997997 0.67023179 0.58852428 0.49307848]\n",
      "reward is :  [0.67023179 0.16417558 0.93504889 0.77997997 0.46922063]\n",
      "regrets is :  [ 0.26481711  0.61580439 -0.26481711 -0.19145569  0.02385785] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.0292 - val_loss: 0.0246\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.0292 - val_loss: 0.0258\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 30us/step - loss: 0.0297 - val_loss: 0.0256\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.0292 - val_loss: 0.0270\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.0293 - val_loss: 0.0252\n",
      "best reward is :  [0.69678538 0.47395417 0.44723585 0.40528031 0.38847298]\n",
      "reward is :  [0.38847298 0.69678538 0.24637744 0.09130851 0.27803345]\n",
      "regrets is :  [ 0.3083124  -0.22283121  0.20085841  0.31397179  0.11043954] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 91us/step - loss: 0.0978 - val_loss: 0.0396\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0337 - val_loss: 0.0322\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0310 - val_loss: 0.0311\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0304 - val_loss: 0.0302\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0305 - val_loss: 0.0295\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0301 - val_loss: 0.0303\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0313 - val_loss: 0.0308\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0306 - val_loss: 0.0316\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0309 - val_loss: 0.0302\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0308 - val_loss: 0.0304\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0304 - val_loss: 0.0324\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0303 - val_loss: 0.0313\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0304 - val_loss: 0.0314\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0304 - val_loss: 0.0303\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0307 - val_loss: 0.0314\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 36us/step - loss: 0.0309 - val_loss: 0.0371\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 37us/step - loss: 0.0304 - val_loss: 0.0403\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 39us/step - loss: 0.0304 - val_loss: 0.0322\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 27us/step - loss: 0.0303 - val_loss: 0.0345\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 42us/step - loss: 0.0303 - val_loss: 0.0401\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 36us/step - loss: 0.0309 - val_loss: 0.0513\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 37us/step - loss: 0.0313 - val_loss: 0.0495\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 43us/step - loss: 0.0310 - val_loss: 0.0381\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 43us/step - loss: 0.0305 - val_loss: 0.0377\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 34us/step - loss: 0.0311 - val_loss: 0.0358\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 35us/step - loss: 0.0320 - val_loss: 0.0333\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 34us/step - loss: 0.0319 - val_loss: 0.0409\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 35us/step - loss: 0.0316 - val_loss: 0.0429\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 36us/step - loss: 0.0320 - val_loss: 0.0456\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 41us/step - loss: 0.0320 - val_loss: 0.0424\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 19us/step - loss: 0.0322 - val_loss: 0.0437\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 33us/step - loss: 0.0328 - val_loss: 0.0336\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 40us/step - loss: 0.0319 - val_loss: 0.0376\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 28us/step - loss: 0.0320 - val_loss: 0.0345\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 28us/step - loss: 0.0317 - val_loss: 0.0338\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 31us/step - loss: 0.0321 - val_loss: 0.0336\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 33us/step - loss: 0.0324 - val_loss: 0.0339\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.0320 - val_loss: 0.0411\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 27us/step - loss: 0.0323 - val_loss: 0.0352\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 28us/step - loss: 0.0321 - val_loss: 0.0378\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 32us/step - loss: 0.0333 - val_loss: 0.0367\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 38us/step - loss: 0.0327 - val_loss: 0.0307\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 38us/step - loss: 0.0325 - val_loss: 0.0358\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 34us/step - loss: 0.0322 - val_loss: 0.0315\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - ETA: 0s - loss: 0.032 - 0s 35us/step - loss: 0.0323 - val_loss: 0.0390\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 28us/step - loss: 0.0323 - val_loss: 0.0355\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 39us/step - loss: 0.0329 - val_loss: 0.0403\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 37us/step - loss: 0.0328 - val_loss: 0.0313\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7650/7650 [==============================] - 0s 40us/step - loss: 0.0325 - val_loss: 0.0322\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 41us/step - loss: 0.0324 - val_loss: 0.0343\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 38us/step - loss: 0.0325 - val_loss: 0.0297\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 38us/step - loss: 0.0319 - val_loss: 0.0268\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 40us/step - loss: 0.0325 - val_loss: 0.0304\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 45us/step - loss: 0.0324 - val_loss: 0.0289\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 22us/step - loss: 0.0323 - val_loss: 0.0277\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 18us/step - loss: 0.0322 - val_loss: 0.0295\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 22us/step - loss: 0.0321 - val_loss: 0.0283\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 22us/step - loss: 0.0321 - val_loss: 0.0306\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 22us/step - loss: 0.0322 - val_loss: 0.0282\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 23us/step - loss: 0.0326 - val_loss: 0.0286\n",
      "best reward is :  [0.69269923 0.67368794 0.64964175 0.55909504 0.52208955]\n",
      "reward is :  [0.43766563 0.52208955 0.69269923 0.39908096 0.22308666]\n",
      "regrets is :  [ 0.2550336   0.15159839 -0.04305748  0.16001407  0.2990029 ] \n",
      "\n",
      "best reward is :  [0.61038906 0.60642641 0.60208955 0.46225873 0.42598124]\n",
      "reward is :  [0.60642641 0.60208955 0.42598124 0.22150737 0.42335878]\n",
      "regrets is :  [0.00396265 0.00433685 0.17610831 0.24075136 0.00262246] \n",
      "\n",
      "best reward is :  [0.73941326 0.54740459 0.51690434 0.50335878 0.48744427]\n",
      "reward is :  [0.284      0.16060595 0.37269923 0.73941326 0.50335878]\n",
      "regrets is :  [ 0.45541326  0.38679864  0.14420511 -0.23605448 -0.01591451] \n",
      "\n",
      "best reward is :  [0.67755204 0.50694237 0.50661537 0.45151201 0.44905089]\n",
      "reward is :  [0.50661537 0.50694237 0.67755204 0.39908096 0.20335878]\n",
      "regrets is :  [ 0.17093668  0.         -0.17093668  0.05243105  0.24569211] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.0318 - val_loss: 0.0315\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.0319 - val_loss: 0.0299\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.0320 - val_loss: 0.0310\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.0321 - val_loss: 0.0302\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.0319 - val_loss: 0.0298\n",
      "best reward is :  [0.77152067 0.6541609  0.63726615 0.59968541 0.56104138]\n",
      "reward is :  [0.41498387 0.6541609  0.5018035  0.26393378 0.22491141]\n",
      "regrets is :  [0.35653681 0.         0.13546265 0.33575164 0.33612997] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 84us/step - loss: 0.0659 - val_loss: 0.0337\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0285 - val_loss: 0.0281\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0278 - val_loss: 0.0288\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0282 - val_loss: 0.0283\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0276 - val_loss: 0.0291\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0280 - val_loss: 0.0279\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0279 - val_loss: 0.0286\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0271 - val_loss: 0.0274\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0274 - val_loss: 0.0282\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0278 - val_loss: 0.0285\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0278 - val_loss: 0.0282\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 54us/step - loss: 0.0278 - val_loss: 0.0291\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.0278 - val_loss: 0.0287\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0283 - val_loss: 0.0275\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0282 - val_loss: 0.0282\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0277 - val_loss: 0.0282\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0273 - val_loss: 0.0277\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0278 - val_loss: 0.0283\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 30us/step - loss: 0.0278 - val_loss: 0.0408\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 35us/step - loss: 0.0278 - val_loss: 0.0401\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 41us/step - loss: 0.0277 - val_loss: 0.0474\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 27us/step - loss: 0.0274 - val_loss: 0.0534\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 29us/step - loss: 0.0281 - val_loss: 0.0375\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.0287 - val_loss: 0.0396\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 26us/step - loss: 0.0285 - val_loss: 0.0540\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 28us/step - loss: 0.0285 - val_loss: 0.0384\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 25us/step - loss: 0.0288 - val_loss: 0.0402\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 28us/step - loss: 0.0283 - val_loss: 0.0406\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 35us/step - loss: 0.0296 - val_loss: 0.0321\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 36us/step - loss: 0.0297 - val_loss: 0.0278\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 41us/step - loss: 0.0296 - val_loss: 0.0349\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 37us/step - loss: 0.0294 - val_loss: 0.0311\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 40us/step - loss: 0.0293 - val_loss: 0.0310\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 41us/step - loss: 0.0297 - val_loss: 0.0357\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 43us/step - loss: 0.0293 - val_loss: 0.0308\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 40us/step - loss: 0.0295 - val_loss: 0.0328\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 38us/step - loss: 0.0295 - val_loss: 0.0309\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 43us/step - loss: 0.0296 - val_loss: 0.0236\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.0296 - val_loss: 0.0208\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 45us/step - loss: 0.0291 - val_loss: 0.0284\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 45us/step - loss: 0.0294 - val_loss: 0.0220\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.0293 - val_loss: 0.0296\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 44us/step - loss: 0.0298 - val_loss: 0.0299\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 35us/step - loss: 0.0293 - val_loss: 0.0235\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 38us/step - loss: 0.0290 - val_loss: 0.0281\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 34us/step - loss: 0.0292 - val_loss: 0.0304\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 28us/step - loss: 0.0294 - val_loss: 0.0268\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 0s 26us/step - loss: 0.0292 - val_loss: 0.0279\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 33us/step - loss: 0.0287 - val_loss: 0.0257\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 38us/step - loss: 0.0285 - val_loss: 0.0232\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 42us/step - loss: 0.0287 - val_loss: 0.0218\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 40us/step - loss: 0.0285 - val_loss: 0.0205\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 40us/step - loss: 0.0286 - val_loss: 0.0267\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 34us/step - loss: 0.0286 - val_loss: 0.0216\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 38us/step - loss: 0.0282 - val_loss: 0.0224\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 32us/step - loss: 0.0283 - val_loss: 0.0184\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 23us/step - loss: 0.0284 - val_loss: 0.0169\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 22us/step - loss: 0.0282 - val_loss: 0.0251\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 35us/step - loss: 0.0281 - val_loss: 0.0202\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 38us/step - loss: 0.0280 - val_loss: 0.0213\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 39us/step - loss: 0.0280 - val_loss: 0.0204\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 38us/step - loss: 0.0278 - val_loss: 0.0220\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 29us/step - loss: 0.0280 - val_loss: 0.0218\n",
      "best reward is :  [0.5719423  0.57064972 0.56257277 0.54447551 0.50426022]\n",
      "reward is :  [0.48446617 0.56257277 0.5719423  0.57064972 0.54447551]\n",
      "regrets is :  [ 0.08747613  0.00807696 -0.00936954 -0.02617421 -0.04021529] \n",
      "\n",
      "best reward is :  [0.61864647 0.56510949 0.56115702 0.5462205  0.48054922]\n",
      "reward is :  [0.41615628 0.61864647 0.56510949 0.5462205  0.48054922]\n",
      "regrets is :  [ 0.20249019 -0.05353698 -0.00395246  0.          0.        ] \n",
      "\n",
      "best reward is :  [0.6437941  0.62885911 0.62695637 0.60890124 0.55877512]\n",
      "reward is :  [0.40080054 0.62695637 0.55877512 0.6437941  0.62885911]\n",
      "regrets is :  [ 0.24299355  0.00190275  0.06818125 -0.03489286 -0.07008399] \n",
      "\n",
      "best reward is :  [0.53711063 0.53288219 0.46344704 0.45836738 0.39409288]\n",
      "reward is :  [0.07763336 0.20082062 0.31046523 0.25931502 0.2800463 ]\n",
      "regrets is :  [0.45947727 0.33206157 0.15298182 0.19905235 0.11404659] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.0278 - val_loss: 0.0178\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.0274 - val_loss: 0.0239\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.0275 - val_loss: 0.0163\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 34us/step - loss: 0.0277 - val_loss: 0.0172\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.0274 - val_loss: 0.0177\n",
      "best reward is :  [0.74759147 0.67925466 0.60346532 0.55705531 0.45664779]\n",
      "reward is :  [0.13565336 0.01329073 0.1475359  0.07367943 0.07761989]\n",
      "regrets is :  [0.61193811 0.66596393 0.45592942 0.48337588 0.3790279 ] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 75us/step - loss: 0.0928 - val_loss: 0.0369\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0353 - val_loss: 0.0329\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0328 - val_loss: 0.0297\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 19us/step - loss: 0.0322 - val_loss: 0.0315\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0324 - val_loss: 0.0302\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0322 - val_loss: 0.0307\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0321 - val_loss: 0.0292\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0322 - val_loss: 0.0301\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0321 - val_loss: 0.0293\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0323 - val_loss: 0.0305\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0325 - val_loss: 0.0300\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0325 - val_loss: 0.0306\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0325 - val_loss: 0.0306\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0326 - val_loss: 0.0305\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0320 - val_loss: 0.0305\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0328 - val_loss: 0.0309\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0323 - val_loss: 0.0291\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0325 - val_loss: 0.0298\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0327 - val_loss: 0.0300\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0324 - val_loss: 0.0318\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0325 - val_loss: 0.0297\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0321 - val_loss: 0.0300\n",
      "Epoch 23/100\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0326 - val_loss: 0.0292\n",
      "Epoch 24/100\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0322 - val_loss: 0.0312\n",
      "Epoch 25/100\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0325 - val_loss: 0.0298\n",
      "Epoch 26/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0326 - val_loss: 0.0300\n",
      "Epoch 27/100\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0327 - val_loss: 0.0309\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 29us/step - loss: 0.0325 - val_loss: 0.0364\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 39us/step - loss: 0.0323 - val_loss: 0.0406\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 40us/step - loss: 0.0331 - val_loss: 0.0355\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 52us/step - loss: 0.0324 - val_loss: 0.0373\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 39us/step - loss: 0.0323 - val_loss: 0.0399\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 33us/step - loss: 0.0323 - val_loss: 0.0505\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 47us/step - loss: 0.0327 - val_loss: 0.0540\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.0322 - val_loss: 0.0517\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.0329 - val_loss: 0.0500\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 44us/step - loss: 0.0328 - val_loss: 0.0447\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 32us/step - loss: 0.0330 - val_loss: 0.0353\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 39us/step - loss: 0.0333 - val_loss: 0.0402\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 34us/step - loss: 0.0330 - val_loss: 0.0395\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 28us/step - loss: 0.0332 - val_loss: 0.0335\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 36us/step - loss: 0.0332 - val_loss: 0.0348\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 22us/step - loss: 0.0336 - val_loss: 0.0396\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6300/6300 [==============================] - 0s 25us/step - loss: 0.0336 - val_loss: 0.0353\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 22us/step - loss: 0.0337 - val_loss: 0.0368\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 24us/step - loss: 0.0336 - val_loss: 0.0367\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 22us/step - loss: 0.0336 - val_loss: 0.0393\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 32us/step - loss: 0.0339 - val_loss: 0.0331\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.0344 - val_loss: 0.0307\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 45us/step - loss: 0.0340 - val_loss: 0.0324\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.0337 - val_loss: 0.0328\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 34us/step - loss: 0.0339 - val_loss: 0.0334\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 40us/step - loss: 0.0337 - val_loss: 0.0393\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 43us/step - loss: 0.0336 - val_loss: 0.0410\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 41us/step - loss: 0.0338 - val_loss: 0.0376\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 46us/step - loss: 0.0335 - val_loss: 0.0417\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 40us/step - loss: 0.0336 - val_loss: 0.0411\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 32us/step - loss: 0.0335 - val_loss: 0.0363\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 43us/step - loss: 0.0337 - val_loss: 0.0380\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 37us/step - loss: 0.0338 - val_loss: 0.0368\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 39us/step - loss: 0.0338 - val_loss: 0.0370\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 38us/step - loss: 0.0337 - val_loss: 0.0367\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 35us/step - loss: 0.0342 - val_loss: 0.0334\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 37us/step - loss: 0.0342 - val_loss: 0.0381\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 36us/step - loss: 0.0341 - val_loss: 0.0352\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 22us/step - loss: 0.0341 - val_loss: 0.0357\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 25us/step - loss: 0.0340 - val_loss: 0.0349\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 21us/step - loss: 0.0340 - val_loss: 0.0337\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 23us/step - loss: 0.0339 - val_loss: 0.0316\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 23us/step - loss: 0.0342 - val_loss: 0.0313\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 24us/step - loss: 0.0340 - val_loss: 0.0323\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 24us/step - loss: 0.0340 - val_loss: 0.0305\n",
      "best reward is :  [0.77843321 0.73371429 0.67053061 0.52826329 0.52713358]\n",
      "reward is :  [0.39681588 0.77843321 0.67053061 0.52826329 0.73371429]\n",
      "regrets is :  [ 0.38161733 -0.04471892  0.          0.         -0.20658071] \n",
      "\n",
      "best reward is :  [0.57279912 0.52563166 0.5024671  0.45945791 0.4146495 ]\n",
      "reward is :  [0.5024671  0.16742301 0.27952041 0.01498127 0.15051765]\n",
      "regrets is :  [0.07033202 0.35820866 0.2229467  0.44447664 0.26413185] \n",
      "\n",
      "best reward is :  [0.58826957 0.54778001 0.53981264 0.47545472 0.42021456]\n",
      "reward is :  [0.24782609 0.33843321 0.53981264 0.30033701 0.40989565]\n",
      "regrets is :  [0.34044348 0.2093468  0.         0.17511771 0.01031891] \n",
      "\n",
      "best reward is :  [0.78782609 0.58111966 0.55781362 0.54113485 0.48256035]\n",
      "reward is :  [0.78782609 0.30671748 0.08056552 0.01498127 0.16371429]\n",
      "regrets is :  [0.         0.27440218 0.4772481  0.52615358 0.31884606] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 21us/step - loss: 0.0338 - val_loss: 0.0300\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.0338 - val_loss: 0.0309\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.0338 - val_loss: 0.0285\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.0337 - val_loss: 0.0316\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.0339 - val_loss: 0.0302\n",
      "best reward is :  [0.67211896 0.53029744 0.48627175 0.44419624 0.38328602]\n",
      "reward is :  [0.22577342 0.38328602 0.44419624 0.25983409 0.3785671 ]\n",
      "regrets is :  [0.44634554 0.14701141 0.0420755  0.18436216 0.00471892] \n",
      "\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 86us/step - loss: 0.0563 - val_loss: 0.0309\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0282 - val_loss: 0.0289\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0281 - val_loss: 0.0281\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0277 - val_loss: 0.0280\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0278 - val_loss: 0.0284\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0280 - val_loss: 0.0286\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0277 - val_loss: 0.0280\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0277 - val_loss: 0.0288\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0278 - val_loss: 0.0277\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0274 - val_loss: 0.0292\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0282 - val_loss: 0.0283\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0277 - val_loss: 0.0285\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0278 - val_loss: 0.0281\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0277 - val_loss: 0.0278\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0280 - val_loss: 0.0282\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0283 - val_loss: 0.0277\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0277 - val_loss: 0.0298\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0285 - val_loss: 0.0289\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0280 - val_loss: 0.0284\n",
      "100\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 30us/step - loss: 0.0276 - val_loss: 0.0310\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 28us/step - loss: 0.0279 - val_loss: 0.0314\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 30us/step - loss: 0.0284 - val_loss: 0.0303\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 24us/step - loss: 0.0279 - val_loss: 0.0316\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 27us/step - loss: 0.0279 - val_loss: 0.0309\n",
      "200\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 20us/step - loss: 0.0280 - val_loss: 0.0337\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 25us/step - loss: 0.0281 - val_loss: 0.0337\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 28us/step - loss: 0.0284 - val_loss: 0.0333\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 24us/step - loss: 0.0286 - val_loss: 0.0334\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 30us/step - loss: 0.0286 - val_loss: 0.0372\n",
      "300\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 36us/step - loss: 0.0284 - val_loss: 0.0331\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5850/5850 [==============================] - 0s 30us/step - loss: 0.0289 - val_loss: 0.0364\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 23us/step - loss: 0.0284 - val_loss: 0.0321\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 23us/step - loss: 0.0286 - val_loss: 0.0295\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 22us/step - loss: 0.0284 - val_loss: 0.0377\n",
      "400\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 20us/step - loss: 0.0286 - val_loss: 0.0323\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 22us/step - loss: 0.0285 - val_loss: 0.0320\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 22us/step - loss: 0.0291 - val_loss: 0.0302\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 23us/step - loss: 0.0285 - val_loss: 0.0278\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 23us/step - loss: 0.0288 - val_loss: 0.0286\n",
      "500\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 33us/step - loss: 0.0289 - val_loss: 0.0239\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 23us/step - loss: 0.0286 - val_loss: 0.0282\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 22us/step - loss: 0.0287 - val_loss: 0.0266\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 23us/step - loss: 0.0287 - val_loss: 0.0252\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.0289 - val_loss: 0.0283\n",
      "600\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 33us/step - loss: 0.0285 - val_loss: 0.0279\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 49us/step - loss: 0.0289 - val_loss: 0.0290\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 1s 72us/step - loss: 0.0286 - val_loss: 0.0269\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.0284 - val_loss: 0.0304\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 1s 71us/step - loss: 0.0284 - val_loss: 0.0308\n",
      "700\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 1s 68us/step - loss: 0.0285 - val_loss: 0.0316\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 42us/step - loss: 0.0288 - val_loss: 0.0325\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 32us/step - loss: 0.0287 - val_loss: 0.0284\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 27us/step - loss: 0.0285 - val_loss: 0.0288\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 47us/step - loss: 0.0285 - val_loss: 0.0297\n",
      "800\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 42us/step - loss: 0.0285 - val_loss: 0.0347\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 48us/step - loss: 0.0287 - val_loss: 0.0314\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 43us/step - loss: 0.0285 - val_loss: 0.0320\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 46us/step - loss: 0.0285 - val_loss: 0.0319\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 47us/step - loss: 0.0284 - val_loss: 0.0324\n",
      "900\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 36us/step - loss: 0.0283 - val_loss: 0.0332\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 30us/step - loss: 0.0284 - val_loss: 0.0332\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 45us/step - loss: 0.0284 - val_loss: 0.0325\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 43us/step - loss: 0.0282 - val_loss: 0.0333\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 42us/step - loss: 0.0284 - val_loss: 0.0320\n",
      "best reward is :  [0.63008301 0.62966563 0.62315716 0.58812232 0.47642863]\n",
      "reward is :  [0.62315716 0.63008301 0.62966563 0.16499928 0.26768132]\n",
      "regrets is :  [ 6.92585260e-03 -4.17378028e-04 -6.50847458e-03  4.23123038e-01\n",
      "  2.08747309e-01] \n",
      "\n",
      "best reward is :  [0.50669649 0.496      0.48995349 0.48949153 0.44472727]\n",
      "reward is :  [0.48949153 0.44472727 0.496      0.43085714 0.18232558]\n",
      "regrets is :  [ 0.01720496  0.05127273 -0.00604651  0.05863438  0.26240169] \n",
      "\n",
      "best reward is :  [0.53877356 0.49136842 0.46623737 0.44995349 0.396     ]\n",
      "reward is :  [0.53877356 0.39371707 0.396      0.38013918 0.33160761]\n",
      "regrets is :  [0.         0.09765135 0.07023737 0.06981431 0.06439239] \n",
      "\n",
      "best reward is :  [0.636      0.63008301 0.62949153 0.58812232 0.47642863]\n",
      "reward is :  [0.62949153 0.63008301 0.636      0.16499928 0.26768132]\n",
      "regrets is :  [ 0.00650847  0.         -0.00650847  0.42312304  0.20874731] \n",
      "\n",
      "1000\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.0287 - val_loss: 0.0334\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 34us/step - loss: 0.0287 - val_loss: 0.0293\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 32us/step - loss: 0.0286 - val_loss: 0.0329\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.0286 - val_loss: 0.0302\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.0287 - val_loss: 0.0337\n",
      "best reward is :  [0.61561042 0.6057861  0.57704329 0.57409755 0.55719927]\n",
      "reward is :  [0.26415186 0.31371707 0.10909307 0.57704329 0.07504556]\n",
      "regrets is :  [ 0.35145856  0.29206903  0.46795022 -0.00294573  0.48215371] \n",
      "\n",
      "End of the simulations, time elapsed: 437.091 seconds.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdeXxkZZXw8d/p7HtS2fc9vW/YisosvjoqojO+7qAyqAjqiDqvCIKoIIqyIyiIqCAiIjI6iqCOiNu4ISjQ3el00ukk3dmXSlVqy1ZVz/vHUwmhSXenu1OpSup8P5/6dOreW/eem0rXqWcXYwxKKaUUwLpYB6CUUip+aFJQSik1T5OCUkqpeZoUlFJKzdOkoJRSap4mBaWUUvM0KSillJqnSUGtCBHpEZEZESk6YvszImJEpC42kcVO5HfyLydw/EtF5DERGReRURF5SETKF+y/RET2iohXRLpF5JJFrjcpIr7I45fHud6/iMjfRcQvIr0i8vbI9hYR+UkkhnER+R8RWX+i96/ikyYFtZK6gXPmnojIViAjduE8R0SS4/l8EQXAXUAdUAt4gXsWXhb498hxZwIXicjZR5zjX40x2ZHHa452IRHZBHwPuALIA3YAf4vszgceBtYDpcBfgZ+c0p2puKFJQa2k+7AfWnPOA76z8AARSRORG0XksIgMi8idIpIR2VcgIo9EvqG6Ij9XLXjtb0Xk8yLyx8i35V8eWTJZcOwrRKRPRD4pIkNEPlxF5A2R0otbRP4kItsWvOY0EXk6cu6HRORBEfnCyZxPRO4DaoCfRr61X3q8X54x5ufGmIeMMR5jTAD4KnDGgv3XG2P+bowJGmPasR/UZxztfMfxaeDrkWsGjTFOY8zByHX+aoz5ljFm3BgzC9wCrBeRwpO8loojmhTUSvoLkCsiG0UkCXgH8N0jjrkOaMF+M20CKoHPRvatw37Y1mI/UCexH4wLvRN4L1ACpAKfOEY8ZYAjcr4LReQ04G7gA0Ah8HXg4UiiSgX+G/h25DUPAG862fMZY84FDvPcN/frAURkt4i88xgxL/RPQOtiO0REgH9cZP/9kaT6SxHZfoxzvzRynj0iMigi3xURxzHiGDLGOJcYt4pnxhh96CPqD6AH+BfsN9AvYas3HgOSAYOtEhHADzQueN3LgO6jnHMH4Frw/LfApxc8/w/gF0d57SuAGSB9wbavAZ8/4rh24J+xH3z9gCzY9wfgCydzvoW/k5P8fW4DxoF/PMr+zwHPAmkLtp2Bra7LBC4HhoD8o7x+JhJfC5AN/BC4f5HjqiK/l3Ni/Temj+V5RKPeU6ljuQ/4PVDPEVVHQDH2A+tv9osuYBNFEoCIZGKrKs7E1psD5IhIkjEmFHk+tOB8AewH2tGMGmOmFjyvBc4TkY8s2JYKVGATV7+JfBJG9J7C+U6aiDQBPwc+Zoz530X2X4StpvtHY8z03HZjzB8XHPYlETkPW5r46SKXmQTuMcZ0RM75ReBXR1ynGPglcIcx5oFTuScVP7T6SK0oY8whbIPzWcCPjtg9hv0w2myMyY888owxcx/sF2MbN083xuRiv72DTRwnFc4Rz3uBaxZcO98Ykxn5wBsEKmVBtgKqT+F8ix1/XCJSi/1w/rwx5r5F9r8PuAx4lTGm7zinMxz9d7f7WPGJSAE2ITxsjLlmKbGr1UGTgoqF84FXGmP8CzcaY8LAN4BbRKQEQEQqReS1kUNysEnDHanfvnKZ4/oG8EEROV2sLBF5vYjkAH8GQtgePcki8kbgJadwPoBhoGGpwYlIJfBr4HZjzJ2L7H8X8EXg1caYriP21YjIGSKSKiLpYrurFgF/PPI8EfcA7xWRhkgJ7ZPAI5Fz5QL/A/zRGHPZUuNXq4MmBbXijDEHjTFPHWX3J4FO4C8i4sF+K57rA/9lbJ34GLbR+hfLHNdTwAXYxmtXJI73RPbNAG/GJjQ38G7sh+T0Yuc63vkivgR8OtIz6RMAItIa+XBfzPuxSeRKeW6sgW/B/i9gG7SfXLB/LnnkYNs4XNg2gDOB15lI47CIvEtE5huljTF3Y6v3ngAORe7zo5HdbwJejE0avgWPmqP9LtTqIc+vIlVKLZWIPAHcaYy557gHK7VKaElBqSUSkX8WkbJI9dF52B5Ay1paUSrWtPeRUku3HvgBtkfTQeCtxpjB2Iak1PLS6iOllFLztPpIKaXUvFVdfVRUVGTq6upiHYZSSq0qf/vb38aMMcWL7VvVSaGuro6nnjpaz0allFKLEZFDR9sXteqjyACZv4rIs5G+15+LbK8XkSdE5EBklsnUyPa0yPPOyP66aMWmlFJqcdFsU5jGjlrdjp247EwReSl2FsxbjDHN2IE050eOPx87uVkTdn6b66IYm1JKqUVELSkYa260ZUrkYYBXAv8V2X4v8H8jP78x8pzI/lcdMc+MUkqpKItq7yMRSRKRZ4AR7DTJBwG3MSYYOaQPO18+kX97ASL7J7BD9pVSSq2QqCYFY0zIGLMDO+f6S4CNix0W+XexUsELBlGIyIUi8pSIPDU6Orp8wSqllFqZcQrGGDd2AZSXAvny3Pq1VcBA5Oc+IlMRR/bnYRcROfJcdxljdhljdhUXL9qjSiml1EmKZu+jYhHJj/ycgV11qw34DfDWyGHn8dyC3w9HnhPZ/2ujw62VUmpFRXOcQjlwb2Qt3nXAD4wxj4jIPuD7Yhc8fxr4VuT4bwH3iUgntoRwdhRjU0qpVckYw6FDhygqKiI7+1gLC56cqCUFY8xuYOci27tYZHGSyDKGb4tWPEoptdpNT0+zd+9evF4v4XB4dSUFpZRSy8fr9bJ3716CwSDNzc1UVJzSUt9HpUlBKaXiWCgUYu/evbhcLlJSUtixYwc5OTnHf+FJ0qSglFJxKhgMsmfPHjweDw0NDZSXl5OSkhLVa2pSUEqpOGOMYXx8nJ6eHnw+Hxs2bKC0tHRFrq1JQSml4kg4HKatrY3R0VHS0tJWNCGAJgWllIoLxhhGR0fp6ekhEAhQU1NDTU0Nyckr+zGtSUEppWIoFArh8/no7OzE6/WSnJzMpk2bKCkpiUk8mhSUUioGjDF0d3dz+PBhAFJSUti0aRNFRUWsWxe7lZI1KSil1Arz+/10dHQwMTFBaWkpBQUFOBwOUlNTYx2aJgWllFopxhj6+/vp6uoCoKWlhfLycuJp6RhNCkoptQKMMXR0dDA4OEhhYSHNzc2kp6fHOqwX0KSglFJRFgwGOXDgAMPDw9TW1lJXVxdXpYOFNCkopVQUhcNh9u7di9vtpqamJq4TAmhSUEqpqAkGg/MJoaWlJWqT2C0nTQpKKbXMJicncTqdHD58mNnZWRobG1dFQgBNCkoptSxmZ2cZGBjA6/XidDoxxpCRkcHmzZvJy8uLdXhLpklBKaVO0eTkJK2trfh8PtLS0qiqqqK8vJyMjIy4bj9YjCYFpZQ6ScYY+vr66OnpQUTYsmULRUVFsQ7rlGhSUEqpk+D1euns7GRiYoLCwkKamprIyMiIdVinTJOCUkotUTgcpru7m9HRUaampkhOTqahoYHq6upVV010NJoUlFJqCaanp9mzZw8+n4/8/HyqqqooKytb8amto21t3Y1SSkWB1+ultbWV2dlZNm7cSElJyZopGRxJk4JSSh2FMYa2tjZGRkZISUlh69at5OfnxzqsqNKkoJRSi1g4vXVZWRn19fWkpaXFOqyo06SglFJHOHz4MN3d3SQlJdHc3ExFRcWarS46UtSW9xGRahH5jYi0iUiriHwssv0qEekXkWcij7MWvOZyEekUkXYReW20YlNKqSOFw2F6enrYvXs3XV1d5OTk8OIXv5jKysqESQgQ3ZJCELjYGPN3EckB/iYij0X23WKMuXHhwSKyCTgb2AxUAL8SkRZjTCiKMSqlFMPDw/T39+PxeMjMzKSiooLm5uaESgZzopYUjDGDwGDkZ6+ItAGVx3jJG4HvG2OmgW4R6QReAvw5WjEqpRKbMYbOzk76+/tJT09n/fr1lJeXxzqsmFqR1aFFpA7YCTwR2XSRiOwWkbtFpCCyrRLoXfCyPhZJIiJyoYg8JSJPjY6ORjFqpdRa5vf7aWtro7+/n4qKCk4//fSETwiwAklBRLKBHwL/aYzxAF8DGoEd2JLETXOHLvJy84INxtxljNlljNlVXFwcpaiVUmtVOBzmwIEDPPnkk4yMjFBaWpqwVUWLiWrvIxFJwSaE+40xPwIwxgwv2P8N4JHI0z6gesHLq4CBaManlEocxhg8Hg8HDx7E4/FQUVFBbW1tQnQzPRFRSwpi0+63gDZjzM0LtpdH2hsA3gTsjfz8MPA9EbkZ29DcDPw1WvEppRJDIBCgv7+f0dFRZmZmEBFtOziGaJYUzgDOBfaIyDORbZ8CzhGRHdiqoR7gAwDGmFYR+QGwD9tz6cPa80gpdSqmp6d55plnCAaDOBwOiouLKSwsXHPzFS2naPY++gOLtxP87BivuQa4JloxKaUSh9PppLW1FYDTTjuN7OzsGEe0Omi6VEqtKaFQiIGBAbq7u0lPT2fjxo2aEE6AJgWl1JoQDofp6upiYGCAcDhMbm4uW7ZsITU1NdahrSqaFJRSq54xhn379jE2NkZJSQmVlZXk5eXFOqxVSZOCUmpVm5qaoqOjg/HxcRoaGqipqYl1SKuaJgWl1Ko1OzvLvn378Hq9VFVVUV1dffwXqWPSpKCUWpXmpqnw+Xxs3LiR0tLSWIe0JmhSUEqtKsFgkLa2NpxOJ8nJyWzdupXCwsJYh7VmaFJQSq0Kk5OT9Pf3Mzg4SCgUoqamhsrKSp2mYplpUlBKxTVjDE6nk3379mGMobi4mPLycgoKCo7/YnXCNCkopeJSOBxmeHiYvr4+/H4/GRkZbN26lczMzFiHFnNuN4hANHrdrsh6CkopdSI8Hg9PPvkk7e3tAGzYsIEXv/jFCZ8Qxsfhs5+F2lq44YboXENLCkqpuBEKhTh06BCHDx8mJSWFzZs3U1RUlPBrHTidcPPN8JWvgNcLb34zvPWt0bmWJgWlVMwZY3C73bS3tzM1NUVZWRkNDQ0JP0XF2BjcdBN89avg99tE8OlPw7Zt0bumJgWlVMzMNSIfPnwYj8dDRkYG27Ztw+FwxDq0mBoZgRtvhDvugEAA3vEOmww2b47+tTUpKKVW1MzMDNPT04yOjjI0NMTMzAxpaWk0NjZSUVFBUlJSrEOMGZcLrr8ebrsNpqbgnHNsMtiwYeVi0KSglFoRgUCA9vZ2PB4Pxtjl1wsKCmhsbKS4uJh16xK338vwMNx6qy0ZeDw2GXz2s7B+/crHoklBKRV1Xq+XvXv3Eg6HqaqqIi8vj9TUVHJychK6EfnQIVsyuPtumJ5emTaD49GkoJSKGq/XS29vLyMjIyQlJbFjxw5ycnJiHVbMtbfbBuRvf9s+//d/h0svhZaWmIYFaFJQSkWBMYauri56e3tJTk6mrKyMuro60tPTYx1aTB06BJdfDg88AKmpcMEFcNllEE+Tu2pSUEotq1AoxMGDBxkYGKCkpITm5mZSUlJiHVZM9fTYMQa33w7r1sGnPgUf/SjE48SumhSUUstmZmaG3bt34/P5qK6upqGhIaHbDJ580o48/uEP7bQU73oXXHMNVFXFOrKj06SglDplU1NTHDp0iOHhYYwxbNmyhaKioliHFRPhMPz857YB+fe/t/MTfeITcNFF8VVNdDSaFJRSJy0YDDI8PEx3dzfBYBCHw0F1dXVCzmDq98P999uupfv22QRw003w/vdDbm6so1s6TQpKqRMWDAY5ePAgg4ODAOTm5rJhw4aEnLDu8GHbXvCNb8DEBGzfDvfdZ0chr8amFE0KSqklM8YwODhIX18fgUCA8vJyiouLKSgoSLi2g7Y2uO46Wzowxo4x+MhH4OUvt+0Hq1XUkoKIVAPfAcqAMHCXMeZWEXEADwJ1QA/wdmOMS+xf1K3AWUAAeI8x5u/Rik8ptXShUIiRkRG6urqYnZ0lMzMzYZfBfPJJuPZa+O//hvR0+PCH4eMfh5qaWEe2PKJZUggCFxtj/i4iOcDfROQx4D3A48aYa0XkMuAy4JPA64DmyON04GuRf5VSMTQ2NkZHRwczMzPk5OTQ3NxMcXFxwpUMfvtbuPpq+M1vbOPxFVfYbqXFxbGObHlFLSkYYwaBwcjPXhFpAyqBNwKviBx2L/BbbFJ4I/AdYydF+YuI5ItIeeQ8SqkVNjU1xf79+3G73WRkZLBp0yaKiooSao4iY2wyuOoq25OorMx2Mb3wwtXVeHwiVqRNQUTqgJ3AE0Dp3Ae9MWZQREoih1UCvQte1hfZ9rykICIXAhcC1KyV8ppScWSu3aCrq4twOExDQwOVlZUJN3vpn/5kSwO//S1UVNiZS9//fsjIiHVk0RX1pCAi2cAPgf80xniOUeRcbId5wQZj7gLuAti1a9cL9iulTl4gEKC1tRW/309OTg4tLS0JN1fRM8/YSekefdSOOL7tNjsdRaLM0BHVpCAiKdiEcL8x5keRzcNz1UIiUg6MRLb3AQuHdlQBA9GMTyllTU5O0tfXx9DQECJCc3MzFRUVCdVu8MwzdrTxf/0X5OfDl75kexNlZcU6spUVzd5HAnwLaDPG3Lxg18PAecC1kX9/smD7RSLyfWwD84S2JygVXaFQiK6uLgYHBwmHwxQWFtLY2Jgw4w2MgT/8wXYtffRR207w6U/DxRfbxJCIollSOAM4F9gjIs9Etn0Kmwx+ICLnA4eBt0X2/QzbHbUT2yX1vVGMTamENzk5yd69e/H7/ZSWllJTU0NWgnwtnp218xHddBM89RQUFsLnP2+nokjUZDAnmr2P/sDi7QQAr1rkeAN8OFrxKKWeMzw8THt7O+vWrUuo8QYeD9x1F9x8MwwO2vULvvY1OPfcxKsmOhod0axUgpgbgDY4OIjH4yEvL4+NGzcmxBoHQ0M2Edx5J3i98KpX2WkpXvc6O5W1eo4mBaXWOGMMTqeTzs5OpqamyMzMpLa2ltra2jU/5mBkxLYX3HEHzMzA294Gl1wCL3pRrCOLX5oUlFrDvF4vbW1tBAIBsrKy2L59O/n5+Wu+V5HTaQeZfeUrMDVlq4c+/Wloaop1ZPFPk4JSa4wxhvHxcXp7e3G73aSlpdHc3Ex5efmaLxm43XDLLfbh88E558BnPwvr18c6stVDk4JSa4jf72f//v14vV5SUlKora2lsrKS1NTUWIcWVT6fHWR2ww02MbzlLfC5z8HmzbGObPXRpKDUKjc7O8vw8DBOpxO3201ycjJNTU1UVFSs+ZKB3297D113HYyNwb/+q00GO3fGOrLVS5OCUquQMQav18vIyAgDAwOEw2EyMzMpLy+nrq5uzZcMvF64/Xbbo2h0FF7zGjuD6ek6r/Ip06Sg1CoSCoXo7++nr6+PmZkZAEpLS6muriY7OzvG0UWf222rib78ZXC54MwzbQPyGWfEOrK1Q5OCUquAx+NhYGAAp9PJ7OwsOTk5NDQ0UFBQQFpaWqzDi7qxMbv28W232QFo//ZvNhm8+MWxjmzt0aSgVBybmJjg4MGDeDwekpKSKCwspKKigry8vDXfrRTg0CHbeHz33TA5aZe8vOIK2LEj1pGtXZoUlIpDxhh6e3vp6uoiJSWFxsZGSktL13xbwZw9e2wyeOABu97xu98Nn/gEbNoU68jWPk0KSsUZn89HZ2cnbreb4uJi1q9fT3Ly2v+vaoxd3ey66+DnP7dzEV10kV3/uLr6+K9Xy2Pt/6UptUqEQiEOHjzIwMAAKSkpCbWmwW9/C1deaZNCcTF84QvwoQ+BwxHryBKPJgWl4sD09DR79+7F6/VSVlZGQ0PDmq8qCoXsGgY33wy/+11iLXkZzzQpKBVjXq+XPXv2EAqF2LJlC0VFRbEOKao8Httw/JWvQFcXVFXZLqYf+EDiLHkZzzQpKBVDY2NjtLW1kZKSwvbt29f0IjcjI7Yk8JWv2MTw8pfDtdfCm94ECdBksmroW6FUDBhj6OzspL+/n+zsbLZu3bpmxxu43XD99bY0MNet9NJLdYxBvFrSxCgi8rGlbFNKHZ8xhv3799Pf309lZSWnnXbamkwIg4N27YKaGvjSl+DNb4a2NnjoIU0I8Wyps2Wdt8i29yxjHEolhGAwyJ49exgeHqampoampqY1N2nd4cN24fuGBtuI/PrXw9NPw3e/Cxs2xDo6dTzHrD4SkXOAdwL1IvLwgl05gDOagSm11rjdbjo6OggEAjQ1NVFZWblmupsaA7/+tV3H4Gc/swPOzj0XPvMZaGyMdXTqRByvTeFPwCBQBNy0YLsX2B2toJRaSwKBAP39/fT395OSksK2bdtwrJEO+MbYbqVf+AI88QSUlsKnPgUXXAC1tbGOTp2MYyYFY8wh4BDwMhGpBZqNMb8SkQwgA5sclFKLCAQCDA0N0dvbizGG0tJSWlpaSEpKinVopywUgh/+EL74RXj2Wairs+savOc92q10tVtS7yMRuQC4EHAAjUAVcCfwquiFptTqNTg4SHt7OwAFBQU0NTWtie6ms7Pwve/ZhuP2drvM5be/De98J6SkxDo6tRyW2iX1w8BLgCcAjDEHRKQkalEptYqNjo7S0dFBbm4uLS0ta2Kdg6kp++F/3XXQ0wPbt8ODD9plL9dAwUctsNSkMG2MmZlrFBORZMBELSqlVqFgMEhXVxcDAwPk5OSwbdu2VT+Rnd8PX/863Hij7WJ6+ul28NnrX28bk9Xas9S+cL8TkU8BGSLyauAh4KfHeoGI3C0iIyKyd8G2q0SkX0SeiTzOWrDvchHpFJF2EXntydyMUrEyOzvLnj17GBgYoKysjJ07d67qhDAxAddcY9sKLr7YdiX91a/gz3+GN7xBE0IsBYNBBgYGcLvdUTn/Uv9qLwPOB/YAHwB+BnzzOK/5NvBV4DtHbL/FGHPjwg0isgk4G9gMVAC/EpEWY0xoifEpFRPGGJxOJwcOHGBmZoaNGzdSWloa67BO2tiYHXn81a/axHDWWXZRm5e/PNaRJTZjDNPT0/T19TE0NEQwGKSqqor8/Pxlv9Zxk4KIJAH3GmPeDXxjqSc2xvxeROqWePgbge8bY6aBbhHpxLZh/Hmp11NqpYXDYTo7OxkYGCAtLY2dO3eSm5sb67BOysAA3HQT3HmnnYriLW+xXUt37ox1ZInJGIPf78fj8eB0OnG5XITDYUSEoqIiqqurycnJicq1j5sUjDEhESkWkVRjzMwyXPMiEfl34CngYmOMC6gE/rLgmL7IthcQkQuxPaGoqalZhnCUOnGTk5Ps27cPr9dLZWUl9fX1q7K6qKfHNh7ffbftZvrOd8Lll8PGjbGOLPGEw2HGxsYYHR3F6/UyNTUFQFpaGqWlpWRlZVFYWEhGlOcVX+pfcQ/wx8ioZv/cRmPMzSd4va8Bn8c2Un8eOyDufcBiNZSLNmQbY+4C7gLYtWuXNnarFRcMBnn22WeZnp5m06ZNFBcXr7qRye3ttlvpd79rew+95z3wyU/aqSnUygkEArhcLjweD+Pj48zOzpKamkpubi41NTXk5+eTkZGxon9fS00KA5HHOuwUFyfFGDM897OIfAN4JPK0D1i44F5V5HpKxY3x8XGcTidjY2PMzMywY8cO8vLyYh3WCXn2WTvg7KGH7CCzj3zErn1cuWi5XC03YwxTU1O43W5GR0cZHx8HICUlhYKCAkpKSnA4HDGdD2tJScEY87nluJiIlBtjBiNP3wTM9Ux6GPieiNyMbWhuBv66HNdU6lQt7GoKkJ2dTXNz86pKCE88YXsT/fSnkJMDl10G//mfUKKjjaIuFArh8/nw+XwMDg7i8/kAmwiqq6uprKwkLS0tbkqbSx3R/FNeWJ0zgW0X+LoxZmqR1zwAvAIoEpE+4ErgFSKyI3KuHmxPJowxrSLyA2AfEAQ+rD2PVDzw+/20trYSCAQoLy+nsbFxVbUd/P73dl6ixx6z6x1ffTVcdBEUFMQ6srVpriTg9Xrx+/2Mj4/j9/sJh8MAZGZm0tTUhMPhWPFqoaUSY45fLS8itwLFwAORTe8AhrDzH+UaY86NWoTHsGvXLvPUU0/F4tJqDTPGMDY2hsvlYmhoCBFh/fr1lKySr9XGwG9+A5/7nE0KpaW2iuiDH4Q1MLg67hhj8Pl8jIyMMDg4SDAYnN+XlZVFQUEB+fn5ZGdnx02JQET+ZozZtdi+pX7l2WmM+acFz38qIr83xvyTiLSeeohKxQe/309XVxdOp50Z3uFw0NLSQvoqmOXNGDvA7Oqr4Q9/gIoKuPVWO2NplDusJJS5XkJut5tAIIDf72d2dhawfy9FRUXk5OSQnp5OcnJyXCSBE7HUpFAsIjXGmMMAIlKDnU4bYDm6qSoVcyMjI+zfvx8RoaGhgerq6lXxH9oY+OUvbcngz3+Gqio7+Oz883XG0uUSDAYZHR3F5XLhdDoJhUIkJSWRmZlJYWEh+fn5OBwOUlNTYx3qKVtqUrgY+IOIHMR2H60H/kNEsoB7oxWcUivBGENHRweDg4Pk5uayefPmVbE8ZjgMP/85fP7ztiG5uhruuAPe9z5YBeHHvXA4zMjIyHyvs1AoREpKCiUlJRQWFsa8l1C0LLX30c9EpBnYgE0K+xc0Ln85WsEpFW0LE0J5eTlNTU1xv96B3w/f+Y6tGmpvt2sg33mnHWugyeDUGGPwer0MDQ3hdDqZnp4mNTWVkpISysvLycnJWRWlx1Ox1N5HmcDHgVpjzAUi0iwi640xjxzvtUrFq1AoREdHB8PDw9TW1lJfXx/rkI5pchLuuceWDIaGYNcuuP9+eNvbdC2DU2GMweVyza+QNzk5iYjgcDhobm6msLBwzSeChZZafXQP8DfgZZHnfdiZUjUpqFUpEAjQ0dGB2+2mqqqKurq6WId0VG63rRb68pdhdNROTveDH8A//IPOVnoyZmZm8Hq9843F09PTz+syun79ehwOx6qoQoyGpSaFRmPMO0TkHABjzKQkUupUa4Yxhp6eHg4dOkRSUhIbNmygrKws1mEtanwcbrkFbrsNPB4480w76Oyf/kmTwYmanJxkZGSEsbExvF67ivC6detwOBwUFhaSm5tLXl4eqampCVUqWMxSk8JMZPSkFAgAACAASURBVF1mAyAijcB01KJSKgpmZmbYs2cPXq+XoqIiGhoayMzMjHVYL+B02lLBXDJ461t1xtKT4ff7cTqdDA0NEQgEAMjNzaW2tpaCggJyc3PXZEPxqVrK1NmCXY/5F0C1iNwPnAG8J7qhKbV8pqam2L17N1NTU3E7id3wsJ2++o47bGPym98MV14J27bFOrLVY3p6mqGhoeeVCOYSQXFx8ZpYGjXaljJ1thGRjwGvAV6K7X30MWPMWLSDU+pUGWMYGhriwIEDhMNhtm3bhsPhiHVYz9PXBzfcAHfdBTMzcPbZtmSweXOsI1s9gsEgfX199Pb2EgqFyM7OprGxkaKioqhPNb3WLLX66C9AgzHm0WgGo9RyCoVCPPvss3g8HnJzc2lpaYmrb4rd3XYtg3vusWMOzj3Xthm0tMQ6svg3MzOD0+lkdHSUQCAwv/ZAcXEx9fX1cVktuFosNSn8H+ADInIIu56CYAsRWrBVcWl8fJyOjg6mpqZoaWmhvLw8bqqLOjrsWgb33WfXMnjf++xaBnHcASouhEIhvF4vAwMDjIyMAJCRkUFubi5lZWUUFhZGbTWyRLLUpPC6qEah1DIJhUIMDAzQ1dVFRkZGXFUX7d1r1zJ48EFITbWzlX7iE3ZaCvV8wWAQv9/P5OQkPp8Pl8uF32/X90pKSqKqqorS0lKys7PjJtmvFUsd0Xwo2oEodaqcTift7e3MzMzgcDjYtGlTXExz3dYGV11lxxZkZdlE8PGP29lLlRUOh+c//EdHR+fXHJiTn59PXV3d/FxD8T7qfDWL/f8YpU7R7Owshw4doq+vj6ysLDZt2kR+fn6sw6Ktzc5Y+uCDNhlccQX8v/8HhYWxjix+GGNwOp0cOHCA6Wnby31uKcq5mUa1NLCyNCmoVWnuw2RuQFI4HKaiooKGhoaYlw727LENyN/7HmRmwqWXwsUXQ3FxTMOKG+FwmImJCdxuNx6PB5fLRWZmJps2bSI3N3dVTFO+lmlSUKuOz+ejvb0dr9dLSkoKxcXFVFVVxbyRsbXVTl/90EM2GVxyia0qSuRkEAwGcTqdjI+P43a7mZ2dnZ9SAiAtLY2mpiYqKip0IFmc0KSgVo3p6Wk6OzsZHR0lKSmJ9evXU1ZWFvOqhf/9X7j+enjkEbuy2Wc+Y9c/jpP27RVljGF6ehqv18vIyAhOp5NwODy/MH1aWhpJSUlkZ2dTUFCgbQNxSJOCinvGGDweD/v27WN2dpby8nLq6upiPmHZ7t22JPDYY1BUZBuTL7oosdoMQqHQ/Opj4+PjuFyu+VXI1q1bR0lJCWVlZeTl5cU8eaul0aSg4prP56OtrQ2/309KSgqnnXZazAegDQzYBuRvfAPy8+3UFB/8oK0yShQul4ve3l5cLhdz67wnJSVRWFhIXl4eOTk5ZGdna5XQKqRJQcUdYwyjo6M4nU6Gh4dJTU1l/fr1FBcXx7QRub3dTlJ3990QDNpSwZVXJkY1kTGGyclJBgcHGRkZYXp6mrS0NCorK8nLyyMjI4OsrCwtDawBmhRU3AiHw/T19TEwMDA/bUFpaSlNTU2kxHAVmYXjDFJT4d3vtt1LGxpiFtKKCYVC9PT0MDw8zMyMXY69sLCQiooKqqurtSSwBmlSUHFhenqatrY23G43ubm51NfXU1RUFNOGyIMHbW+i+++3VUNXXAEf/SiUlMQspBVjjGFwcJDe3l4mJycpLi6moKAAh8OhXUbXOE0KKqZCoRBtbW04nU5EJC4WvenqsnMT3XOPLRlcfLEda1BUFNOwVoQxhpGREbq7u5mamiInJ4ft27dTUFAQ69DUColaUhCRu4E3ACPGmC2RbQ7gQaAO6AHeboxxRdZsuBU4CwgA7zHG/D1asan4EAwGaW1txeVyUV1dTXl5eUxnt2xttcnggQfsmscf/jBcfjnE6cJsy25qaorW1la8Xi85OTnU19dTUlKi7QQJJpoVgt8Gzjxi22XA48aYZuDxyHOwE+41Rx4XAl+LYlwqxowx9Pf389RTT+FyuWhpaaGxsTFmCWH/fnjLW2DLFvjxj+1UFN3dcOutiZMQ/H4/Tz/9NIFAgJaWFk477TRKS0s1ISSgqCUFY8zvgfEjNr8RuDfy873A/12w/TvG+guQLyLl0YpNxY4xhu7ubg4cOEBSUhLbtm2joqIiJrEMDcGHPmSTwWOP2UFnhw7BjTdCeQL99Xk8Hp5++mmMMezcuZOKigpNBglspdsUSo0xgwDGmEERmWuyqwR6FxzXF9k2eOQJRORCbGmCmpqa6Earlo3P58Pr9TI8PIzb7aa8vJyWlpaYfPgMDdkRyF/7mu1a+h//YRNCok1HMdeY3NnZSVpaGtu2bdNVylTcNDQv9slgFjvQGHMXcBfArl27Fj1GxY/p6Wm6u7sZGhoC7CjXmpoa6uvrVzwhDA8/lwxmZuxKZ1dcAU1NKxpGXJiZmWH//v2Mj4+Tn5/Ppk2bSE1NjXVYKg6sdFIYFpHySCmhHBiJbO8DqhccVwUMrHBsahmFQiG6u7sZGBiYn8G0urqa9PT0mCSDG26AO+6A6WmbDD796cRMBgCBQIA9e/YwPT1Nc3OzVhep51nppPAwcB5wbeTfnyzYfpGIfB84HZiYq2ZSq4sxZn5qikAgQFlZGbW1tTGplhgZscng9tttMnj3u20yaG5e8VDixujoKO3t7YgIO3bsIDc3N9YhqTgTzS6pDwCvAIpEpA+4EpsMfiAi5wOHgbdFDv8ZtjtqJ7ZL6nujFZeKnqmpKfbs2YPf7yc5OZkdO3bEZLGbkRHbWHz77TA1Be96l00GLS0rHkrcmBuZ3NvbS05ODps2bdL2A7WoqCUFY8w5R9n1qkWONcCHoxWLij6/38/u3bsJhUI0NDRQVla24nXUo6M2GXz1qzYZvPOdNhmsX7+iYcSduRlmp6amKC8vp7m5WaenUEcVLw3NapUyxtDX10d3d/d86WClZzEdG3suGQQCzyWDDRtWNIy4NDIyQltbG6mpqToyWS2JJgV1UuaWw+zu7sbv95Obm8uGDRtWdADa2JidtvorX7HJ4JxzbNdSTQZ2tHhPTw99fX3k5eWxZcuWmE4qqFYPTQrqhHm9Xjo6OvB6vaSnp7N582aKiopWrAeL0/lcMvD74eyzbTLYuHFFLh/3XC4Xra2tBINBysvLaWpq0hXO1JJpUlBLFg6H6e3tpaenZ345zNLS0hWrnx4ft8ngtttsMnjHO2wy2LRpRS4f91wuFz09PUxMTJCZmcn27dtjvm61Wn00KaglmZiYoKOjA7/fT3FxMS0tLStWHeH32wFn11wDExPw9rfbZLB584pcPm4ZYxgfH8fr9eJyuZiYmCA9PZ3a2lqqqqq0ukidFE0K6phCoRCDg4McPHiQ5ORktmzZQtEKzSE9MWG7ld5yi20/eO1r7biDrVtX5PJxZy4JBAIBfD4fExMT84sRpaenU19frwvfqFOmSUEd1dTUFHv37sXn8+FwONi0adOKLIfpdNoZSm+7zSaGs86y01G8/OVRv3RcCYfDBAIBwuEwHo+HgYEBAoEAYNdDzsnJoaGhAYfDEdNlStXaon9JalEej4c9e/YQDodZv349ZWVlUW9Ibm+33UrvucdWGb35zfCpT8GLXhTVy8aV6elp3G43ExMTDA8PEwqF5vdlZWWxadMm8vPzdZ4iFTWaFNTzGGNwu93s27ePpKQkdu7cGfVupnOL23zve3Zxm3e8w650tmVLVC8bF4LBINPT00xOTtLb28vExARgSwL5+fkUFxeTkpJCamoq2dnZOkeRijpNCmpeKBSio6OD4eFhUlJS2Lp1a1QTwt69cNVV8MMfQlaWTQQf//jaXgM5HA7j9/sZGxtjYmICt9s9vy8tLY36+nocDocmABUzmhQUAJOTk7S2tuLz+aiurqauri5qfdt//3u4+mp4/HHIyYHPfhY++lEoLIzK5eKCMYbR0VEOHDjA7OwsIkJaWhq1tbVkZWWRkpJCXl6eNhKrmNOkkOCCwSD9/f0cPnwYEYla76JwGH7+c7j2WvjDH6C01P78/vev7WQQDocZGxvj0KFD+P1+srOzaWpqoqCgQNsFVFzSpJCgwuEwfX19DAwMMDU1RV5eHhs3biQ9PX1ZrzM7C9//Plx3nW07qK62PYve/36I0ZLMURUOh/F6vbjdblwuFz6fj2AwSEZGBhs3bqSkpESrhVRc06SQgJxOJ4cPH2ZiYoLs7Gx27txJXl7esl4jEIBvfctOVHf4sB1bcN99thF5rY2pmmucP3z4MD6fj9nZWQAyMzNxOBwUFRVRXFysyUCtCpoUEojf76erqwun00lycjIbNmygrKxsWa/hctlupbfdZgec/cM/2NHIr3sdrLXPxEAgwNDQECMjI0xNTZGamorD4aCwsJC8vDzS0tJiHaJSJ0yTQgIwxtDd3c3hw4dJSkqitraW2traZW3U7O+3I4+//nXw+eANb4BPftImhdXOGMPs7CxOp5PJyUlCoRAejwev1wuAw+GgpqaGsrIybShWq54mhTXOGENHRweDg4OUlZVRX1+/rN9g9++3VUTf+Y5tTD77bJsMVvtUFHNVQhMTE4yMjMyPJBYR1q1bR1ZWFvX19ZSVlWmJQK0pmhTWsFAoRFtbG2NjY9TU1NDQ0LBs5376aTtB3Y9+BGlpcMEF8IlPQH39sl1ixc3NLeRyuRgdHWV6ehqwI4kbGhrIyckhPz9f2wbUmqZJYY2amZnh6aefZnJykqamJqqqqpblvE88AV/4AjzyCOTm2mkoPvYxKC5eltPHhDEGl8tFV1cXPp8PsFVCTU1N5Ofn62yjKqFoUliDXC4XBw4cYHp6elnGHRgDv/udTQaPPw4Ohx189pGPQH7+MgW9goLBIH6/H4/Hw/j4OH6/n5mZGdLT09mwYQMlJSXaNqASliaFNcQYQ29vL11dXWRkZLBlyxYcDscpnM8OOLvmGvjTn+yAsxtugA98wI5EXk1CoRADAwP4fD7GxsbmJ5rLyMggLy+P/Px8ysvLNRmohKdJYY0Ih8Ps27ePsbExioqK2Lhx40lPU2EM/PjH8PnP27aDmhrbzfR974OMjGUOPArmGok9Hg+zs7OEQiGcTiczMzPz3UZLS0vJysoiPT1d2wiUWkCTwhowOTlJW1sbHo+HqqoqGhsbT+qDzhh49FE7F9HTT0NTkx2A9u53QzzPyGCMwefzMTU1RSAQwOl04vF4ADvbaFJSEpmZmWzevHnZB+kptdZoUljl/H4/f//73wmFQifdoGwMPPaYTQZPPAENDXDvvfDOd0I8r93i9/vp7+9nfHx8fgUygNTUVNavX09xcbEuPqPUCdL/MauUMYb+/n66u7tZt24dp512GllZWSd0jlAIHn4YbroJ/vhHW030jW/AeefF71QUMzMzDA8PMzIygtfrRUTIy8ujurqanJwcMjIySE5O1iohpU5STJKCiPQAXiAEBI0xu0TEATwI1AE9wNuNMa5YxBfvgsEge/bsYWJiAofDQXNzMxknUNk/MwP3329nKe3ogNpa22bw/vfbMQfxaHx8nJ6eHrxeL8YYsrOzqa2tpbKyUmcbVWoZxbKk8H+MMWMLnl8GPG6MuVZELos8/2RsQotfxpj59oOmpiYqKyuX/K14chK++U3bg6i3F7ZvtzOYvuUt8VVNZIwhEAjML0zvdDrx+/2kp6dTWVlJeXn5CZeKlFJLE0cfBbwReEXk53uB36JJ4XlCoRAHDx7E6XSeUPuBzwe33w433wwjI3DGGXaOojPPjK9J6iYnJ3G5XPNdR+fk5eXR2NhIZWWldhlVKspilRQM8EsRMcDXjTF3AaXGmEEAY8ygiCy6KKOIXAhcCFBTU7NS8cZcKBRi9+7dTExMUFFRQWVl5XFfMztr2wg+9zmbDF77Wrj8cvjnf16BgJdobmqJuaohsNNKNDc3k5ubS2ZmZtRWgFNKvVCsksIZxpiByAf/YyKyf6kvjCSQuwB27dplohVgPPH5fOzbt49AIMD69espLy8/5vGzs/CDH9j1jzs74R//EX7yE3jpS1cm3mOZmpqarxaanZ1lbGyMqakp0tPTaWxspKCggKysLG0oVipGYpIUjDEDkX9HROS/gZcAwyJSHikllAMjsYgtnsxNed3b20tKSgrbtm075gjlcNjOVnrllXZhmy1b7BxFZ50V+2oit9tNd3c3ExMTz9uen59PXV2dTi2hVJxY8aQgIlnAOmOMN/Lza4CrgYeB84BrI//+ZKVjiydut5uuri48Hg9FRUW0tLQcs5fNH/9oZyn9y1/gJS+xvYle/3qI5efs9PQ0w8PDDA0NEQgESE1NpaGhAYfDQWZmJiKiJQKl4kwsSgqlwH9HPgySge8ZY34hIk8CPxCR84HDwNtiEFvMBYNB9u/fz9jYGGlpaaxfv56ysrKjfnh2d8Nll9nqovJy+Pa34dxzY5cMpqamGBsbY3R0dL5UMDf1dGVlpbYPKBXnVjwpGGO6gO2LbHcCr1rpeOLJ1NQUe/fuxe/3U11dTV1d3VE/RIeG7Kyld91lu5NedZUtKcSip2YwGGR0dJTh4WHcbjcAaWlp1NTUUFJSQnZ29soHpZQ6KfHUJTVhBQIBhoeH6e/vJxgMsmnTJkpKFu18hcsF118Pt95qG5TPPx8+8xlYQmekZTM34dz4+Djj4+MEAgGMMaSkpFBXV0dRUZE2Fiu1SmlSiCFjDAMDA3R2dmKMweFw0NDQsOg3a7/fJoLrrwePB845x3Y1bWpauXjD4TDj4+N0dXXNL09ZUFBAYWEhhYWF5OTkaGOxUqucJoUYCAaDuFwu+vv7cbvd5ObmsmHDBjIzM19w7PS0rSK65hoYHoZ//VdbbbRt28rG29fXR19fH8FgkPT0dDZv3kxBQYFOOKfUGqP/o1fYzMwMzz77LH6/n+TkZGpqaqirq3vBN+xQCL77Xdu99NAhO+DsRz+Cl7985WL1+/3z1VqhUIi8vDxqamooKCjQEoFSa5QmhRU0OjrKwYMHmZmZOerUznML3FxxBbS1wYteZEsKr371yow1mBthfPjw4fneQ8XFxdTU1JCz2pZbU0qdME0KK8AYg9PpZN++faSlpbF9+/ZFF3v54x/h0kvt0pfr18NDD9nJ6lYiGfh8vvlEMD09Pd9oXFpaekIzsCqlVjdNClHm8/k4ePAgLpeLjIwMXvSiF72gdPDnP9seRI8/bsca3HUXvPe90Z+5NBwOMzY2Rn9/PxMTEyQlJVFYWEh+fj6lpaU6pkCpBKRJIYrGx8fZs2cPIkJtbS3V1dXPSwh79thqop/+FEpL4cYb4YMfjO5Yg8nJSXw+H36/n4GBAWZmZkhPT6e2tpaKigrS4nVBBaXUitCkECUej4fW1laysrLYtm3b86ao6OuzyeC++yA3F774RfjoR6OXDGZmZhgfH2dgYGB+7WKA3NxcGhsbKSkp0TEFSilAk8KyC4VC7N+/n9HRUdLS0ti6det8QvD57DiDG2+0k9ddcgl88pNwjDnuTko4HMbn8zE6Osr4+Dh+vx+AjIwMamtrKSoqIj09nZR4XXNTKRUzmhSWyVxj8sGDB5mcnKSyspLa2lpSU1MJheDee23pYGgIzj4bvvQlqKtb3hjC4TD9/f309PQQCoUAWxqoq6ujoKCA3NxcLREopY5Jk8IyCIfDdHR0MDQ0NF86KCwsBODXv4aPfxyefRZOP92ONXjZy5b3+nOL2R86dIhgMEhhYSGlpaXk5eVpG4FS6oRoUjhFU1NTtLa24vV6qaqqor6+nqSkJNrbbffShx+Gmhp44AF4xztOvXtpMBjE6/Xi9XqZmppiamoKl8uFMYbc3Fxqa2vnE5JSSp0oTQqnYHx8nLa2tvlJ7IqLixkfF66+Gu64AzIybDXRxz5mfz4ZwWAQp9PJ5OQk4+PjeL1ejLELziUnJ5Oenk5JSQlVVVU6uEwpdco0KZyE2dlZuru7GRgYIC0tjV27dpGSksWtt8LVV8PEBFxwgZ2wrrT05K4xOTnJ8PAww8PDTE5OApCTk0NVVRX5+flkZ2dr1ZBSatlpUjhBs7OzPP3000xOTlJaWkpTUzOPPprMJZfY9ZBf8xq46Sa7FOaJmpiYYGBggEAgML+IfWZmJlu3biU3N1d7Cymlok6TwgkYGRnh4MGDTE9Ps23bNnp6HLz61fC738HGjfCzn8GZZy693SAUCjE8PIzf78ftduP3+0lJSSErK4va2lrKy8tJT0+P7k0ppdQCmhSWaGBggI6ODjIyMigv38nHP57Hd74DhYW2/eCCC5Y2LcXMzAwDAwOMjIwwOTmJMYakpCRycnJobGykoqJCp5dQSsWMJoXjCAaDHDhwgOHhYbKzC3j00a1cf/06gkE7+OxTn4JF5rZ7gampKTo6OhgfHwfs+IHq6mocDgf5+flRvgullFoaTQpHYYxhbGyMzs7OyDQRVVxwQSOdncLb3w7XXgv19cc+h8fjwe12MzY2htfrZd26dVRVVVFeXk5mZqYOJFNKxR1NCouYnZ2ltbUVt9vNzEwWDz20mW9+M5eGBjuT6Stfufjr5pardLlc8+0EYBuLq6qqqKio0GmolVJxTZPCEXw+H3v37sXrneZ//7eRG26oIhwWLrkErroKjlwxMxgMMjk5yejoKIODg8zOzpKUlER6ejp1dXWUlZWRlpampQKl1KqgSSHCGEN/fz/d3T0880wSt912Gp2dOZxzjp3FdG6eImMMHo8Hl8uF2+1mYmJifjBZUVER5eXlulylUmrV0qSAXYv4wIED/P3vbh59NIdf/GIjmzdn8qc/2XmKgsEgQ0NjjIyM4PF4CAaDAGRlZVFdXU1ubi7Z2dnafVQpteolfFIYHh7mr39t59FHk3j44RZSU8v56lenee1rh3C5nDz11CSTk5OEQiGSk5MpKirC4XDoZHNKqTUp7pKCiJwJ3AokAd80xlwbjesYY+jqOsyDD3bz05/m0N9fwYc+5OOVr/wrs7OTdHRAWloaWVlZZGdnU1RURGFhobYNKKXWtLhKCiKSBNwOvBroA54UkYeNMfuW8zrGGH70o3Z+/OODjI4msXUrXHppO4WF68jJycfhqCQ3N5ecnBxNAkqphBJXSQF4CdBpjOkCEJHvA28EljUp3Hnnfv7856cwJpu3vKWUV7yieH7Bem0gVkolsnhLCpVA74LnfcDpCw8QkQuBCwFqampO6iL/9m/VjIxMcP75TVRWapWQUkrNibevxYt9OpvnPTHmLmPMLmPMruLi4pO6SGVlNlde+VKqqoo0ISil1ALxlhT6gOoFz6uAgRjFopRSCSfeksKTQLOI1ItIKnA28HCMY1JKqYQRV20KxpigiFwE/A+2S+rdxpjWGIellFIJI66SAoAx5mfAz2Idh1JKJaJ4qz5SSikVQ5oUlFJKzdOkoJRSap4mBaWUUvNkbi2A1UhERoFDJ/nyImBsGcNZDfSeE4Pec2I4lXuuNcYsOvp3VSeFUyEiTxljdsU6jpWk95wY9J4TQ7TuWauPlFJKzdOkoJRSal4iJ4W7Yh1ADOg9Jwa958QQlXtO2DYFpZRSL5TIJQWllFJH0KSglFJqXkImBRE5U0TaRaRTRC6LdTzLRUSqReQ3ItImIq0i8rHIdoeIPCYiByL/FkS2i4jcFvk97BaR02J7BydHRJJE5GkReSTyvF5Enojc74ORadgRkbTI887I/rpYxn0qRCRfRP5LRPZH3u+XreX3WUT+X+Rveq+IPCAi6WvxfRaRu0VkRET2Lth2wu+riJwXOf6AiJx3IjEkXFIQkSTgduB1wCbgHBHZFNuolk0QuNgYsxF4KfDhyL1dBjxujGkGHo88B/s7aI48LgS+tvIhL4uPAW0Lnl8H3BK5XxdwfmT7+YDLGNME3BI5brW6FfiFMWYDsB17/2vyfRaRSuCjwC5jzBbstPpnszbf528DZx6x7YTeVxFxAFdilzJ+CXDlXCJZEmNMQj2AlwH/s+D55cDlsY4rSvf6E+DVQDtQHtlWDrRHfv46cM6C4+ePWy0P7Op8jwOvBB7BLuk6BiQf+X5j1+l4WeTn5MhxEut7OIl7zgW6j4x9rb7PPLd2uyPyvj0CvHatvs9AHbD3ZN9X4Bzg6wu2P++44z0SrqTAc39gc/oi29aUSJF5J/AEUGqMGQSI/FsSOWwt/C6+DFwKhCPPCwG3MSYYeb7wnubvN7J/InL8atMAjAL3RKrNvikiWazR99kY0w/cCBwGBrHv299Y++/znBN9X0/p/U7EpCCLbFtT/XJFJBv4IfCfxhjPsQ5dZNuq+V2IyBuAEWPM3xZuXuRQs4R9q0kycBrwNWPMTsDPc1UKi1nV9x2p+ngjUA9UAFnYqpMjrbX3+XiOdp+ndP+JmBT6gOoFz6uAgRjFsuxEJAWbEO43xvwosnlYRMoj+8uBkcj21f67OAP4NxHpAb6PrUL6MpAvInOrCi68p/n7jezPA8ZXMuBl0gf0GWOeiDz/L2ySWKvv878A3caYUWPMLPAj4OWs/fd5zom+r6f0fidiUngSaI70XEjFNlg9HOOYloWICPAtoM0Yc/OCXQ8Dcz0QzsO2Ncxt//dIL4aXAhNzxdTVwBhzuTGmyhhTh30ff22MeRfwG+CtkcOOvN+538NbI8evum+QxpghoFdE1kc2vQrYxxp9n7HVRi8VkczI3/jc/a7p93mBE31f/wd4jYgUREpZr4lsW5pYN6rEqCHnLKADOAhcEet4lvG+/gFbTNwNPBN5nIWtT30cOBD51xE5XrA9sQ4Ce7C9O2J+Hyd5768AHon83AD8FegEHgLSItvTI887I/sbYh33KdzvDuCpyHv9Y6BgLb/P/P/27uZFpzCM4/j3V2qK7KxsLLzsRENekoUSStlJdl5S7GQ9kZU0Gwt/gKJmYS1FUkqMhWZiIVlYsWGBslEui/s4nqaGZ6bhCd9PmQPczAAAAdxJREFUPZ3Tc+5zuu/O4jrXebluuAi8AJ4D14Gxf/E8A1O05yZfaFf8JxdzXoET3fhfAccX0gfLXEiSev/j7SNJ0jwMCpKknkFBktQzKEiSegYFSVLPoCAtUpKzSZaPuh/SUvKVVGmRui+pt1bVu1H3RVoqZgrSEJKsSHIryWxX0/8CrQ7P/ST3uzb7kjxK8jTJza4GFUleJ7mc5En3W9f9f7g71mySB6MbnfSDQUEazgHgTVVtqlbT/wqtnsyeqtqTZBUwAeytqnHa18bnBvb/WFXbgKvdvgDngf1VtQk49KcGIv2MQUEazjNgb3fFv7uqPszZvoM2adPDJDO0GjVrBrZPDSx3dusPgWtJTtEmjpFGbtmvm0iqqpdJttBqSV1KcmdOkwB3q+rofIeYu15Vp5NsBw4CM0k2V9X7pe67tBBmCtIQkqwGPlfVDdqEL+PAJ2Bl1+QxsGvgecHyJBsGDnFkYPmoa7O2qqar6jxtdrDBcsfSSJgpSMPZCEwm+UqrYHmGdhvodpK33XOFY8BUkrFunwlaNV6AsSTTtAux79nEZJL1tCzjHjD7Z4Yizc9XUqXfzFdX9Tfx9pEkqWemIEnqmSlIknoGBUlSz6AgSeoZFCRJPYOCJKn3DcKX9M2YOJ2mAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "layers = [64]\n",
    "regret, regrets, _, _ = run_several_experiments_hist_DL_online(layers, evolutive_env = False, nb_exp = 20, nb_steps_history=1000)\n",
    "plot_regret(regret, regrets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation 0 started, time elapsed: 0.000 seconds.\n",
      "End of the simulations, time elapsed: 52.681 seconds.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "regret, regrets, rewards, _ = run_several_experiments_Dot(evolutive_env = True, nb_exp = 20, nb_steps = 1000, action_size = 5)\n",
    "plot_regret(regret, regrets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation 0 started, time elapsed: 0.000 seconds.\n",
      "End of the simulations, time elapsed: 30.977 seconds.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "regret, regrets, rewards, _ = run_several_experiments_Dot(evolutive_env = False, nb_exp = 20, nb_steps = 1000, action_size = 5)\n",
    "plot_regret(regret, regrets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation 0 started, time elapsed: 0.000 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 101us/step - loss: 0.1016 - val_loss: 0.1028\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0871 - val_loss: 0.0726\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0501 - val_loss: 0.0377\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0299 - val_loss: 0.0290\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0263 - val_loss: 0.0273\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0251 - val_loss: 0.0266\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0240 - val_loss: 0.0253\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0223 - val_loss: 0.0234\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0199 - val_loss: 0.0205\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0167 - val_loss: 0.0172\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0135 - val_loss: 0.0142\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0113 - val_loss: 0.0124\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0101 - val_loss: 0.0115\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0095 - val_loss: 0.0110\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0092 - val_loss: 0.0105\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0089 - val_loss: 0.0101\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0085 - val_loss: 0.0097\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0081 - val_loss: 0.0091\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0076 - val_loss: 0.0085\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0062 - val_loss: 0.0069\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0055 - val_loss: 0.0060\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 58us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "best reward is :  [0.76083145 0.68       0.64930511 0.64634829 0.59623431]\n",
      "reward is :  [0.76083145 0.68       0.64930511 0.64634829 0.59623431]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n",
      "best reward is :  [0.72606277 0.56134533 0.52482423 0.51159671 0.485346  ]\n",
      "reward is :  [0.72606277 0.51159671 0.56134533 0.52482423 0.47214866]\n",
      "regrets is :  [ 0.          0.04974861 -0.0365211  -0.01322751  0.01319733] \n",
      "\n",
      "best reward is :  [0.68284995 0.61700148 0.56440508 0.53257729 0.44931837]\n",
      "reward is :  [0.61700148 0.56440508 0.68284995 0.53257729 0.44931837]\n",
      "regrets is :  [ 0.06584847  0.0525964  -0.11844488  0.          0.        ] \n",
      "\n",
      "best reward is :  [0.61184165 0.53486166 0.51999893 0.51135778 0.49735849]\n",
      "reward is :  [0.61184165 0.53486166 0.51135778 0.48485281 0.49735849]\n",
      "regrets is :  [0.         0.         0.00864115 0.02650497 0.        ] \n",
      "\n",
      "best reward is :  [0.6403323  0.56550728 0.45102412 0.44930511 0.44032068]\n",
      "reward is :  [0.56550728 0.6403323  0.44930511 0.45102412 0.3975044 ]\n",
      "regrets is :  [ 0.07482501 -0.07482501  0.00171901 -0.00171901  0.04281628] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 94us/step - loss: 0.1081 - val_loss: 0.1109\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0904 - val_loss: 0.0747\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0506 - val_loss: 0.0372\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0297 - val_loss: 0.0269\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0258 - val_loss: 0.0247\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0247 - val_loss: 0.0238\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0241 - val_loss: 0.0232\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0234 - val_loss: 0.0223\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0223 - val_loss: 0.0211\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0205 - val_loss: 0.0194\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0178 - val_loss: 0.0168\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0146 - val_loss: 0.0141\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0117 - val_loss: 0.0118\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0083 - val_loss: 0.0091\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0068 - val_loss: 0.0074\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0058 - val_loss: 0.0063\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 84us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "best reward is :  [0.76062016 0.62153846 0.59642983 0.59119101 0.58621514]\n",
      "reward is :  [0.58621514 0.76062016 0.59119101 0.62153846 0.59642983]\n",
      "regrets is :  [ 0.17440502 -0.13908169  0.00523882 -0.03034745 -0.01021469] \n",
      "\n",
      "best reward is :  [0.69689418 0.64       0.56872441 0.53848564 0.47369498]\n",
      "reward is :  [0.69689418 0.64       0.56872441 0.53848564 0.47369498]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n",
      "best reward is :  [0.75642983 0.65073713 0.64621514 0.54480349 0.48900535]\n",
      "reward is :  [0.75642983 0.65073713 0.64621514 0.54480349 0.42294328]\n",
      "regrets is :  [0.         0.         0.         0.         0.06606206] \n",
      "\n",
      "best reward is :  [0.69642983 0.65073713 0.58621514 0.54480349 0.48900535]\n",
      "reward is :  [0.69642983 0.65073713 0.58621514 0.54480349 0.42294328]\n",
      "regrets is :  [0.         0.         0.         0.         0.06606206] \n",
      "\n",
      "best reward is :  [0.64475217 0.59642983 0.5490767  0.47191489 0.42574028]\n",
      "reward is :  [0.59642983 0.5490767  0.64475217 0.47191489 0.42574028]\n",
      "regrets is :  [ 0.04832234  0.04735313 -0.09567548  0.          0.        ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 96us/step - loss: 0.1184 - val_loss: 0.1129\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.1061 - val_loss: 0.0853\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0653 - val_loss: 0.0401\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0306 - val_loss: 0.0195\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0178 - val_loss: 0.0128\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0127 - val_loss: 0.0099\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0104 - val_loss: 0.0088\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0094 - val_loss: 0.0084\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0090 - val_loss: 0.0083\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0088 - val_loss: 0.0082\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0087 - val_loss: 0.0082\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0086 - val_loss: 0.0081\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0085 - val_loss: 0.0080\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0084 - val_loss: 0.0079\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0083 - val_loss: 0.0078\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0081 - val_loss: 0.0077\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0079 - val_loss: 0.0074\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0076 - val_loss: 0.0070\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0072 - val_loss: 0.0066\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0067 - val_loss: 0.0062\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0062 - val_loss: 0.0056\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "best reward is :  [0.77537913 0.54302837 0.53966878 0.46295615 0.46257205]\n",
      "reward is :  [0.77537913 0.54302837 0.44961475 0.53966878 0.46257205]\n",
      "regrets is :  [ 0.          0.          0.09005403 -0.07671263  0.        ] \n",
      "\n",
      "best reward is :  [0.76       0.70519856 0.663787   0.63766871 0.6191623 ]\n",
      "reward is :  [0.70519856 0.76       0.663787   0.6191623  0.63766871]\n",
      "regrets is :  [ 0.05480144 -0.05480144  0.          0.01850641 -0.01850641] \n",
      "\n",
      "best reward is :  [0.7106687  0.60317758 0.59147477 0.56669825 0.52158871]\n",
      "reward is :  [0.7106687  0.56669825 0.52158871 0.59147477 0.60317758]\n",
      "regrets is :  [ 0.          0.03647933  0.06988606 -0.02477652 -0.08158887] \n",
      "\n",
      "best reward is :  [0.63118471 0.56535574 0.55055429 0.54555297 0.50302445]\n",
      "reward is :  [0.54555297 0.63118471 0.55055429 0.56535574 0.50302445]\n",
      "regrets is :  [ 0.08563174 -0.06582897  0.         -0.01980277  0.        ] \n",
      "\n",
      "best reward is :  [0.77766871 0.68519856 0.68       0.6791623  0.66760563]\n",
      "reward is :  [0.6791623  0.77766871 0.68519856 0.66760563 0.68      ]\n",
      "regrets is :  [ 0.09850641 -0.09247016 -0.00519856  0.01155667 -0.01239437] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 88us/step - loss: 0.1100 - val_loss: 0.1117\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0991 - val_loss: 0.0876\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0627 - val_loss: 0.0457\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0337 - val_loss: 0.0290\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0251 - val_loss: 0.0232\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0197 - val_loss: 0.0177\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0147 - val_loss: 0.0133\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0099 - val_loss: 0.0101\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0092 - val_loss: 0.0098\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0089 - val_loss: 0.0096\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0086 - val_loss: 0.0093\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0083 - val_loss: 0.0091\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0079 - val_loss: 0.0087\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 54us/step - loss: 0.0074 - val_loss: 0.0083\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 55us/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0058 - val_loss: 0.0067\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 54us/step - loss: 0.0053 - val_loss: 0.0063\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 74us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 70us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 50us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 91us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 70us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 77us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 99us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "best reward is :  [0.75294733 0.64615976 0.63583678 0.63018614 0.60911194]\n",
      "reward is :  [0.75294733 0.64615976 0.63583678 0.63018614 0.60911194]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n",
      "best reward is :  [0.79136842 0.69321754 0.57443329 0.54540541 0.47387787]\n",
      "reward is :  [0.79136842 0.69321754 0.54540541 0.57443329 0.47387787]\n",
      "regrets is :  [ 0.          0.          0.02902788 -0.02902788  0.        ] \n",
      "\n",
      "best reward is :  [0.74362976 0.71217082 0.68362976 0.64620511 0.63332231]\n",
      "reward is :  [0.74362976 0.64620511 0.71217082 0.68362976 0.63332231]\n",
      "regrets is :  [ 0.          0.06596571 -0.02854105 -0.03742465  0.        ] \n",
      "\n",
      "best reward is :  [0.74145285 0.70332285 0.66566704 0.58620511 0.56924316]\n",
      "reward is :  [0.74145285 0.66566704 0.70332285 0.58620511 0.50260435]\n",
      "regrets is :  [ 0.          0.03765581 -0.03765581  0.          0.06663881] \n",
      "\n",
      "best reward is :  [0.75294733 0.65223881 0.64615976 0.63583678 0.60911194]\n",
      "reward is :  [0.75294733 0.64615976 0.63583678 0.65223881 0.60911194]\n",
      "regrets is :  [ 0.          0.00607904  0.01032298 -0.01640203  0.        ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 99us/step - loss: 0.0958 - val_loss: 0.0988\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0852 - val_loss: 0.0748\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0532 - val_loss: 0.0385\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0280 - val_loss: 0.0220\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0178 - val_loss: 0.0144\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0124 - val_loss: 0.0105\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0098 - val_loss: 0.0090\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0089 - val_loss: 0.0085\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 84us/step - loss: 0.0085 - val_loss: 0.0083\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0083 - val_loss: 0.0081\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0078 - val_loss: 0.0075\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0070 - val_loss: 0.0066\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0065 - val_loss: 0.0060\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0061 - val_loss: 0.0056\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 56us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 79us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 50us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 56us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 55us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 50us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "best reward is :  [0.65664748 0.60460875 0.48464484 0.47327227 0.42719097]\n",
      "reward is :  [0.60460875 0.65664748 0.47327227 0.42719097 0.48464484]\n",
      "regrets is :  [ 0.05203873 -0.05203873  0.01137257  0.0460813  -0.05745388] \n",
      "\n",
      "best reward is :  [0.61511962 0.5854603  0.55852165 0.51709091 0.50160618]\n",
      "reward is :  [0.61511962 0.5854603  0.55852165 0.51709091 0.50160618]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n",
      "best reward is :  [0.62963539 0.59816308 0.56434351 0.51266206 0.49278635]\n",
      "reward is :  [0.4686385  0.62963539 0.59816308 0.49278635 0.56434351]\n",
      "regrets is :  [ 0.16099689 -0.03147231 -0.03381957  0.01987571 -0.07155715] \n",
      "\n",
      "best reward is :  [0.68178628 0.56328276 0.53626481 0.50678175 0.48566255]\n",
      "reward is :  [0.56328276 0.45278635 0.68178628 0.50678175 0.53626481]\n",
      "regrets is :  [ 0.11850353  0.1104964  -0.14552148  0.         -0.05060226] \n",
      "\n",
      "best reward is :  [0.53850958 0.49725892 0.47542289 0.43280734 0.4286385 ]\n",
      "reward is :  [0.49725892 0.53850958 0.47542289 0.43280734 0.4286385 ]\n",
      "regrets is :  [ 0.04125066 -0.04125066  0.          0.          0.        ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 1s 118us/step - loss: 0.0894 - val_loss: 0.0924\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0826 - val_loss: 0.0760\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0557 - val_loss: 0.0405\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0271 - val_loss: 0.0206\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0153 - val_loss: 0.0135\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0088 - val_loss: 0.0096\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.0081 - val_loss: 0.0091\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 52us/step - loss: 0.0077 - val_loss: 0.0087\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 58us/step - loss: 0.0074 - val_loss: 0.0083\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0070 - val_loss: 0.0078\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0066 - val_loss: 0.0074\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 55us/step - loss: 0.0056 - val_loss: 0.0065\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0054 - val_loss: 0.0063\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0052 - val_loss: 0.0061\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0050 - val_loss: 0.0060\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0041 - val_loss: 0.0051\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 53us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 81us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 83us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "best reward is :  [0.71643032 0.46409266 0.45839142 0.45058824 0.44975838]\n",
      "reward is :  [0.71643032 0.45839142 0.44975838 0.46409266 0.45058824]\n",
      "regrets is :  [ 0.          0.00570124  0.00863304 -0.01350443 -0.00082986] \n",
      "\n",
      "best reward is :  [0.38092522 0.37659466 0.37058824 0.32667569 0.31465807]\n",
      "reward is :  [0.38092522 0.31204182 0.37058824 0.32667569 0.37659466]\n",
      "regrets is :  [ 0.          0.06455284  0.          0.         -0.06193659] \n",
      "\n",
      "best reward is :  [0.64975838 0.5410352  0.47222123 0.41142721 0.39544105]\n",
      "reward is :  [0.47222123 0.5410352  0.64975838 0.41142721 0.39544105]\n",
      "regrets is :  [ 0.17753714  0.         -0.17753714  0.          0.        ] \n",
      "\n",
      "best reward is :  [0.61642505 0.49107133 0.43301464 0.41966378 0.3849738 ]\n",
      "reward is :  [0.49107133 0.61642505 0.43301464 0.31303244 0.37864574]\n",
      "regrets is :  [ 0.12535371 -0.12535371  0.          0.10663134  0.00632806] \n",
      "\n",
      "best reward is :  [0.67976654 0.66127894 0.6256382  0.61517801 0.5396327 ]\n",
      "reward is :  [0.67976654 0.6256382  0.66127894 0.61517801 0.52736842]\n",
      "regrets is :  [ 0.          0.03564074 -0.03564074  0.          0.01226428] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 88us/step - loss: 0.0969 - val_loss: 0.1043\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0867 - val_loss: 0.0814\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0560 - val_loss: 0.0454\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 54us/step - loss: 0.0318 - val_loss: 0.0288\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 52us/step - loss: 0.0226 - val_loss: 0.0222\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0177 - val_loss: 0.0174\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0141 - val_loss: 0.0138\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 50us/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 85us/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0089 - val_loss: 0.0092\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 66us/step - loss: 0.0086 - val_loss: 0.0089\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0083 - val_loss: 0.0086\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0080 - val_loss: 0.0083\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 55us/step - loss: 0.0076 - val_loss: 0.0078\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0063 - val_loss: 0.0063\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0058 - val_loss: 0.0059\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "best reward is :  [0.73025559 0.72242641 0.66380952 0.53587025 0.53200172]\n",
      "reward is :  [0.72242641 0.53200172 0.66380952 0.73025559 0.45137465]\n",
      "regrets is :  [ 0.00782918  0.19042469  0.         -0.19438534  0.08062707] \n",
      "\n",
      "best reward is :  [0.61242718 0.61204301 0.54076336 0.43014085 0.41818182]\n",
      "reward is :  [0.61242718 0.61204301 0.54076336 0.41818182 0.43014085]\n",
      "regrets is :  [ 0.          0.          0.          0.01195903 -0.01195903] \n",
      "\n",
      "best reward is :  [0.52047769 0.4889921  0.48599066 0.45146383 0.41325881]\n",
      "reward is :  [0.48599066 0.52047769 0.4889921  0.31549658 0.45146383]\n",
      "regrets is :  [ 0.03448703 -0.03148559 -0.00300144  0.13596725 -0.03820502] \n",
      "\n",
      "best reward is :  [0.56170922 0.45404537 0.42746385 0.41499644 0.39767073]\n",
      "reward is :  [0.56170922 0.39767073 0.42746385 0.36532502 0.45404537]\n",
      "regrets is :  [ 0.          0.05637464  0.          0.04967142 -0.05637464] \n",
      "\n",
      "best reward is :  [0.63975822 0.62894825 0.60178862 0.58       0.5173607 ]\n",
      "reward is :  [0.62894825 0.58       0.63975822 0.60178862 0.5173607 ]\n",
      "regrets is :  [ 0.01080998  0.04894825 -0.0379696  -0.02178862  0.        ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 94us/step - loss: 0.0930 - val_loss: 0.0985\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0851 - val_loss: 0.0813\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0598 - val_loss: 0.0464\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0313 - val_loss: 0.0224\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 67us/step - loss: 0.0172 - val_loss: 0.0128\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 71us/step - loss: 0.0108 - val_loss: 0.0087\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 51us/step - loss: 0.0079 - val_loss: 0.0070\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "best reward is :  [0.5793824  0.49181368 0.48931273 0.48474035 0.47179718]\n",
      "reward is :  [0.48474035 0.47179718 0.5793824  0.48931273 0.49181368]\n",
      "regrets is :  [ 0.09464205  0.0200165  -0.09006968 -0.00457238 -0.0200165 ] \n",
      "\n",
      "best reward is :  [0.54626194 0.54200931 0.50620195 0.4869516  0.48216385]\n",
      "reward is :  [0.54626194 0.54200931 0.46294733 0.4869516  0.50620195]\n",
      "regrets is :  [ 0.          0.          0.04325462  0.         -0.0240381 ] \n",
      "\n",
      "best reward is :  [0.60423743 0.5369682  0.48400424 0.45858136 0.44502564]\n",
      "reward is :  [0.48400424 0.5369682  0.45858136 0.42736829 0.60423743]\n",
      "regrets is :  [ 0.12023319  0.          0.02542288  0.03121307 -0.15921179] \n",
      "\n",
      "best reward is :  [0.60423743 0.51211538 0.50782288 0.4824     0.44502564]\n",
      "reward is :  [0.50782288 0.51211538 0.4824     0.42736829 0.60423743]\n",
      "regrets is :  [ 0.09641455  0.          0.02542288  0.05503171 -0.15921179] \n",
      "\n",
      "best reward is :  [0.65530587 0.62464783 0.6063929  0.56198024 0.5513352 ]\n",
      "reward is :  [0.62464783 0.65530587 0.6063929  0.56198024 0.5513352 ]\n",
      "regrets is :  [ 0.03065804 -0.03065804  0.          0.          0.        ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 92us/step - loss: 0.1074 - val_loss: 0.1160\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0953 - val_loss: 0.0904\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0601 - val_loss: 0.0476\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0337 - val_loss: 0.0323\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0280 - val_loss: 0.0296\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0263 - val_loss: 0.0280\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0246 - val_loss: 0.0256\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0217 - val_loss: 0.0221\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0178 - val_loss: 0.0176\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 72us/step - loss: 0.0135 - val_loss: 0.0134\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0085 - val_loss: 0.0092\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0077 - val_loss: 0.0085\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0069 - val_loss: 0.0075\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0061 - val_loss: 0.0066\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0057 - val_loss: 0.0060\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 58us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 70us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "best reward is :  [0.61542857 0.60484371 0.5053138  0.49901049 0.48580153]\n",
      "reward is :  [0.61542857 0.60484371 0.5053138  0.49901049 0.48580153]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n",
      "best reward is :  [0.58327602 0.55596278 0.55130326 0.52816945 0.50254456]\n",
      "reward is :  [0.52816945 0.58327602 0.55130326 0.50254456 0.55596278]\n",
      "regrets is :  [ 0.05510657 -0.02731324  0.          0.02562489 -0.05341823] \n",
      "\n",
      "best reward is :  [0.69935663 0.59796757 0.58569853 0.47220645 0.46063729]\n",
      "reward is :  [0.59796757 0.69935663 0.58569853 0.46063729 0.45080034]\n",
      "regrets is :  [ 0.10138906 -0.10138906  0.          0.01156916  0.00983696] \n",
      "\n",
      "best reward is :  [0.60644809 0.57010412 0.52397063 0.48084571 0.44349361]\n",
      "reward is :  [0.60644809 0.44349361 0.48084571 0.43220645 0.52397063]\n",
      "regrets is :  [ 0.          0.12661051  0.04312491  0.04863926 -0.08047702] \n",
      "\n",
      "best reward is :  [0.57450382 0.4144632  0.40887892 0.40490816 0.39036703]\n",
      "reward is :  [0.57450382 0.40887892 0.4144632  0.37080034 0.31311475]\n",
      "regrets is :  [ 0.          0.00558428 -0.00558428  0.03410782  0.07725228] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 89us/step - loss: 0.0886 - val_loss: 0.0832\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0804 - val_loss: 0.0658\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0532 - val_loss: 0.0349\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0296 - val_loss: 0.0212\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0201 - val_loss: 0.0146\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0138 - val_loss: 0.0099\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0100 - val_loss: 0.0077\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0084 - val_loss: 0.0069\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0078 - val_loss: 0.0065\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0073 - val_loss: 0.0061\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0069 - val_loss: 0.0057\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "best reward is :  [0.6177215  0.54799449 0.53245704 0.46170098 0.44372537]\n",
      "reward is :  [0.54799449 0.6177215  0.46170098 0.44372537 0.53245704]\n",
      "regrets is :  [ 0.06972701 -0.06972701  0.07075606  0.01797561 -0.08873167] \n",
      "\n",
      "best reward is :  [0.6177215  0.55917503 0.54799449 0.47165402 0.46170098]\n",
      "reward is :  [0.54799449 0.6177215  0.46170098 0.47165402 0.55917503]\n",
      "regrets is :  [ 0.06972701 -0.05854647  0.08629351  0.         -0.09747405] \n",
      "\n",
      "best reward is :  [0.62451548 0.5897905  0.55250836 0.49784881 0.49510009]\n",
      "reward is :  [0.55250836 0.62451548 0.5897905  0.49784881 0.49510009]\n",
      "regrets is :  [ 0.07200712 -0.03472498 -0.03728213  0.          0.        ] \n",
      "\n",
      "best reward is :  [0.76485281 0.72345873 0.64832421 0.56154496 0.5597619 ]\n",
      "reward is :  [0.76485281 0.72345873 0.64832421 0.5597619  0.56154496]\n",
      "regrets is :  [ 0.          0.          0.          0.00178306 -0.00178306] \n",
      "\n",
      "best reward is :  [0.65468354 0.54       0.49413259 0.39198108 0.37969072]\n",
      "reward is :  [0.65468354 0.54       0.49413259 0.36653291 0.37969072]\n",
      "regrets is :  [0.         0.         0.         0.02544817 0.        ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 1s 172us/step - loss: 0.1030 - val_loss: 0.1085\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0889 - val_loss: 0.0773\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0523 - val_loss: 0.0380\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0312 - val_loss: 0.0262\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 58us/step - loss: 0.0272 - val_loss: 0.0242\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0258 - val_loss: 0.0228\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0241 - val_loss: 0.0210\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0215 - val_loss: 0.0184\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0178 - val_loss: 0.0151\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0140 - val_loss: 0.0124\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0086 - val_loss: 0.0092\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0081 - val_loss: 0.0088\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0076 - val_loss: 0.0082\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0070 - val_loss: 0.0077\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0058 - val_loss: 0.0066\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0052 - val_loss: 0.0060\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 71us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 50us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 67us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 51us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 69us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 55us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 52us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "best reward is :  [0.58664207 0.54417393 0.53558442 0.52797844 0.51056093]\n",
      "reward is :  [0.54417393 0.53558442 0.52797844 0.58664207 0.51056093]\n",
      "regrets is :  [ 0.04246814  0.00858952  0.00760598 -0.05866363  0.        ] \n",
      "\n",
      "best reward is :  [0.6347027  0.60615385 0.60552245 0.57230769 0.552     ]\n",
      "reward is :  [0.60552245 0.57230769 0.60615385 0.50184049 0.552     ]\n",
      "regrets is :  [ 0.02918025  0.03384615 -0.0006314   0.0704672   0.        ] \n",
      "\n",
      "best reward is :  [0.68546557 0.59705415 0.57384101 0.55083029 0.54684594]\n",
      "reward is :  [0.57384101 0.59705415 0.54684594 0.68546557 0.55083029]\n",
      "regrets is :  [ 0.11162456  0.          0.02699507 -0.13463528 -0.00398435] \n",
      "\n",
      "best reward is :  [0.71586207 0.64314607 0.62607029 0.61213918 0.44712405]\n",
      "reward is :  [0.71586207 0.61213918 0.62607029 0.64314607 0.44184049]\n",
      "regrets is :  [ 0.          0.03100689  0.         -0.03100689  0.00528356] \n",
      "\n",
      "best reward is :  [0.68546557 0.60285714 0.59705415 0.57586207 0.56184049]\n",
      "reward is :  [0.60285714 0.59705415 0.57586207 0.68546557 0.56184049]\n",
      "regrets is :  [ 0.08260842  0.00580299  0.02119209 -0.1096035   0.        ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 1s 113us/step - loss: 0.1068 - val_loss: 0.1150\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0915 - val_loss: 0.0829\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0542 - val_loss: 0.0428\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0323 - val_loss: 0.0302\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0271 - val_loss: 0.0268\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0239 - val_loss: 0.0232\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0198 - val_loss: 0.0183\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0152 - val_loss: 0.0136\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0094 - val_loss: 0.0088\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 53us/step - loss: 0.0084 - val_loss: 0.0081\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0079 - val_loss: 0.0077\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0076 - val_loss: 0.0074\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0074 - val_loss: 0.0072\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0070 - val_loss: 0.0068\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 53us/step - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 52us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 51us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 56us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 70us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 54us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 53us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 55us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 54us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 51us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 50us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 51us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 55us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "best reward is :  [0.71647059 0.59503822 0.57610415 0.51243491 0.49449154]\n",
      "reward is :  [0.71647059 0.59503822 0.57610415 0.51243491 0.49449154]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n",
      "best reward is :  [0.65294128 0.63183948 0.56461988 0.56368063 0.55910146]\n",
      "reward is :  [0.56461988 0.56368063 0.63183948 0.55910146 0.65294128]\n",
      "regrets is :  [ 0.0883214   0.06815885 -0.0672196   0.00457917 -0.09383982] \n",
      "\n",
      "best reward is :  [0.66685083 0.61719626 0.60166487 0.58647059 0.51647059]\n",
      "reward is :  [0.66685083 0.58647059 0.61719626 0.60166487 0.51647059]\n",
      "regrets is :  [ 0.          0.03072567 -0.01553139 -0.01519428  0.        ] \n",
      "\n",
      "best reward is :  [0.73170364 0.6513234  0.55647059 0.55398862 0.50833154]\n",
      "reward is :  [0.73170364 0.6513234  0.55398862 0.50833154 0.55647059]\n",
      "regrets is :  [ 0.          0.          0.00248197  0.04565708 -0.04813905] \n",
      "\n",
      "best reward is :  [0.77523185 0.70021904 0.64060657 0.62461988 0.50060141]\n",
      "reward is :  [0.70021904 0.62461988 0.77523185 0.64060657 0.50060141]\n",
      "regrets is :  [ 0.07501282  0.07559916 -0.13462529 -0.01598669  0.        ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 77us/step - loss: 0.1076 - val_loss: 0.1195\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 19us/step - loss: 0.0957 - val_loss: 0.0927\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0610 - val_loss: 0.0507\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0337 - val_loss: 0.0307\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0229 - val_loss: 0.0211\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0162 - val_loss: 0.0149\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0121 - val_loss: 0.0117\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0095 - val_loss: 0.0097\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0091 - val_loss: 0.0093\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0086 - val_loss: 0.0088\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0077 - val_loss: 0.0076\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 52us/step - loss: 0.0071 - val_loss: 0.0070\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 53us/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.005 - 0s 82us/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 51us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 54us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 50us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 75us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 68us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 87us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 58us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "best reward is :  [0.77683963 0.71151377 0.65026251 0.55788095 0.51794733]\n",
      "reward is :  [0.77683963 0.65026251 0.71151377 0.51794733 0.55788095]\n",
      "regrets is :  [ 0.          0.06125125 -0.06125125  0.03993362 -0.03993362] \n",
      "\n",
      "best reward is :  [0.65553719 0.55221269 0.54231975 0.54182116 0.50363636]\n",
      "reward is :  [0.65553719 0.41924567 0.50363636 0.54231975 0.55221269]\n",
      "regrets is :  [ 0.          0.13296702  0.03868339 -0.00049858 -0.04857633] \n",
      "\n",
      "best reward is :  [0.86944858 0.62350333 0.57268817 0.54956938 0.46535574]\n",
      "reward is :  [0.62350333 0.54956938 0.86944858 0.57268817 0.46535574]\n",
      "regrets is :  [ 0.24594526  0.07393395 -0.29676041 -0.02311879  0.        ] \n",
      "\n",
      "best reward is :  [0.80944858 0.62350333 0.57268817 0.54956938 0.46535574]\n",
      "reward is :  [0.62350333 0.54956938 0.80944858 0.57268817 0.46535574]\n",
      "regrets is :  [ 0.18594526  0.07393395 -0.23676041 -0.02311879  0.        ] \n",
      "\n",
      "best reward is :  [0.74928203 0.57711814 0.51688534 0.49802151 0.48411465]\n",
      "reward is :  [0.74928203 0.51688534 0.45278536 0.57711814 0.47885141]\n",
      "regrets is :  [ 0.          0.0602328   0.06409998 -0.07909663  0.00526324] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 94us/step - loss: 0.1020 - val_loss: 0.1092\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0896 - val_loss: 0.0828\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 19us/step - loss: 0.0581 - val_loss: 0.0447\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0314 - val_loss: 0.0249\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0188 - val_loss: 0.0154\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0123 - val_loss: 0.0107\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0096 - val_loss: 0.0091\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0087 - val_loss: 0.0086\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0079 - val_loss: 0.0078\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0074\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0070 - val_loss: 0.0068\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "best reward is :  [0.79401036 0.73549815 0.71383051 0.68228013 0.54      ]\n",
      "reward is :  [0.68228013 0.73549815 0.79401036 0.71383051 0.54      ]\n",
      "regrets is :  [ 0.11173023  0.         -0.08017985 -0.03155038  0.        ] \n",
      "\n",
      "best reward is :  [0.83549815 0.74228013 0.69401036 0.61383051 0.58      ]\n",
      "reward is :  [0.74228013 0.83549815 0.69401036 0.61383051 0.58      ]\n",
      "regrets is :  [ 0.09321802 -0.09321802  0.          0.          0.        ] \n",
      "\n",
      "best reward is :  [0.50026291 0.44240572 0.40435821 0.39673996 0.39206782]\n",
      "reward is :  [0.39673996 0.50026291 0.40435821 0.31103108 0.44240572]\n",
      "regrets is :  [ 0.10352295 -0.05785719  0.          0.08570889 -0.05033791] \n",
      "\n",
      "best reward is :  [0.86713294 0.71344549 0.70485281 0.62767599 0.54749614]\n",
      "reward is :  [0.86713294 0.71344549 0.62767599 0.70485281 0.54749614]\n",
      "regrets is :  [ 0.          0.          0.07717682 -0.07717682  0.        ] \n",
      "\n",
      "best reward is :  [0.70810556 0.69156216 0.68928203 0.63401036 0.61223482]\n",
      "reward is :  [0.68928203 0.69156216 0.70810556 0.60478019 0.63401036]\n",
      "regrets is :  [ 0.01882353  0.         -0.01882353  0.02923018 -0.02177554] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 93us/step - loss: 0.1000 - val_loss: 0.1084\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0911 - val_loss: 0.0862\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0602 - val_loss: 0.0469\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0342 - val_loss: 0.0283\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0240 - val_loss: 0.0197\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0173 - val_loss: 0.0138\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0123 - val_loss: 0.0104\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0095 - val_loss: 0.0088\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0081 - val_loss: 0.0080\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0074 - val_loss: 0.0075\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0070 - val_loss: 0.0072\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0067 - val_loss: 0.0070\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0063 - val_loss: 0.0067\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0060 - val_loss: 0.0063\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0057 - val_loss: 0.0060\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 76us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 58us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "best reward is :  [0.76485281 0.66523498 0.58413125 0.56536673 0.56286384]\n",
      "reward is :  [0.76485281 0.58413125 0.55486482 0.66523498 0.56536673]\n",
      "regrets is :  [ 0.          0.08110373  0.02926643 -0.09986825 -0.00250289] \n",
      "\n",
      "best reward is :  [0.5998027  0.58033613 0.49417476 0.42921958 0.41945205]\n",
      "reward is :  [0.58033613 0.5998027  0.41011765 0.49417476 0.42921958]\n",
      "regrets is :  [ 0.01946657 -0.01946657  0.08405711 -0.06495518 -0.00976752] \n",
      "\n",
      "best reward is :  [0.75835866 0.73366563 0.64038217 0.63536774 0.59244114]\n",
      "reward is :  [0.73366563 0.63536774 0.59244114 0.75835866 0.64038217]\n",
      "regrets is :  [ 0.02469303  0.09829789  0.04794102 -0.12299092 -0.04794102] \n",
      "\n",
      "best reward is :  [0.73011765 0.63660116 0.62037324 0.60981818 0.48187846]\n",
      "reward is :  [0.73011765 0.63660116 0.60981818 0.62037324 0.48187846]\n",
      "regrets is :  [ 0.          0.          0.01055505 -0.01055505  0.        ] \n",
      "\n",
      "best reward is :  [0.76950371 0.64776531 0.62898979 0.5390018  0.52836463]\n",
      "reward is :  [0.62898979 0.76950371 0.64776531 0.5390018  0.52306003]\n",
      "regrets is :  [ 0.14051392 -0.12173841 -0.01877551  0.          0.00530459] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 109us/step - loss: 0.1034 - val_loss: 0.1077\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0898 - val_loss: 0.0792\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0541 - val_loss: 0.0406\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0298 - val_loss: 0.0264\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0216 - val_loss: 0.0203\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0159 - val_loss: 0.0149\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0115 - val_loss: 0.0114\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0083 - val_loss: 0.0091\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0080 - val_loss: 0.0088\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0078 - val_loss: 0.0087\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0076 - val_loss: 0.0084\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0073 - val_loss: 0.0082\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0070 - val_loss: 0.0078\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0062 - val_loss: 0.0068\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0057 - val_loss: 0.0062\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "best reward is :  [0.67708098 0.50296483 0.44913612 0.40309945 0.40264334]\n",
      "reward is :  [0.67708098 0.50296483 0.44913612 0.40309945 0.36006601]\n",
      "regrets is :  [0.         0.         0.         0.         0.04257734] \n",
      "\n",
      "best reward is :  [0.61152104 0.59811201 0.52350883 0.43253071 0.426181  ]\n",
      "reward is :  [0.52350883 0.59811201 0.42428331 0.426181   0.61152104]\n",
      "regrets is :  [ 0.08801221  0.          0.09922552  0.00634971 -0.18534004] \n",
      "\n",
      "best reward is :  [0.61591315 0.61463678 0.58928203 0.54824307 0.47946539]\n",
      "reward is :  [0.61463678 0.58928203 0.61591315 0.47946539 0.54824307]\n",
      "regrets is :  [ 0.00127636  0.02535475 -0.02663111  0.06877768 -0.06877768] \n",
      "\n",
      "best reward is :  [0.61811201 0.61455129 0.55126791 0.54223064 0.53115408]\n",
      "reward is :  [0.61455129 0.61811201 0.54223064 0.53115408 0.55126791]\n",
      "regrets is :  [ 0.00356072 -0.00356072  0.00903727  0.01107655 -0.02011382] \n",
      "\n",
      "best reward is :  [0.65222816 0.50296483 0.44913612 0.41410965 0.40264334]\n",
      "reward is :  [0.65222816 0.50296483 0.44913612 0.41410965 0.36006601]\n",
      "regrets is :  [0.         0.         0.         0.         0.04257734] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 93us/step - loss: 0.1089 - val_loss: 0.1163\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0986 - val_loss: 0.0903\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0620 - val_loss: 0.0459\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0314 - val_loss: 0.0253\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0204 - val_loss: 0.0174\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0149 - val_loss: 0.0133\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0118 - val_loss: 0.0114\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0104 - val_loss: 0.0108\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0095 - val_loss: 0.0104\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0094 - val_loss: 0.0104\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0092 - val_loss: 0.0102\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0088 - val_loss: 0.0097\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0084 - val_loss: 0.0094\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0080 - val_loss: 0.0088\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0075 - val_loss: 0.0081\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0068 - val_loss: 0.0074\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0061 - val_loss: 0.0065\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 52us/step - loss: 0.0054 - val_loss: 0.0057\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 52us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 54us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 77us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 58us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.002 - 0s 68us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 69us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 77us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 68us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 83us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 54us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 76us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 56us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "best reward is :  [0.78644068 0.6959487  0.59615385 0.586875   0.55110021]\n",
      "reward is :  [0.78644068 0.6959487  0.586875   0.55110021 0.59615385]\n",
      "regrets is :  [ 0.          0.          0.00927885  0.03577479 -0.04505363] \n",
      "\n",
      "best reward is :  [0.54272727 0.50141955 0.50043956 0.4419089  0.39972213]\n",
      "reward is :  [0.50141955 0.54272727 0.50043956 0.4419089  0.39812034]\n",
      "regrets is :  [ 0.04130773 -0.04130773  0.          0.          0.00160179] \n",
      "\n",
      "best reward is :  [0.65328203 0.61906927 0.60710812 0.59972269 0.54754374]\n",
      "reward is :  [0.65328203 0.61906927 0.59972269 0.60710812 0.52181818]\n",
      "regrets is :  [ 0.          0.          0.00738543 -0.00738543  0.02572556] \n",
      "\n",
      "best reward is :  [0.83217391 0.79333333 0.67459459 0.62457472 0.56263297]\n",
      "reward is :  [0.83217391 0.79333333 0.67459459 0.62457472 0.56263297]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n",
      "best reward is :  [0.7199487  0.53572271 0.50710812 0.50543588 0.50442825]\n",
      "reward is :  [0.7199487  0.50442825 0.53572271 0.50710812 0.50543588]\n",
      "regrets is :  [ 0.          0.03129446 -0.02861459 -0.00167224 -0.00100763] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 104us/step - loss: 0.0886 - val_loss: 0.0945\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0780 - val_loss: 0.0728\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0493 - val_loss: 0.0409\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0298 - val_loss: 0.0305\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0255 - val_loss: 0.0276\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0230 - val_loss: 0.0242\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0192 - val_loss: 0.0195\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0146 - val_loss: 0.0145\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0085 - val_loss: 0.0095\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0087\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0069 - val_loss: 0.0082\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0059 - val_loss: 0.0073\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0052 - val_loss: 0.0067\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0050 - val_loss: 0.0064\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0048 - val_loss: 0.0062\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0043 - val_loss: 0.0057\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0041 - val_loss: 0.0054\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0039 - val_loss: 0.0050\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "best reward is :  [0.45645298 0.40498663 0.39834506 0.38608696 0.28819715]\n",
      "reward is :  [0.45645298 0.40498663 0.39834506 0.24165862 0.38608696]\n",
      "regrets is :  [ 0.          0.          0.          0.14442833 -0.09788981] \n",
      "\n",
      "best reward is :  [0.67110281 0.57500207 0.54698215 0.52804229 0.51406733]\n",
      "reward is :  [0.67110281 0.52804229 0.57500207 0.54698215 0.51406733]\n",
      "regrets is :  [ 0.          0.04695978 -0.02801992 -0.01893986  0.        ] \n",
      "\n",
      "best reward is :  [0.67681592 0.66104332 0.59439963 0.55553203 0.53331652]\n",
      "reward is :  [0.66104332 0.59439963 0.67681592 0.55553203 0.53331652]\n",
      "regrets is :  [ 0.0157726   0.06664369 -0.08241629  0.          0.        ] \n",
      "\n",
      "best reward is :  [0.64608696 0.58927054 0.51299248 0.50012539 0.41708155]\n",
      "reward is :  [0.64608696 0.50012539 0.58927054 0.51299248 0.41708155]\n",
      "regrets is :  [ 0.          0.08914515 -0.07627806 -0.01286709  0.        ] \n",
      "\n",
      "best reward is :  [0.60559737 0.58617462 0.55649374 0.48701036 0.39941698]\n",
      "reward is :  [0.60559737 0.58617462 0.48701036 0.55649374 0.39941698]\n",
      "regrets is :  [ 0.          0.          0.06948338 -0.06948338  0.        ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 92us/step - loss: 0.1037 - val_loss: 0.1065\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0976 - val_loss: 0.0933\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0734 - val_loss: 0.0574\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0371 - val_loss: 0.0254\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0173 - val_loss: 0.0142\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0116 - val_loss: 0.0112\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0089 - val_loss: 0.0092\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0085 - val_loss: 0.0086\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0079 - val_loss: 0.0080\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0066 - val_loss: 0.0065\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "best reward is :  [0.52758902 0.52613454 0.50752989 0.50711864 0.47581332]\n",
      "reward is :  [0.52613454 0.50752989 0.47581332 0.4365931  0.45708736]\n",
      "regrets is :  [0.00145448 0.01860465 0.03171656 0.07052554 0.01872597] \n",
      "\n",
      "best reward is :  [0.70240505 0.67197146 0.62791851 0.62605838 0.58823743]\n",
      "reward is :  [0.62605838 0.70240505 0.67197146 0.58823743 0.62791851]\n",
      "regrets is :  [ 0.07634667 -0.03043359 -0.04405295  0.03782095 -0.03968108] \n",
      "\n",
      "best reward is :  [0.65266665 0.57997865 0.56283173 0.55768221 0.53234773]\n",
      "reward is :  [0.57997865 0.65266665 0.56283173 0.55768221 0.53234773]\n",
      "regrets is :  [ 0.072688 -0.072688  0.        0.        0.      ] \n",
      "\n",
      "best reward is :  [0.76       0.7542268  0.70809756 0.62711864 0.57737052]\n",
      "reward is :  [0.76       0.70809756 0.7542268  0.57737052 0.62711864]\n",
      "regrets is :  [ 0.          0.04612924 -0.04612924  0.04974813 -0.04974813] \n",
      "\n",
      "best reward is :  [0.82120556 0.70711864 0.70244198 0.57755224 0.56556078]\n",
      "reward is :  [0.82120556 0.70711864 0.56556078 0.57755224 0.70244198]\n",
      "regrets is :  [ 0.         0.         0.1368812  0.        -0.1368812] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 78us/step - loss: 0.0916 - val_loss: 0.0940\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0823 - val_loss: 0.0741\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 19us/step - loss: 0.0538 - val_loss: 0.0403\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0290 - val_loss: 0.0240\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0191 - val_loss: 0.0163\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0131 - val_loss: 0.0111\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0097 - val_loss: 0.0087\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0082 - val_loss: 0.0077\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0075 - val_loss: 0.0071\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "best reward is :  [0.62450342 0.6        0.49045593 0.44808799 0.41221485]\n",
      "reward is :  [0.6        0.62450342 0.44808799 0.49045593 0.41221485]\n",
      "regrets is :  [ 0.02450342 -0.02450342  0.04236794 -0.04236794  0.        ] \n",
      "\n",
      "best reward is :  [0.57729818 0.50646874 0.47815916 0.4330865  0.37374733]\n",
      "reward is :  [0.57729818 0.50646874 0.47815916 0.4330865  0.37374733]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n",
      "best reward is :  [0.62450342 0.6        0.47601664 0.43045593 0.41221485]\n",
      "reward is :  [0.6        0.62450342 0.47601664 0.43045593 0.41221485]\n",
      "regrets is :  [ 0.02450342 -0.02450342  0.          0.          0.        ] \n",
      "\n",
      "best reward is :  [0.64367943 0.61175492 0.61095801 0.56646063 0.50273151]\n",
      "reward is :  [0.61095801 0.64367943 0.61175492 0.46902775 0.50273151]\n",
      "regrets is :  [ 0.03272142 -0.03192451 -0.00079691  0.09743288  0.        ] \n",
      "\n",
      "best reward is :  [0.60618615 0.55316092 0.54656111 0.51288233 0.48753902]\n",
      "reward is :  [0.60618615 0.55316092 0.54656111 0.51288233 0.48753902]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n",
      "End of the simulations, time elapsed: 289.324 seconds.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "regret, regrets, rewards, _ = run_several_experiments_hist_Embedding(evolutive_env = False, nb_exp = 20, nb_steps_history=1000, nb_steps = 1000, action_size = 5)\n",
    "plot_regret(regret, regrets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation 0 started, time elapsed: 0.000 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 83us/step - loss: 0.0905 - val_loss: 0.1041\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0786 - val_loss: 0.0773\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0486 - val_loss: 0.0427\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0273 - val_loss: 0.0262\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0178 - val_loss: 0.0176\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0124 - val_loss: 0.0132\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0102 - val_loss: 0.0115\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0090 - val_loss: 0.0106\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0087 - val_loss: 0.0102\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0084 - val_loss: 0.0098\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0081 - val_loss: 0.0093\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0076 - val_loss: 0.0087\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 73us/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 74us/step - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0055 - val_loss: 0.0063\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 66us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 53us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 52us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 56us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 76us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 85us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 58us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 68us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 31us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 29us/step - loss: 0.0020 - val_loss: 0.0051\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 24us/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 28us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 26us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 24us/step - loss: 0.0022 - val_loss: 0.0056\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 25us/step - loss: 0.0022 - val_loss: 0.0057\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 29us/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 32us/step - loss: 0.0021 - val_loss: 0.0055\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 29us/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 23us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 41us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 46us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 44us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 50us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 43us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 43us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 37us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 44us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 44us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 42us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 46us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 41us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 50us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 44us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 0s 25us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 22us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 21us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 22us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 21us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 23us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 24us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 32us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 47us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 40us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 51us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 48us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 31us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 27us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 47us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 47us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "best reward is :  [0.68380461 0.63344146 0.63025676 0.5320759  0.50936675]\n",
      "reward is :  [0.68380461 0.63344146 0.63025676 0.49282283 0.50936675]\n",
      "regrets is :  [0.         0.         0.         0.03925307 0.        ] \n",
      "\n",
      "best reward is :  [0.69134752 0.66486295 0.63978142 0.54110603 0.51217391]\n",
      "reward is :  [0.69134752 0.63978142 0.66486295 0.51217391 0.47413793]\n",
      "regrets is :  [ 0.          0.02508153 -0.02508153  0.02893211  0.03803598] \n",
      "\n",
      "best reward is :  [0.66148148 0.61111833 0.60793363 0.45818182 0.43834648]\n",
      "reward is :  [0.66148148 0.60793363 0.61111833 0.45818182 0.43834648]\n",
      "regrets is :  [ 0.         0.0031847 -0.0031847  0.         0.       ] \n",
      "\n",
      "best reward is :  [0.78848045 0.7381173  0.7349326  0.5237659  0.44565999]\n",
      "reward is :  [0.78848045 0.7381173  0.7349326  0.5237659  0.42262818]\n",
      "regrets is :  [0.        0.        0.        0.        0.0230318] \n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 46us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 47us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "best reward is :  [0.7598862  0.6679646  0.58468085 0.55280182 0.53311475]\n",
      "reward is :  [0.7598862  0.6679646  0.58468085 0.55280182 0.53311475]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 1s 113us/step - loss: 0.0976 - val_loss: 0.0969\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0861 - val_loss: 0.0708\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 50us/step - loss: 0.0515 - val_loss: 0.0342\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0278 - val_loss: 0.0220\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0201 - val_loss: 0.0174\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0156 - val_loss: 0.0141\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0125 - val_loss: 0.0121\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0093 - val_loss: 0.0099\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0085 - val_loss: 0.0089\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 57us/step - loss: 0.0079 - val_loss: 0.0082\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 73us/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 51us/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 68us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 54us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 52us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 19us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 17us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 17us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 16us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 16us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 17us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 17us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 17us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 21us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 17us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 17us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 18us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 25us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 16us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 35us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 27us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 28us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 29us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 29us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 38us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 31us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 31us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 17us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 16us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 16us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 16us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 16us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 20us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 20us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 19us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 18us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 18us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 16us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 0s 18us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 16us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 19us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 16us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 16us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 16us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 19us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 24us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 34us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 22us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 23us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 23us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 28us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 19us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 34us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 26us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 24us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 25us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 19us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "best reward is :  [0.78872878 0.69899668 0.6687501  0.63167859 0.53886399]\n",
      "reward is :  [0.78872878 0.6687501  0.69899668 0.63167859 0.53886399]\n",
      "regrets is :  [ 0.          0.03024658 -0.03024658  0.          0.        ] \n",
      "\n",
      "best reward is :  [0.63096831 0.61953243 0.52980033 0.49955375 0.4143954 ]\n",
      "reward is :  [0.61953243 0.63096831 0.52980033 0.49955375 0.4143954 ]\n",
      "regrets is :  [ 0.01143588 -0.01143588  0.          0.          0.        ] \n",
      "\n",
      "best reward is :  [0.58970256 0.512      0.50984541 0.50095358 0.41271287]\n",
      "reward is :  [0.58970256 0.512      0.50095358 0.50984541 0.39099526]\n",
      "regrets is :  [ 0.          0.          0.00889183 -0.00889183  0.02171761] \n",
      "\n",
      "best reward is :  [0.86430164 0.56530233 0.49658199 0.46122028 0.45434095]\n",
      "reward is :  [0.86430164 0.56530233 0.46122028 0.49658199 0.45434095]\n",
      "regrets is :  [ 0.         0.         0.0353617 -0.0353617  0.       ] \n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 18us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 17us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 19us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 17us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "best reward is :  [0.67942506 0.58098979 0.54966395 0.50058094 0.49869235]\n",
      "reward is :  [0.58098979 0.67942506 0.50058094 0.54966395 0.49869235]\n",
      "regrets is :  [ 0.09843526 -0.09843526  0.04908301 -0.04908301  0.        ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 84us/step - loss: 0.1109 - val_loss: 0.1154\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.1008 - val_loss: 0.0935\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0692 - val_loss: 0.0548\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0390 - val_loss: 0.0337\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0271 - val_loss: 0.0259\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0209 - val_loss: 0.0195\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0152 - val_loss: 0.0134\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0110 - val_loss: 0.0097\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0087 - val_loss: 0.0077\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0075 - val_loss: 0.0067\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0067 - val_loss: 0.0061\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0062 - val_loss: 0.0056\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 54us/step - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.004 - 0s 44us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 17us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 54us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 49us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 39us/step - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 39us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 31us/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 32us/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 34us/step - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 33us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 55us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 46us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 60us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 36us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 29us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 32us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 40us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 29us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 37us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 33us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 29us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 32us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 30us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 29us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 34us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 45us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 33us/step - loss: 0.0022 - val_loss: 0.0027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 33us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 30us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 28us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 42us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 28us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 33us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 35us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 30us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 30us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 31us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 30us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 29us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 30us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 29us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 29us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 32us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 40us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 42us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 35us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "best reward is :  [0.83061553 0.65098658 0.63394372 0.63073517 0.56891839]\n",
      "reward is :  [0.83061553 0.63073517 0.63394372 0.56891839 0.65098658]\n",
      "regrets is :  [ 0.          0.02025142  0.          0.06181678 -0.08206819] \n",
      "\n",
      "best reward is :  [0.65379856 0.56509599 0.5461121  0.52744419 0.51016334]\n",
      "reward is :  [0.65379856 0.56509599 0.52744419 0.5461121  0.51016334]\n",
      "regrets is :  [ 0.         0.         0.0186679 -0.0186679  0.       ] \n",
      "\n",
      "best reward is :  [0.68410225 0.67826476 0.66371114 0.64356775 0.5519693 ]\n",
      "reward is :  [0.68410225 0.67826476 0.66371114 0.5519693  0.64356775]\n",
      "regrets is :  [ 0.          0.          0.          0.09159845 -0.09159845] \n",
      "\n",
      "best reward is :  [0.67482022 0.66898273 0.66371114 0.63428571 0.55830366]\n",
      "reward is :  [0.67482022 0.66898273 0.66371114 0.55830366 0.63428571]\n",
      "regrets is :  [ 0.          0.          0.          0.07598205 -0.07598205] \n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "best reward is :  [0.64382968 0.57504474 0.57243993 0.5240811  0.50703824]\n",
      "reward is :  [0.64382968 0.57504474 0.5240811  0.57243993 0.50703824]\n",
      "regrets is :  [ 0.          0.          0.04835883 -0.04835883  0.        ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 81us/step - loss: 0.0980 - val_loss: 0.1004\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0855 - val_loss: 0.0746\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0517 - val_loss: 0.0398\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0292 - val_loss: 0.0276\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0219 - val_loss: 0.0212\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0163 - val_loss: 0.0156\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0121 - val_loss: 0.0119\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0092 - val_loss: 0.0094\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0089 - val_loss: 0.0091\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0086 - val_loss: 0.0089\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0083 - val_loss: 0.0085\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0080 - val_loss: 0.0081\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 53us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 50us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 55us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 43us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 43us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 33us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 49us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 29us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 51us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 56us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 57us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 45us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 25us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 41us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 53us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 45us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 38us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 34us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 36us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 43us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 24us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 16us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 17us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 28us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 20us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 16us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 23us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 46us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 38us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 0s 32us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 43us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 27us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 33us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 43us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 49us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 1s 72us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 40us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 56us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 1s 69us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 51us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 52us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 38us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 33us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 25us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 25us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 29us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 34us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 52us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "best reward is :  [0.71851913 0.57899158 0.46432523 0.41543288 0.40668603]\n",
      "reward is :  [0.71851913 0.57899158 0.46432523 0.40668603 0.3670907 ]\n",
      "regrets is :  [0.         0.         0.         0.00874685 0.03959534] \n",
      "\n",
      "best reward is :  [0.58398287 0.54646563 0.52895975 0.52693674 0.51663456]\n",
      "reward is :  [0.58398287 0.54646563 0.51663456 0.52895975 0.52693674]\n",
      "regrets is :  [ 0.          0.          0.01232519 -0.00202301 -0.01030217] \n",
      "\n",
      "best reward is :  [0.67225096 0.58979849 0.56826457 0.56208203 0.54457615]\n",
      "reward is :  [0.67225096 0.56826457 0.58979849 0.56208203 0.54457615]\n",
      "regrets is :  [ 0.          0.02153392 -0.02153392  0.          0.        ] \n",
      "\n",
      "best reward is :  [0.76904295 0.61217868 0.57979849 0.56208203 0.53529412]\n",
      "reward is :  [0.76904295 0.57979849 0.61217868 0.56208203 0.53529412]\n",
      "regrets is :  [ 0.          0.03238019 -0.03238019  0.          0.        ] \n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 45us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 56us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 34us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 44us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 51us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "best reward is :  [0.58398287 0.5528     0.53529412 0.52693674 0.52296893]\n",
      "reward is :  [0.58398287 0.5528     0.52296893 0.53529412 0.52693674]\n",
      "regrets is :  [ 0.          0.          0.01232519 -0.00835738 -0.00396781] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 95us/step - loss: 0.0953 - val_loss: 0.1017\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0880 - val_loss: 0.0839\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0602 - val_loss: 0.0467\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0331 - val_loss: 0.0292\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0253 - val_loss: 0.0257\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0234 - val_loss: 0.0239\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0214 - val_loss: 0.0209\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0181 - val_loss: 0.0162\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0138 - val_loss: 0.0115\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0104 - val_loss: 0.0086\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0086 - val_loss: 0.0073\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0078 - val_loss: 0.0066\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0073 - val_loss: 0.0062\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0069 - val_loss: 0.0058\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0065 - val_loss: 0.0054\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 23us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 22us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 23us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 28us/step - loss: 0.0016 - val_loss: 0.0053\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 27us/step - loss: 0.0016 - val_loss: 0.0052\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 22us/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 25us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 36us/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 33us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 42us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 42us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 27us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 26us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 23us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 24us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 24us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 30us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 36us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 41us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - ETA: 0s - loss: 0.002 - 0s 35us/step - loss: 0.0021 - val_loss: 0.0024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 37us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 34us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 37us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 36us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 33us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 21us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 21us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 22us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 24us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 22us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 23us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 23us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 23us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 20us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 21us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 23us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 20us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 23us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 24us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "best reward is :  [0.65606024 0.56178979 0.55686559 0.52705369 0.47919244]\n",
      "reward is :  [0.65606024 0.56178979 0.52705369 0.55686559 0.47919244]\n",
      "regrets is :  [ 0.          0.          0.02981191 -0.02981191  0.        ] \n",
      "\n",
      "best reward is :  [0.61529105 0.57946667 0.54100257 0.48010114 0.42983535]\n",
      "reward is :  [0.61529105 0.57946667 0.54100257 0.48010114 0.42368416]\n",
      "regrets is :  [0.        0.        0.        0.        0.0061512] \n",
      "\n",
      "best reward is :  [0.56029705 0.48863781 0.45798965 0.38613333 0.37206732]\n",
      "reward is :  [0.56029705 0.48863781 0.45798965 0.351085   0.37206732]\n",
      "regrets is :  [0.         0.         0.         0.03504833 0.        ] \n",
      "\n",
      "best reward is :  [0.63120743 0.56178979 0.53806389 0.53201278 0.47919244]\n",
      "reward is :  [0.63120743 0.56178979 0.53806389 0.53201278 0.47919244]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 21us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "best reward is :  [0.50408413 0.44550475 0.40332139 0.38108427 0.37256396]\n",
      "reward is :  [0.50408413 0.37256396 0.40332139 0.38108427 0.34634816]\n",
      "regrets is :  [0.         0.07294079 0.         0.         0.0262158 ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 91us/step - loss: 0.0899 - val_loss: 0.0968\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0797 - val_loss: 0.0762\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0539 - val_loss: 0.0439\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0280 - val_loss: 0.0215\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0145 - val_loss: 0.0127\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0087 - val_loss: 0.0097\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0083 - val_loss: 0.0096\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0082 - val_loss: 0.0095\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0081 - val_loss: 0.0095\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0079 - val_loss: 0.0094\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0078 - val_loss: 0.0093\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0076 - val_loss: 0.0091\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0073 - val_loss: 0.0087\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0070 - val_loss: 0.0084\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0066 - val_loss: 0.0079\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0061 - val_loss: 0.0075\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0057 - val_loss: 0.0070\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0053 - val_loss: 0.0067\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0050 - val_loss: 0.0065\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0048 - val_loss: 0.0063\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0047 - val_loss: 0.0060\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0043 - val_loss: 0.0057\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0041 - val_loss: 0.0054\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0039 - val_loss: 0.0051\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 22us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 27us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 29us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 38us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 33us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 23us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 26us/step - loss: 0.0019 - val_loss: 0.0054\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 28us/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 27us/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 28us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 24us/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 27us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 26us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 25us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 27us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 23us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 27us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 25us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 28us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 30us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 23us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 25us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 26us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 26us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 25us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 25us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 0s 26us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 21us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 23us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 21us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 23us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 23us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 21us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 36us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 38us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 36us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 34us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 1s 78us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 54us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 52us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 48us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 34us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 29us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "best reward is :  [0.75706484 0.70928203 0.59632184 0.57678771 0.53095436]\n",
      "reward is :  [0.75706484 0.70928203 0.59632184 0.57678771 0.53095436]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n",
      "best reward is :  [0.75565646 0.4820907  0.41105831 0.39865985 0.38779391]\n",
      "reward is :  [0.75565646 0.4820907  0.38779391 0.39865985 0.41105831]\n",
      "regrets is :  [ 0.         0.         0.0232644  0.        -0.0232644] \n",
      "\n",
      "best reward is :  [0.56591021 0.45715096 0.43552894 0.41714286 0.41052632]\n",
      "reward is :  [0.56591021 0.43552894 0.45715096 0.41052632 0.41714286]\n",
      "regrets is :  [ 0.          0.02162201 -0.02162201  0.00661654 -0.00661654] \n",
      "\n",
      "best reward is :  [0.57777778 0.52       0.50489731 0.49052632 0.41630955]\n",
      "reward is :  [0.57777778 0.52       0.50489731 0.49052632 0.41305936]\n",
      "regrets is :  [0.         0.         0.         0.         0.00325019] \n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 53us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 52us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 53us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "best reward is :  [0.77450799 0.72569183 0.63930229 0.60898979 0.55066213]\n",
      "reward is :  [0.72569183 0.77450799 0.63930229 0.60898979 0.55066213]\n",
      "regrets is :  [ 0.04881616 -0.04881616  0.          0.          0.        ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 92us/step - loss: 0.0957 - val_loss: 0.1001\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0832 - val_loss: 0.0745\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0524 - val_loss: 0.0408\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0308 - val_loss: 0.0277\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0238 - val_loss: 0.0234\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0206 - val_loss: 0.0208\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0178 - val_loss: 0.0179\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0122 - val_loss: 0.0124\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0087 - val_loss: 0.0091\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0083 - val_loss: 0.0086\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0079 - val_loss: 0.0081\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0073 - val_loss: 0.0075\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0059 - val_loss: 0.0060\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 24us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 29us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 22us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 23us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 25us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 36us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 36us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 37us/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 33us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 42us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 39us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 36us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 38us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 31us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 42us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 37us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 40us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 35us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 28us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 24us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 0s 24us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 22us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 22us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 22us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 20us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 21us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 21us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 22us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 23us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 22us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 23us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 22us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 24us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 22us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 22us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 21us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 23us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 44us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 29us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "best reward is :  [0.51333333 0.50571429 0.49283733 0.48235796 0.47311475]\n",
      "reward is :  [0.46867512 0.50571429 0.51333333 0.47311475 0.42261767]\n",
      "regrets is :  [ 0.04465821  0.         -0.02049601  0.00924321  0.05049709] \n",
      "\n",
      "best reward is :  [0.72465817 0.58532298 0.58107304 0.56908963 0.55533825]\n",
      "reward is :  [0.72465817 0.58532298 0.58107304 0.47366563 0.55533825]\n",
      "regrets is :  [0.         0.         0.         0.09542399 0.        ] \n",
      "\n",
      "best reward is :  [0.83048544 0.63313869 0.56       0.52047016 0.48433416]\n",
      "reward is :  [0.83048544 0.63313869 0.56       0.52047016 0.48433416]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n",
      "best reward is :  [0.66095238 0.62073134 0.58485281 0.5775     0.56461538]\n",
      "reward is :  [0.66095238 0.56461538 0.58485281 0.5775     0.62073134]\n",
      "regrets is :  [ 0.          0.05611595  0.          0.         -0.05611595] \n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 24us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 18us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 17us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 19us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "best reward is :  [0.82252031 0.622114   0.58580519 0.56200492 0.5094682 ]\n",
      "reward is :  [0.82252031 0.622114   0.58580519 0.56200492 0.5094682 ]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 1s 116us/step - loss: 0.1029 - val_loss: 0.1103\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0944 - val_loss: 0.0883\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0616 - val_loss: 0.0472\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0350 - val_loss: 0.0315\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0284 - val_loss: 0.0279\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0259 - val_loss: 0.0254\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0231 - val_loss: 0.0221\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0193 - val_loss: 0.0179\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0150 - val_loss: 0.0136\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0092 - val_loss: 0.0088\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0079 - val_loss: 0.0078\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0072 - val_loss: 0.0071\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0066 - val_loss: 0.0065\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 67us/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 69us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 86us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 53us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 59us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 52us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 52us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 69us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 64us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 59us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 42us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 84us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 33us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 38us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 35us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 71us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 49us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 54us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 28us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 23us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 25us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 27us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 24us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 49us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 46us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 25us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 36us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 23us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 0s 24us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 22us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 21us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 22us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 20us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 23us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 22us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 39us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 39us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 37us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 36us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 37us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 37us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 30us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 35us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 35us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 37us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 35us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 35us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "best reward is :  [0.72485281 0.566472   0.55286103 0.49618094 0.41096149]\n",
      "reward is :  [0.72485281 0.566472   0.55286103 0.49618094 0.41096149]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n",
      "best reward is :  [0.60242641 0.53288544 0.51273138 0.49656175 0.49309091]\n",
      "reward is :  [0.60242641 0.49309091 0.49656175 0.49183099 0.51273138]\n",
      "regrets is :  [ 0.          0.03979454  0.01616964  0.00473076 -0.01964047] \n",
      "\n",
      "best reward is :  [0.70615385 0.67604938 0.67048458 0.66490928 0.61387164]\n",
      "reward is :  [0.70615385 0.67604938 0.67048458 0.66490928 0.61387164]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n",
      "best reward is :  [0.59328201 0.53300325 0.50358699 0.48741735 0.48281485]\n",
      "reward is :  [0.59328201 0.48219518 0.48281485 0.48741735 0.50358699]\n",
      "regrets is :  [ 0.          0.05080806  0.02077214  0.         -0.02077214] \n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 33us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 30us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 21us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 21us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "best reward is :  [0.57370213 0.55543588 0.51604938 0.51419132 0.51048458]\n",
      "reward is :  [0.57370213 0.55543588 0.51604938 0.51419132 0.51048458]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 69us/step - loss: 0.0929 - val_loss: 0.1054\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0797 - val_loss: 0.0765\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 19us/step - loss: 0.0479 - val_loss: 0.0435\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 19us/step - loss: 0.0315 - val_loss: 0.0344\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 19us/step - loss: 0.0281 - val_loss: 0.0322\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0268 - val_loss: 0.0309\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0253 - val_loss: 0.0287\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0229 - val_loss: 0.0253\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0191 - val_loss: 0.0203\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0146 - val_loss: 0.0150\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0088 - val_loss: 0.0094\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0079 - val_loss: 0.0085\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0070 - val_loss: 0.0075\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0066 - val_loss: 0.0070\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0061 - val_loss: 0.0064\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 52us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 54us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 52us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 60us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 62us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 55us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 61us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 41us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 35us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 53us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 61us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 60us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 36us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 44us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 45us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 49us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 40us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 40us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 38us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 26us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 26us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 23us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 25us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 30us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 24us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 24us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 27us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 25us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 0s 25us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 22us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 21us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 21us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 20us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 20us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 21us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 21us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 21us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 20us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 22us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 22us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 23us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 20us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 21us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 23us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 21us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 23us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 24us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "best reward is :  [0.71489124 0.67739703 0.64694215 0.6319939  0.6009516 ]\n",
      "reward is :  [0.6319939  0.64694215 0.71489124 0.67739703 0.6009516 ]\n",
      "regrets is :  [ 0.08289734  0.03045489 -0.06794909 -0.04540314  0.        ] \n",
      "\n",
      "best reward is :  [0.58875139 0.52578682 0.49887613 0.47561776 0.45129782]\n",
      "reward is :  [0.58875139 0.52578682 0.49887613 0.45129782 0.47561776]\n",
      "regrets is :  [ 0.          0.          0.          0.02431994 -0.02431994] \n",
      "\n",
      "best reward is :  [0.80694215 0.7919939  0.73489124 0.70235033 0.69739703]\n",
      "reward is :  [0.7919939  0.80694215 0.73489124 0.69739703 0.70235033]\n",
      "regrets is :  [ 0.01494825 -0.01494825  0.          0.0049533  -0.0049533 ] \n",
      "\n",
      "best reward is :  [0.62694215 0.60761827 0.57594843 0.54271186 0.49982344]\n",
      "reward is :  [0.60761827 0.54271186 0.62694215 0.57594843 0.49982344]\n",
      "regrets is :  [ 0.01932388  0.0649064  -0.05099371 -0.03323657  0.        ] \n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 21us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "best reward is :  [0.62492104 0.59422392 0.57315296 0.48513827 0.42225928]\n",
      "reward is :  [0.62492104 0.57315296 0.59422392 0.48513827 0.42225928]\n",
      "regrets is :  [ 0.          0.02107096 -0.02107096  0.          0.        ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 90us/step - loss: 0.0847 - val_loss: 0.0894\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0739 - val_loss: 0.0661\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0453 - val_loss: 0.0347\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0256 - val_loss: 0.0217\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0175 - val_loss: 0.0151\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 46us/step - loss: 0.0126 - val_loss: 0.0112\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0100 - val_loss: 0.0095\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0088 - val_loss: 0.0087\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0080 - val_loss: 0.0079\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0076 - val_loss: 0.0074\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0072 - val_loss: 0.0070\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 22us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 22us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 22us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 26us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 25us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 22us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 27us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 26us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 32us/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 23us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 26us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 22us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 25us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 24us/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 22us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 26us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 24us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 31us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 29us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 24us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 30us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 37us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 0s 35us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 40us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 35us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 37us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 35us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 36us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 41us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 36us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 39us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 32us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 33us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 34us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 24us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 21us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 25us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 22us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 20us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 23us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "best reward is :  [0.61835367 0.60115751 0.51481426 0.48088693 0.42211638]\n",
      "reward is :  [0.61835367 0.60115751 0.51481426 0.48088693 0.42211638]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n",
      "best reward is :  [0.63299793 0.5763047  0.48996145 0.48088693 0.42211638]\n",
      "reward is :  [0.63299793 0.5763047  0.48996145 0.48088693 0.42211638]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n",
      "best reward is :  [0.58643242 0.53432658 0.4579465  0.44878993 0.43251741]\n",
      "reward is :  [0.58643242 0.53432658 0.44878993 0.43251741 0.4579465 ]\n",
      "regrets is :  [ 0.          0.          0.00915657  0.01627252 -0.02542909] \n",
      "\n",
      "best reward is :  [0.60400601 0.53432658 0.46633126 0.4579465  0.44878993]\n",
      "reward is :  [0.60400601 0.53432658 0.44878993 0.46633126 0.4579465 ]\n",
      "regrets is :  [ 0.          0.          0.01754133 -0.00838476 -0.00915657] \n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "best reward is :  [0.72685315 0.67244444 0.61143552 0.54563151 0.54231738]\n",
      "reward is :  [0.72685315 0.67244444 0.61143552 0.54563151 0.54231738]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 94us/step - loss: 0.1083 - val_loss: 0.1120\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0988 - val_loss: 0.0915\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0686 - val_loss: 0.0506\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0345 - val_loss: 0.0234\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0185 - val_loss: 0.0140\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0123 - val_loss: 0.0105\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0097 - val_loss: 0.0091\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0087 - val_loss: 0.0085\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0081 - val_loss: 0.0080\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0076 - val_loss: 0.0074\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0070 - val_loss: 0.0068\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0065 - val_loss: 0.0064\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.002 - 0s 41us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 53us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 64us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 65us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 50us/step - loss: 0.0021 - val_loss: 0.0059\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 51us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 43us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 40us/step - loss: 0.0020 - val_loss: 0.0057\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 54us/step - loss: 0.0020 - val_loss: 0.0057\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 69us/step - loss: 0.0023 - val_loss: 0.0060\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 64us/step - loss: 0.0022 - val_loss: 0.0060\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 76us/step - loss: 0.0022 - val_loss: 0.0056\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 47us/step - loss: 0.0022 - val_loss: 0.0055\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.0022 - val_loss: 0.0055\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 35us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 46us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 42us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 57us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 56us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 45us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 54us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 53us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 47us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 45us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 56us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 56us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 54us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 50us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 53us/step - loss: 0.0025 - val_loss: 0.0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 41us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 36us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 36us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 37us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 32us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 38us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 38us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 34us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 40us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 33us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 35us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 36us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 33us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 33us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 32us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 34us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 37us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 36us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 32us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "best reward is :  [0.72920064 0.72777964 0.70260982 0.70014693 0.66317342]\n",
      "reward is :  [0.72777964 0.72920064 0.66317342 0.70014693 0.70260982]\n",
      "regrets is :  [ 0.001421  -0.001421   0.0394364  0.        -0.0394364] \n",
      "\n",
      "best reward is :  [0.72777964 0.66317342 0.58920064 0.56260982 0.53529412]\n",
      "reward is :  [0.72777964 0.66317342 0.58920064 0.53529412 0.56260982]\n",
      "regrets is :  [ 0.          0.          0.          0.02731571 -0.02731571] \n",
      "\n",
      "best reward is :  [0.66978979 0.58963711 0.56274325 0.54269609 0.53998862]\n",
      "reward is :  [0.58963711 0.56274325 0.53998862 0.66978979 0.54269609]\n",
      "regrets is :  [ 0.08015268  0.02689387  0.02275463 -0.12709371 -0.00270747] \n",
      "\n",
      "best reward is :  [0.74515464 0.56095681 0.55890909 0.54881356 0.52740741]\n",
      "reward is :  [0.74515464 0.54881356 0.56095681 0.55890909 0.49535574]\n",
      "regrets is :  [ 0.          0.01214325 -0.00204771 -0.01009553  0.03205167] \n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 30us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "best reward is :  [0.70881356 0.67882027 0.61355011 0.58062215 0.55464102]\n",
      "reward is :  [0.67882027 0.61355011 0.70881356 0.55464102 0.58062215]\n",
      "regrets is :  [ 0.02999329  0.06527016 -0.09526345  0.02598114 -0.02598114] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 78us/step - loss: 0.1063 - val_loss: 0.1211\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 19us/step - loss: 0.0961 - val_loss: 0.0947\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0587 - val_loss: 0.0489\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 19us/step - loss: 0.0322 - val_loss: 0.0339\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 19us/step - loss: 0.0274 - val_loss: 0.0313\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 19us/step - loss: 0.0261 - val_loss: 0.0297\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 19us/step - loss: 0.0247 - val_loss: 0.0279\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 19us/step - loss: 0.0224 - val_loss: 0.0247\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 18us/step - loss: 0.0189 - val_loss: 0.0204\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0147 - val_loss: 0.0158\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0112 - val_loss: 0.0122\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0091 - val_loss: 0.0102\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0082 - val_loss: 0.0093\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0078 - val_loss: 0.0088\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0075 - val_loss: 0.0084\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0069 - val_loss: 0.0076\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0065 - val_loss: 0.0071\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0061 - val_loss: 0.0065\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 31us/step - loss: 0.0016 - val_loss: 0.0064\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 41us/step - loss: 0.0016 - val_loss: 0.0061\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 39us/step - loss: 0.0016 - val_loss: 0.0060\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 42us/step - loss: 0.0016 - val_loss: 0.0062\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 36us/step - loss: 0.0016 - val_loss: 0.0060\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 36us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 24us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0045\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 22us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 30us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 36us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 35us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 40us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 33us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 24us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 23us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 27us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 27us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 25us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 28us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 23us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 29us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 26us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 36us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 0s 37us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 41us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 36us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 38us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 38us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 40us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 33us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 42us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 35us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 37us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 33us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 34us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 25us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 21us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 21us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 22us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 23us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 21us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 33us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "best reward is :  [0.60467155 0.59916472 0.57999657 0.55894865 0.49163673]\n",
      "reward is :  [0.57999657 0.59916472 0.55894865 0.60467155 0.49163673]\n",
      "regrets is :  [ 0.02467498  0.          0.02104792 -0.0457229   0.        ] \n",
      "\n",
      "best reward is :  [0.78262563 0.68034793 0.67523982 0.65439585 0.55002563]\n",
      "reward is :  [0.78262563 0.67523982 0.68034793 0.65439585 0.55002563]\n",
      "regrets is :  [ 0.          0.00510811 -0.00510811  0.          0.        ] \n",
      "\n",
      "best reward is :  [0.67478112 0.61804994 0.58683092 0.47555069 0.46093719]\n",
      "reward is :  [0.67478112 0.61804994 0.58683092 0.47555069 0.40246235]\n",
      "regrets is :  [0.         0.         0.         0.         0.05847483] \n",
      "\n",
      "best reward is :  [0.78896    0.7024006  0.67523982 0.66073022 0.57538462]\n",
      "reward is :  [0.78896    0.67523982 0.7024006  0.66073022 0.57538462]\n",
      "regrets is :  [ 0.          0.02716078 -0.02716078  0.          0.        ] \n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 30us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "best reward is :  [0.72073022 0.63538462 0.59581395 0.56798469 0.5665798 ]\n",
      "reward is :  [0.72073022 0.63538462 0.56798469 0.59581395 0.5665798 ]\n",
      "regrets is :  [ 0.          0.          0.02782927 -0.02782927  0.        ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 98us/step - loss: 0.1019 - val_loss: 0.1070\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0868 - val_loss: 0.0756\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0508 - val_loss: 0.0411\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0321 - val_loss: 0.0331\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0291 - val_loss: 0.0326\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0286 - val_loss: 0.0325\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0283 - val_loss: 0.0326\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0279 - val_loss: 0.0322\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0273 - val_loss: 0.0314\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0260 - val_loss: 0.0296\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0239 - val_loss: 0.0266\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0207 - val_loss: 0.0223\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0169 - val_loss: 0.0175\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0133 - val_loss: 0.0136\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0092 - val_loss: 0.0091\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0087 - val_loss: 0.0087\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0083 - val_loss: 0.0081\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0079 - val_loss: 0.0076\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0074 - val_loss: 0.0071\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0070 - val_loss: 0.0066\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 23us/step - loss: 0.0022 - val_loss: 0.0067\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 28us/step - loss: 0.0021 - val_loss: 0.0066\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 27us/step - loss: 0.0021 - val_loss: 0.0066\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 25us/step - loss: 0.0021 - val_loss: 0.0064\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 27us/step - loss: 0.0021 - val_loss: 0.0065\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 24us/step - loss: 0.0024 - val_loss: 0.0059\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 29us/step - loss: 0.0023 - val_loss: 0.0059\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 23us/step - loss: 0.0023 - val_loss: 0.0057\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 25us/step - loss: 0.0023 - val_loss: 0.0056\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 27us/step - loss: 0.0023 - val_loss: 0.0057\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 23us/step - loss: 0.0025 - val_loss: 0.0056\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 27us/step - loss: 0.0025 - val_loss: 0.0054\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 24us/step - loss: 0.0025 - val_loss: 0.0054\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 27us/step - loss: 0.0025 - val_loss: 0.0055\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 24us/step - loss: 0.0025 - val_loss: 0.0055\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 24us/step - loss: 0.0027 - val_loss: 0.0055\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 27us/step - loss: 0.0027 - val_loss: 0.0054\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 27us/step - loss: 0.0027 - val_loss: 0.0052\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 26us/step - loss: 0.0027 - val_loss: 0.0052\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 31us/step - loss: 0.0027 - val_loss: 0.0052\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 24us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 23us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 27us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 27us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 24us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 23us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 0s 26us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 20us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 22us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 21us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 20us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 22us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 21us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 22us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 22us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 20us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 27us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 37us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 37us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 26us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 22us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 23us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 21us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 23us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 23us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "best reward is :  [0.66313853 0.64934024 0.58228901 0.52590947 0.49796355]\n",
      "reward is :  [0.66313853 0.64934024 0.49116156 0.58228901 0.47596071]\n",
      "regrets is :  [ 0.          0.          0.09112744 -0.05637954  0.02200284] \n",
      "\n",
      "best reward is :  [0.88756775 0.62036428 0.60261537 0.55157711 0.51790541]\n",
      "reward is :  [0.88756775 0.62036428 0.60261537 0.55157711 0.51790541]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n",
      "best reward is :  [0.75623305 0.62024241 0.56190539 0.52236292 0.504614  ]\n",
      "reward is :  [0.75623305 0.62024241 0.56190539 0.504614   0.52236292]\n",
      "regrets is :  [ 0.          0.          0.          0.01774892 -0.01774892] \n",
      "\n",
      "best reward is :  [0.5900807  0.49754312 0.47698979 0.46736996 0.4336387 ]\n",
      "reward is :  [0.5900807  0.47698979 0.46736996 0.40813126 0.38120249]\n",
      "regrets is :  [0.         0.02055333 0.00961983 0.0592387  0.05243621] \n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 21us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "best reward is :  [0.71316364 0.6775     0.65801645 0.5871479  0.55658835]\n",
      "reward is :  [0.71316364 0.6775     0.65801645 0.5871479  0.55658835]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 93us/step - loss: 0.1008 - val_loss: 0.0956\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0917 - val_loss: 0.0785\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0653 - val_loss: 0.0466\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0368 - val_loss: 0.0271\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0228 - val_loss: 0.0180\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0150 - val_loss: 0.0120\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0108 - val_loss: 0.0091\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0077 - val_loss: 0.0069\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0072 - val_loss: 0.0064\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0066 - val_loss: 0.0060\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 22us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 25us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 25us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 26us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 30us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 22us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 29us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 27us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 26us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 26us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 23us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 26us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 25us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 22us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 27us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 27us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 26us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 28us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 23us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 24us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 24us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 27us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 26us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 26us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 0s 26us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 22us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 21us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 20us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 20us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 20us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 22us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 21us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 22us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 20us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 24us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 20us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 22us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 23us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 22us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 23us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 21us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 23us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 24us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "best reward is :  [0.71250499 0.68587681 0.63907504 0.59270467 0.5829337 ]\n",
      "reward is :  [0.71250499 0.68587681 0.63907504 0.5829337  0.59270467]\n",
      "regrets is :  [ 0.          0.          0.          0.00977097 -0.00977097] \n",
      "\n",
      "best reward is :  [0.46885366 0.46325281 0.44209498 0.43389742 0.38745684]\n",
      "reward is :  [0.37514286 0.44209498 0.46325281 0.30655204 0.43389742]\n",
      "regrets is :  [ 0.0937108   0.02115784 -0.02115784  0.12734538 -0.04644057] \n",
      "\n",
      "best reward is :  [0.72514286 0.67111111 0.62082641 0.54205714 0.50525   ]\n",
      "reward is :  [0.67111111 0.72514286 0.62082641 0.54205714 0.50525   ]\n",
      "regrets is :  [ 0.05403175 -0.05403175  0.          0.          0.        ] \n",
      "\n",
      "best reward is :  [0.51468963 0.48525    0.43111111 0.42765217 0.41468467]\n",
      "reward is :  [0.51468963 0.41468467 0.48525    0.43111111 0.42765217]\n",
      "regrets is :  [ 0.          0.07056533 -0.05413889 -0.00345894 -0.01296751] \n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 21us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "best reward is :  [0.921024   0.76785185 0.74765217 0.59664863 0.56242641]\n",
      "reward is :  [0.921024   0.76785185 0.74765217 0.59664863 0.56242641]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 88us/step - loss: 0.1197 - val_loss: 0.1296\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.1043 - val_loss: 0.0975\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0633 - val_loss: 0.0492\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0322 - val_loss: 0.0285\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0217 - val_loss: 0.0204\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0157 - val_loss: 0.0147\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0115 - val_loss: 0.0111\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0092 - val_loss: 0.0093\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0082 - val_loss: 0.0086\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0079 - val_loss: 0.0083\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0077 - val_loss: 0.0082\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0073 - val_loss: 0.0077\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0067 - val_loss: 0.0070\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0063 - val_loss: 0.0066\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0059 - val_loss: 0.0062\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 34us/step - loss: 0.0022 - val_loss: 0.0057\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 26us/step - loss: 0.0021 - val_loss: 0.0056\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 31us/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 23us/step - loss: 0.0021 - val_loss: 0.0055\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 27us/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 29us/step - loss: 0.0023 - val_loss: 0.0065\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 45us/step - loss: 0.0022 - val_loss: 0.0061\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 43us/step - loss: 0.0022 - val_loss: 0.0060\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.0022 - val_loss: 0.0059\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 45us/step - loss: 0.0022 - val_loss: 0.0056\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 36us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 34us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 36us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 45us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 39us/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 37us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 37us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 41us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 40us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 35us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 26us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 27us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 28us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 25us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 22us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 0s 23us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 20us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 20us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 23us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 25us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 21us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 23us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 23us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 23us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 21us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 21us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 24us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 23us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "best reward is :  [0.55439114 0.49154062 0.47983855 0.44635945 0.4126246 ]\n",
      "reward is :  [0.55439114 0.44635945 0.47983855 0.49154062 0.35189296]\n",
      "regrets is :  [ 0.          0.04518117  0.         -0.04518117  0.06073164] \n",
      "\n",
      "best reward is :  [0.44635945 0.44542714 0.43439114 0.35983855 0.33614911]\n",
      "reward is :  [0.43439114 0.44635945 0.44542714 0.35983855 0.31951497]\n",
      "regrets is :  [ 0.0119683  -0.00093231 -0.01103599  0.          0.01663414] \n",
      "\n",
      "best reward is :  [0.67470917 0.61439114 0.55215577 0.53983855 0.52635945]\n",
      "reward is :  [0.67470917 0.61439114 0.52635945 0.53983855 0.55215577]\n",
      "regrets is :  [ 0.          0.          0.02579632  0.         -0.02579632] \n",
      "\n",
      "best reward is :  [0.84785358 0.74257426 0.72888053 0.69885714 0.69642105]\n",
      "reward is :  [0.74257426 0.69885714 0.72888053 0.84785358 0.69642105]\n",
      "regrets is :  [ 0.10527932  0.04371711  0.         -0.14899643  0.        ] \n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 21us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "best reward is :  [0.72370996 0.70742707 0.66127387 0.65270639 0.60140439]\n",
      "reward is :  [0.72370996 0.70742707 0.65270639 0.66127387 0.53787032]\n",
      "regrets is :  [ 0.          0.          0.00856748 -0.00856748  0.06353407] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 100us/step - loss: 0.1163 - val_loss: 0.1261\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.1034 - val_loss: 0.0958\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0631 - val_loss: 0.0479\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0339 - val_loss: 0.0310\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0274 - val_loss: 0.0283\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0260 - val_loss: 0.0276\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0255 - val_loss: 0.0272\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0249 - val_loss: 0.0266\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0240 - val_loss: 0.0256\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0226 - val_loss: 0.0236\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0203 - val_loss: 0.0208\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0172 - val_loss: 0.0171\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0138 - val_loss: 0.0136\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0091 - val_loss: 0.0091\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0080 - val_loss: 0.0083\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0078\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0070 - val_loss: 0.0074\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0062 - val_loss: 0.0069\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0060 - val_loss: 0.0067\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0059 - val_loss: 0.0065\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0057 - val_loss: 0.0064\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0056 - val_loss: 0.0061\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0054 - val_loss: 0.0059\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 33us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 28us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0052\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 27us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 34us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 35us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 35us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 36us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 39us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 36us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 38us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 36us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 23us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 27us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 27us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 27us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 25us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 23us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 27us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 29us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 39us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 0s 28us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 21us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 21us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 22us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 20us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 21us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 23us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 23us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 21us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 22us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 22us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 22us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 23us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 22us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 22us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 21us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 24us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 21us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 20us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "best reward is :  [0.62041812 0.59813259 0.59738933 0.54421896 0.52075949]\n",
      "reward is :  [0.62041812 0.59738933 0.59813259 0.52075949 0.54421896]\n",
      "regrets is :  [ 0.          0.00074326 -0.00074326  0.02345946 -0.02345946] \n",
      "\n",
      "best reward is :  [0.84224214 0.70284453 0.62561231 0.57446373 0.48664537]\n",
      "reward is :  [0.84224214 0.70284453 0.62561231 0.57446373 0.48664537]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n",
      "best reward is :  [0.69277734 0.65630367 0.64186069 0.61689014 0.58527093]\n",
      "reward is :  [0.69277734 0.64186069 0.65630367 0.61689014 0.58527093]\n",
      "regrets is :  [ 0.          0.01444298 -0.01444298  0.          0.        ] \n",
      "\n",
      "best reward is :  [0.81738933 0.72041812 0.60075949 0.59203733 0.48664537]\n",
      "reward is :  [0.81738933 0.72041812 0.60075949 0.59203733 0.48664537]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 24us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 21us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "best reward is :  [0.72667136 0.62970015 0.53004153 0.52216629 0.44954112]\n",
      "reward is :  [0.72667136 0.62970015 0.53004153 0.52216629 0.44261537]\n",
      "regrets is :  [0.         0.         0.         0.         0.00692576] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 92us/step - loss: 0.0941 - val_loss: 0.1092\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0869 - val_loss: 0.0891\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0577 - val_loss: 0.0503\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0335 - val_loss: 0.0339\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0268 - val_loss: 0.0283\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0221 - val_loss: 0.0220\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0167 - val_loss: 0.0161\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0125 - val_loss: 0.0121\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0092 - val_loss: 0.0092\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0085 - val_loss: 0.0084\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0079 - val_loss: 0.0077\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 27us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 25us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 23us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 24us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 22us/step - loss: 0.0021 - val_loss: 0.0060\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 27us/step - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 28us/step - loss: 0.0020 - val_loss: 0.0059\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 29us/step - loss: 0.0020 - val_loss: 0.0057\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 27us/step - loss: 0.0020 - val_loss: 0.0058\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 22us/step - loss: 0.0022 - val_loss: 0.0053\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 26us/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 26us/step - loss: 0.0022 - val_loss: 0.0051\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 28us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 24us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 23us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 29us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 26us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 25us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 27us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 24us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 26us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 26us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 39us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 29us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 23us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 24us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 29us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 29us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 24us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 21us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 24us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 23us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 24us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 21us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 23us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 24us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 23us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 21us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 23us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 23us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "best reward is :  [0.67520436 0.6743662  0.63755102 0.59714286 0.58      ]\n",
      "reward is :  [0.67520436 0.6743662  0.59714286 0.63755102 0.58      ]\n",
      "regrets is :  [ 0.          0.          0.04040816 -0.04040816  0.        ] \n",
      "\n",
      "best reward is :  [0.75372781 0.724      0.70166667 0.58742773 0.51980835]\n",
      "reward is :  [0.75372781 0.724      0.70166667 0.58742773 0.51980835]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n",
      "best reward is :  [0.69328203 0.63940316 0.50723404 0.49980835 0.43675867]\n",
      "reward is :  [0.69328203 0.63940316 0.50723404 0.49980835 0.43675867]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n",
      "best reward is :  [0.68436698 0.66641706 0.57025822 0.48821307 0.4790544 ]\n",
      "reward is :  [0.68436698 0.66641706 0.57025822 0.48821307 0.4790544 ]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 34us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "best reward is :  [0.75084628 0.7487962  0.62783181 0.55264229 0.54858441]\n",
      "reward is :  [0.7487962  0.75084628 0.62783181 0.55264229 0.52319138]\n",
      "regrets is :  [ 0.00205008 -0.00205008  0.          0.          0.02539303] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 90us/step - loss: 0.0938 - val_loss: 0.1006\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0863 - val_loss: 0.0829\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0581 - val_loss: 0.0442\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0294 - val_loss: 0.0220\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0175 - val_loss: 0.0135\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0120 - val_loss: 0.0096\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0095 - val_loss: 0.0080\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0084 - val_loss: 0.0073\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0079 - val_loss: 0.0069\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0074 - val_loss: 0.0064\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 39us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 38us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 41us/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 38us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 33us/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 33us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 36us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 41us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 31us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 39us/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 44us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 38us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 38us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 39us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 24us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 27us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 26us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 24us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 27us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 23us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 27us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 27us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 29us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 26us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 23us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 0s 23us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 21us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 24us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 20us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 23us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 22us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 23us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 24us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 24us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 22us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 22us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 22us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 23us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 22us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 22us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "best reward is :  [0.69353735 0.67270011 0.66851309 0.54731414 0.4732153 ]\n",
      "reward is :  [0.66851309 0.67270011 0.69353735 0.54731414 0.44816214]\n",
      "regrets is :  [ 0.02502426  0.         -0.02502426  0.          0.02505315] \n",
      "\n",
      "best reward is :  [0.56019624 0.47270011 0.44948847 0.44068745 0.4197573 ]\n",
      "reward is :  [0.56019624 0.44948847 0.47270011 0.4197573  0.41682353]\n",
      "regrets is :  [ 0.          0.02321164 -0.02321164  0.02093015  0.00293377] \n",
      "\n",
      "best reward is :  [0.53744    0.52664386 0.5220429  0.5        0.4958873 ]\n",
      "reward is :  [0.53744    0.5220429  0.4958873  0.52664386 0.5       ]\n",
      "regrets is :  [ 0.          0.00460096  0.0261556  -0.02664386 -0.0041127 ] \n",
      "\n",
      "best reward is :  [0.57601185 0.56731875 0.56638405 0.53794147 0.47850746]\n",
      "reward is :  [0.57601185 0.56731875 0.53794147 0.46808325 0.46652402]\n",
      "regrets is :  [0.         0.         0.02844258 0.06985822 0.01198343] \n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 21us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 24us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "best reward is :  [0.69353735 0.67903448 0.67484746 0.54731414 0.4732153 ]\n",
      "reward is :  [0.67484746 0.67903448 0.69353735 0.54731414 0.44816214]\n",
      "regrets is :  [ 0.01868989  0.         -0.01868989  0.          0.02505315] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 90us/step - loss: 0.0977 - val_loss: 0.1070\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 0.0887 - val_loss: 0.0848\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 0.0589 - val_loss: 0.0462\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0345 - val_loss: 0.0307\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0268 - val_loss: 0.0244\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - ETA: 0s - loss: 0.021 - 0s 44us/step - loss: 0.0210 - val_loss: 0.0183\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0150 - val_loss: 0.0132\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0092 - val_loss: 0.0091\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0075 - val_loss: 0.0075\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 42us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 45us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 41us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 35us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 26us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 25us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 25us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 27us/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 25us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 29us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 25us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 28us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 27us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 24us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 28us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 35us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 36us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 30us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 23us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 28us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 28us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 27us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 29us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 23us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 24us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 24us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 27us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 28us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 25us/step - loss: 0.0022 - val_loss: 0.0026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 0s 23us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 22us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 21us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 22us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 21us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 23us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 23us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 24us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 21us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 20us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 23us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 22us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 24us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 25us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 22us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 35us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 34us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 33us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 25us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "best reward is :  [0.7688389  0.59955526 0.49308431 0.4859126  0.47011309]\n",
      "reward is :  [0.7688389  0.59955526 0.4859126  0.49308431 0.47011309]\n",
      "regrets is :  [ 0.          0.          0.00717172 -0.00717172  0.        ] \n",
      "\n",
      "best reward is :  [0.68384236 0.6459126  0.64372605 0.56897227 0.49408284]\n",
      "reward is :  [0.6459126  0.68384236 0.64372605 0.56897227 0.49408284]\n",
      "regrets is :  [ 0.03792977 -0.03792977  0.          0.          0.        ] \n",
      "\n",
      "best reward is :  [0.56307264 0.51887324 0.51601751 0.45215258 0.42462873]\n",
      "reward is :  [0.56307264 0.51887324 0.51601751 0.42462873 0.45215258]\n",
      "regrets is :  [ 0.          0.          0.          0.02752386 -0.02752386] \n",
      "\n",
      "best reward is :  [0.7633315  0.64407524 0.62       0.60945338 0.51770492]\n",
      "reward is :  [0.7633315  0.64407524 0.62       0.60945338 0.51770492]\n",
      "regrets is :  [0. 0. 0. 0. 0.] \n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "best reward is :  [0.65076541 0.57573823 0.55382508 0.54869518 0.4350546 ]\n",
      "reward is :  [0.65076541 0.57573823 0.54869518 0.55382508 0.4350546 ]\n",
      "regrets is :  [ 0.         0.         0.0051299 -0.0051299  0.       ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/envs/ia316/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 0s 87us/step - loss: 0.0979 - val_loss: 0.1014\n",
      "Epoch 2/50\n",
      "4500/4500 [==============================] - 0s 19us/step - loss: 0.0883 - val_loss: 0.0793\n",
      "Epoch 3/50\n",
      "4500/4500 [==============================] - 0s 20us/step - loss: 0.0556 - val_loss: 0.0414\n",
      "Epoch 4/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0308 - val_loss: 0.0289\n",
      "Epoch 5/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0257 - val_loss: 0.0270\n",
      "Epoch 6/50\n",
      "4500/4500 [==============================] - 0s 21us/step - loss: 0.0242 - val_loss: 0.0255\n",
      "Epoch 7/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0222 - val_loss: 0.0228\n",
      "Epoch 8/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0188 - val_loss: 0.0185\n",
      "Epoch 9/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0145 - val_loss: 0.0139\n",
      "Epoch 10/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0107 - val_loss: 0.0105\n",
      "Epoch 11/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0086 - val_loss: 0.0088\n",
      "Epoch 12/50\n",
      "4500/4500 [==============================] - 0s 22us/step - loss: 0.0076 - val_loss: 0.0079\n",
      "Epoch 13/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0070 - val_loss: 0.0074\n",
      "Epoch 14/50\n",
      "4500/4500 [==============================] - 0s 33us/step - loss: 0.0065 - val_loss: 0.0068\n",
      "Epoch 15/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0060 - val_loss: 0.0063\n",
      "Epoch 16/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 17/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 18/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 19/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 20/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 21/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 22/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 23/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 24/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 25/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 26/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 27/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 28/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 29/50\n",
      "4500/4500 [==============================] - 0s 35us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 30/50\n",
      "4500/4500 [==============================] - 0s 34us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 31/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 32/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 33/50\n",
      "4500/4500 [==============================] - 0s 37us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 34/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 35/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 36/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 37/50\n",
      "4500/4500 [==============================] - 0s 47us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 38/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 39/50\n",
      "4500/4500 [==============================] - 0s 36us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 40/50\n",
      "4500/4500 [==============================] - 0s 38us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 41/50\n",
      "4500/4500 [==============================] - 0s 40us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 42/50\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 43/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 44/50\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 45/50\n",
      "4500/4500 [==============================] - 0s 26us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 46/50\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 47/50\n",
      "4500/4500 [==============================] - 0s 39us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 48/50\n",
      "4500/4500 [==============================] - 0s 48us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 49/50\n",
      "4500/4500 [==============================] - 0s 44us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 50/50\n",
      "4500/4500 [==============================] - 0s 43us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Train on 4950 samples, validate on 550 samples\n",
      "Epoch 1/5\n",
      "4950/4950 [==============================] - 0s 32us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 2/5\n",
      "4950/4950 [==============================] - 0s 25us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 3/5\n",
      "4950/4950 [==============================] - 0s 27us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 4/5\n",
      "4950/4950 [==============================] - 0s 24us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 5/5\n",
      "4950/4950 [==============================] - 0s 25us/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "5400/5400 [==============================] - 0s 23us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 2/5\n",
      "5400/5400 [==============================] - 0s 27us/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 3/5\n",
      "5400/5400 [==============================] - 0s 39us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 4/5\n",
      "5400/5400 [==============================] - 0s 33us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 5/5\n",
      "5400/5400 [==============================] - 0s 42us/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Train on 5850 samples, validate on 650 samples\n",
      "Epoch 1/5\n",
      "5850/5850 [==============================] - 0s 34us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 2/5\n",
      "5850/5850 [==============================] - 0s 37us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 3/5\n",
      "5850/5850 [==============================] - 0s 35us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 4/5\n",
      "5850/5850 [==============================] - 0s 39us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 5/5\n",
      "5850/5850 [==============================] - 0s 44us/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/5\n",
      "6300/6300 [==============================] - 0s 36us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 2/5\n",
      "6300/6300 [==============================] - 0s 37us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 3/5\n",
      "6300/6300 [==============================] - 0s 37us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 4/5\n",
      "6300/6300 [==============================] - 0s 41us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 5/5\n",
      "6300/6300 [==============================] - 0s 40us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/5\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 2/5\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 3/5\n",
      "6750/6750 [==============================] - 0s 55us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 4/5\n",
      "6750/6750 [==============================] - 0s 32us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 5/5\n",
      "6750/6750 [==============================] - 0s 48us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 0s 42us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 0s 39us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 0s 39us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 0s 39us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 0s 41us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Train on 7650 samples, validate on 850 samples\n",
      "Epoch 1/5\n",
      "7650/7650 [==============================] - 0s 38us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 2/5\n",
      "7650/7650 [==============================] - 0s 34us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 3/5\n",
      "7650/7650 [==============================] - 0s 38us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 4/5\n",
      "7650/7650 [==============================] - 0s 33us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 5/5\n",
      "7650/7650 [==============================] - 0s 37us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/5\n",
      "8100/8100 [==============================] - 0s 34us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 2/5\n",
      "8100/8100 [==============================] - 0s 37us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 3/5\n",
      "8100/8100 [==============================] - 0s 34us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 4/5\n",
      "8100/8100 [==============================] - 0s 34us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 5/5\n",
      "8100/8100 [==============================] - 0s 35us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Train on 8550 samples, validate on 950 samples\n",
      "Epoch 1/5\n",
      "8550/8550 [==============================] - 0s 26us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 2/5\n",
      "8550/8550 [==============================] - 0s 23us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 3/5\n",
      "8550/8550 [==============================] - 0s 36us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 4/5\n",
      "8550/8550 [==============================] - 0s 39us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 5/5\n",
      "8550/8550 [==============================] - 0s 37us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "best reward is :  [0.70425131 0.56577085 0.56470187 0.54830014 0.5461501 ]\n",
      "reward is :  [0.70425131 0.54830014 0.56470187 0.5461501  0.56577085]\n",
      "regrets is :  [ 0.          0.01747071  0.          0.00215004 -0.01962075] \n",
      "\n",
      "best reward is :  [0.74169583 0.69393957 0.64809054 0.59853127 0.54768203]\n",
      "reward is :  [0.74169583 0.69393957 0.64809054 0.54768203 0.59853127]\n",
      "regrets is :  [ 0.          0.          0.          0.05084924 -0.05084924] \n",
      "\n",
      "best reward is :  [0.56838829 0.56049564 0.412      0.37066721 0.3593985 ]\n",
      "reward is :  [0.56049564 0.56838829 0.412      0.37066721 0.28614316]\n",
      "regrets is :  [ 0.00789265 -0.00789265  0.          0.          0.07325534] \n",
      "\n",
      "best reward is :  [0.60128203 0.58986597 0.58169583 0.53393957 0.5184    ]\n",
      "reward is :  [0.58986597 0.58169583 0.60128203 0.53393957 0.46376852]\n",
      "regrets is :  [ 0.01141606  0.00817015 -0.01958621  0.          0.05463148] \n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 0s 34us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "best reward is :  [0.67138169 0.54585034 0.53958671 0.52334444 0.5218249 ]\n",
      "reward is :  [0.67138169 0.5218249  0.53958671 0.52334444 0.50186139]\n",
      "regrets is :  [0.         0.02402544 0.         0.         0.01996352] \n",
      "\n",
      "End of the simulations, time elapsed: 494.716 seconds.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "regret, regrets, rewards, _ = run_several_experiments_hist_Embedding_online(evolutive_env = False, nb_exp = 20, nb_steps_history=1000, nb_steps = 1000, action_size = 5)\n",
    "plot_regret(regret, regrets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
